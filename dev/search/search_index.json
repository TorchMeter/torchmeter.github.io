{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Intros","text":"<p>     \ud83d\ude80 \ud835\udc80\ud835\udc90\ud835\udc96\ud835\udc93 \ud835\udc68\ud835\udc8d\ud835\udc8d-\ud835\udc8a\ud835\udc8f-\ud835\udc76\ud835\udc8f\ud835\udc86 \ud835\udc7b\ud835\udc90\ud835\udc90\ud835\udc8d \ud835\udc87\ud835\udc90\ud835\udc93 \ud835\udc77\ud835\udc9a\ud835\udc95\ud835\udc90\ud835\udc93\ud835\udc84\ud835\udc89 \ud835\udc74\ud835\udc90\ud835\udc85\ud835\udc86\ud835\udc8d \ud835\udc68\ud835\udc8f\ud835\udc82\ud835\udc8d\ud835\udc9a\ud835\udc94\ud835\udc8a\ud835\udc94 \ud83d\ude80 </p> <p> </p> <ul> <li>Repo: https://github.com/TorchMeter/torchmeter</li> <li>Intro: Provides comprehensive measurement of <code>Pytorch</code> model's <code>Parameters</code>, <code>FLOPs/MACs</code>, <code>Memory-Cost</code>, <code>Inference-Time</code> and <code>Throughput</code> with highly customizable result display \u2728</li> </ul>"},{"location":"#\ud835\udc9c-\ud835\udc3b\ud835\udcbe\ud835\udc54\ud835\udcbd\ud835\udcc1\ud835\udcbe\ud835\udc54\ud835\udcbd\ud835\udcc9\ud835\udcc8","title":"\ud835\udc9c. \ud835\udc3b\ud835\udcbe\ud835\udc54\ud835\udcbd\ud835\udcc1\ud835\udcbe\ud835\udc54\ud835\udcbd\ud835\udcc9\ud835\udcc8","text":"\ud835\ude89\ud835\ude8e\ud835\ude9b\ud835\ude98-\ud835\ude78\ud835\ude97\ud835\ude9d\ud835\ude9b\ud835\ude9e\ud835\ude9c\ud835\ude92\ud835\ude98\ud835\ude97 \ud835\ude7f\ud835\ude9b\ud835\ude98\ud835\udea1\ud835\udea2 <ul> <li> Acts as drop-in decorator without any changes of the underlying model</li> <li> Seamlessly integrates with <code>Pytorch</code> modules while preserving full compatibility (attributes and methods)</li> </ul>  \ud835\ude75\ud835\ude9e\ud835\ude95\ud835\ude95-\ud835\ude82\ud835\ude9d\ud835\ude8a\ud835\ude8c\ud835\ude94 \ud835\ude7c\ud835\ude98\ud835\ude8d\ud835\ude8e\ud835\ude95 \ud835\ude70\ud835\ude97\ud835\ude8a\ud835\ude95\ud835\udea2\ud835\ude9d\ud835\ude92\ud835\ude8c\ud835\ude9c <p>Holistic performance analytics across 5 dimensions: </p> <ul> <li> <p> Parameter Analysis</p> <ul> <li>Total/trainable parameter quantification</li> <li>Layer-wise parameter distribution analysis</li> <li>Gradient state tracking (requires_grad flags)</li> </ul> </li> <li> <p> Computational Profiling</p> <ul> <li>FLOPs/MACs precision calculation</li> <li>Operation-wise calculation distribution analysis</li> <li>Dynamic input/output detection (number, type, shape, ...)</li> </ul> </li> <li> <p> Memory Diagnostics </p> <ul> <li>Input/output tensor memory awareness</li> <li>Hierarchical memory consumption analysis</li> </ul> </li> <li> <p> Inference latency &amp; 5. Throughput benchmarking</p> <ul> <li>Auto warm-up phase execution (eliminates cold-start bias)</li> <li>Device-specific high-precision timing</li> <li>Inference latency  &amp; Throughput Benchmarking</li> </ul> </li> </ul>  \ud835\ude81\ud835\ude92\ud835\ude8c\ud835\ude91 \ud835\ude85\ud835\ude92\ud835\ude9c\ud835\ude9e\ud835\ude8a\ud835\ude95\ud835\ude92\ud835\udea3\ud835\ude8a\ud835\ude9d\ud835\ude92\ud835\ude98\ud835\ude97 <ul> <li> <p> Programmable tabular report</p> <ul> <li>Dynamic table structure adjustment</li> <li>Style customization and real-time rendering</li> <li>Real-time data analysis in programmable way</li> </ul> </li> <li> <p> Rich-text hierarchical operation tree</p> <ul> <li>Style customization and real-time rendering</li> <li>Smart module folding based on structural equivalence detection for intuitive model structure insights</li> </ul> </li> </ul>  \ud835\ude75\ud835\ude92\ud835\ude97\ud835\ude8e-\ud835\ude76\ud835\ude9b\ud835\ude8a\ud835\ude92\ud835\ude97\ud835\ude8e\ud835\ude8d \ud835\ude72\ud835\ude9e\ud835\ude9c\ud835\ude9d\ud835\ude98\ud835\ude96\ud835\ude92\ud835\udea3\ud835\ude8a\ud835\ude9d\ud835\ude92\ud835\ude98\ud835\ude97 <ul> <li> <p> Real-time hot-reload rendering:  Dynamic adjustment of rendering configuration for operation trees, report tables and their nested components </p> </li> <li> <p> Progressive update: Namespace assignment + dictionary batch update</p> </li> </ul>  \ud835\ude72\ud835\ude98\ud835\ude97\ud835\ude8f\ud835\ude92\ud835\ude90-\ud835\ude73\ud835\ude9b\ud835\ude92\ud835\ude9f\ud835\ude8e\ud835\ude97 \ud835\ude81\ud835\ude9e\ud835\ude97\ud835\ude9d\ud835\ude92\ud835\ude96\ud835\ude8e \ud835\ude7c\ud835\ude8a\ud835\ude97\ud835\ude8a\ud835\ude90\ud835\ude8e\ud835\ude96\ud835\ude8e\ud835\ude97\ud835\ude9d <ul> <li> <p> Centralized control: Singleton-managed global configuration for dynamic behavior adjustment </p> </li> <li> <p> Portable presets: Export/import YAML profiles for runtime behaviors, eliminating repetitive setup</p> </li> </ul>  \ud835\ude7f\ud835\ude98\ud835\ude9b\ud835\ude9d\ud835\ude8a\ud835\ude8b\ud835\ude92\ud835\ude95\ud835\ude92\ud835\ude9d\ud835\udea2 \ud835\ude8a\ud835\ude97\ud835\ude8d \ud835\ude7f\ud835\ude9b\ud835\ude8a\ud835\ude8c\ud835\ude9d\ud835\ude92\ud835\ude8c\ud835\ude8a\ud835\ude95\ud835\ude92\ud835\ude9d\ud835\udea2 <ul> <li> <p> Decoupled pipeline: Separation of data collection and visualization </p> </li> <li> <p> Automatic device synchronization: Maintains production-ready status by keeping model and data co-located </p> </li> <li> <p> Dual-mode reporting with export flexibility: </p> <ul> <li>Measurement units mode vs. raw data mode</li> <li>Multi-format export (<code>CSV</code>/<code>Excel</code>) for analysis integration</li> </ul> </li> </ul>"},{"location":"#\u212c-\ud835\udc3c\ud835\udcc3\ud835\udcc8\ud835\udcc9\ud835\udcb6\ud835\udcc1\ud835\udcc1\ud835\udcb6\ud835\udcc9\ud835\udcbe\ud835\udc5c\ud835\udcc3","title":"\u212c. \ud835\udc3c\ud835\udcc3\ud835\udcc8\ud835\udcc9\ud835\udcb6\ud835\udcc1\ud835\udcc1\ud835\udcb6\ud835\udcc9\ud835\udcbe\ud835\udc5c\ud835\udcc3","text":"\ud835\ude72\ud835\ude98\ud835\ude96\ud835\ude99\ud835\ude8a\ud835\ude9d\ud835\ude92\ud835\ude8b\ud835\ude92\ud835\ude95\ud835\ude92\ud835\ude9d\ud835\udea2 <ul> <li> OS: <code>windows</code> / <code>linux</code> / <code>macOS</code></li> <li> Python: &gt;= 3.8</li> <li> Pytorch: &gt;= 1.7.0</li> </ul> \ud835\ude83\ud835\ude91\ud835\ude9b\ud835\ude98\ud835\ude9e\ud835\ude90\ud835\ude91 \ud835\ude7f\ud835\udea2\ud835\ude9d\ud835\ude91\ud835\ude98\ud835\ude97 \ud835\ude7f\ud835\ude8a\ud835\ude8c\ud835\ude94\ud835\ude8a\ud835\ude90\ud835\ude8e \ud835\ude7c\ud835\ude8a\ud835\ude97\ud835\ude8a\ud835\ude90\ud835\ude8e\ud835\ude9b <p>the most convenient way, suitable for installing the released latest stable version</p> <pre><code># pip series\npip/pipx/pipenv install torchmeter\n\n# Or via conda\nconda install torchmeter\n\n# Or via uv\nuv add torchmeter\n\n# Or via poetry\npoetry add torchmeter\n\n# Other managers' usage please refer to their own documentation\n</code></pre> \ud835\ude83\ud835\ude91\ud835\ude9b\ud835\ude98\ud835\ude9e\ud835\ude90\ud835\ude91 \ud835\ude71\ud835\ude92\ud835\ude97\ud835\ude8a\ud835\ude9b\ud835\udea2 \ud835\ude73\ud835\ude92\ud835\ude9c\ud835\ude9d\ud835\ude9b\ud835\ude92\ud835\ude8b\ud835\ude9e\ud835\ude9d\ud835\ude92\ud835\ude98\ud835\ude97 <p>Suitable for installing released historical versions</p> <ol> <li> <p>Download <code>.whl</code> from PyPI  or Github Releases .</p> </li> <li> <p>Install locally:</p> <pre><code>pip install torchmeter-x.x.x.whl # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>x.x.x</code> with actual version</li> </ol> </li> </ol> \ud835\ude83\ud835\ude91\ud835\ude9b\ud835\ude98\ud835\ude9e\ud835\ude90\ud835\ude91 \ud835\ude82\ud835\ude98\ud835\ude9e\ud835\ude9b\ud835\ude8c\ud835\ude8e \ud835\ude72\ud835\ude98\ud835\ude8d\ud835\ude8e <p>Suitable for who want to try out the upcoming features (may has unknown bugs).</p> <pre><code>git clone https://github.com/TorchMeter/torchmeter.git\ncd torchmeter\n\n# If you want to install the released stable version, use this: \ngit checkout vx.x.x # Stable (1)\n\n# If you want to try the latest development version(alpha/beta), use this:\ngit checkout master  # Development version\n\npip install .\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Don't forget to eplace <code>x.x.x</code> with actual version. You can check all available versions with <code>git tag -l</code></li> </ol>"},{"location":"#\ud835\udc9e-\ud835\udca2\ud835\udc52\ud835\udcc9\ud835\udcc9\ud835\udcbe\ud835\udcc3\ud835\udc54-\ud835\udcc8\ud835\udcc9\ud835\udcb6\ud835\udcc7\ud835\udcc9\ud835\udc52\ud835\udcb9","title":"\ud835\udc9e. \ud835\udca2\ud835\udc52\ud835\udcc9\ud835\udcc9\ud835\udcbe\ud835\udcc3\ud835\udc54 \ud835\udcc8\ud835\udcc9\ud835\udcb6\ud835\udcc7\ud835\udcc9\ud835\udc52\ud835\udcb9","text":"\ud835\ude73\ud835\ude8e\ud835\ude95\ud835\ude8e\ud835\ude90\ud835\ude8a\ud835\ude9d\ud835\ude8e \ud835\udea2\ud835\ude98\ud835\ude9e\ud835\ude9b \ud835\ude96\ud835\ude98\ud835\ude8d\ud835\ude8e\ud835\ude95 \ud835\ude9d\ud835\ude98 \ud835\ude9d\ud835\ude98\ud835\ude9b\ud835\ude8c\ud835\ude91\ud835\ude96\ud835\ude8e\ud835\ude9d\ud835\ude8e\ud835\ude9b Implementation of ExampleNet Python<pre><code>import torch.nn as nn\n\nclass ExampleNet(nn.Module):\n    def __init__(self):\n        super(ExampleNet, self).__init__()\n\n        self.backbone = nn.Sequential(\n            self._nested_repeat_block(2),\n            self._nested_repeat_block(2)\n        )\n\n        self.gap = nn.AdaptiveAvgPool2d(1)\n\n        self.classifier = nn.Linear(3, 2)\n\n    def _inner_net(self):\n        return nn.Sequential(\n            nn.Conv2d(10, 10, 1),\n            nn.BatchNorm2d(10),\n            nn.ReLU(),\n        )\n\n    def _nested_repeat_block(self, repeat:int=1):\n        inners = [self._inner_net() for _ in range(repeat)]\n        return nn.Sequential(\n            nn.Conv2d(3, 10, 3, stride=1, padding=1),\n            nn.BatchNorm2d(10),\n            nn.ReLU(),\n            *inners,\n            nn.Conv2d(10, 3, 1),\n            nn.BatchNorm2d(3),\n            nn.ReLU()\n        )\n\n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.gap(x)\n        x = x.squeeze(dim=(2,3))\n        return self.classifier(x)\n</code></pre> Python<pre><code>import torch.nn as nn\nfrom torchmeter import Meter\nfrom torch.cuda import is_available as is_cuda\n\n# 1\ufe0f\u20e3 Prepare your pytorch model, here is a simple examples\nunderlying_model = ExampleNet() # (1)\n\n# Set an extra attribute to the model to show \n# how torchmeter acts as a zero-intrusion proxy later\nunderlying_model.example_attr = \"ABC\"\n\n# 2\ufe0f\u20e3 Wrap your model with torchmeter\nmodel = Meter(underlying_model)\n\n# 3\ufe0f\u20e3 Validate the zero-intrusion proxy\n\n# Get the model's attribute\nprint(model.example_attr)\n\n# Get the model's method\n# `_inner_net` is a method defined in the ExampleNet\nprint(hasattr(model, \"_inner_net\")) \n\n# Move the model to other device (now on cpu)\nprint(model)\nif is_cuda():\n    model.to(\"cuda\")\n    print(model) # now on cuda\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f see above for implementation of <code>ExampleNet</code></li> </ol>  \ud835\ude76\ud835\ude8e\ud835\ude9d \ud835\ude92\ud835\ude97\ud835\ude9c\ud835\ude92\ud835\ude90\ud835\ude91\ud835\ude9d\ud835\ude9c \ud835\ude92\ud835\ude97\ud835\ude9d\ud835\ude98 \ud835\ude9d\ud835\ude91\ud835\ude8e \ud835\ude96\ud835\ude98\ud835\ude8d\ud835\ude8e\ud835\ude95 \ud835\ude9c\ud835\ude9d\ud835\ude9b\ud835\ude9e\ud835\ude8c\ud835\ude9d\ud835\ude9e\ud835\ude9b\ud835\ude8e Python<pre><code>from rich import print\n\nprint(model.structure)\n</code></pre>  \ud835\ude80\ud835\ude9e\ud835\ude8a\ud835\ude97\ud835\ude9d\ud835\ude92\ud835\ude8f\ud835\udea2 \ud835\ude96\ud835\ude98\ud835\ude8d\ud835\ude8e\ud835\ude95 \ud835\ude99\ud835\ude8e\ud835\ude9b\ud835\ude8f\ud835\ude98\ud835\ude9b\ud835\ude96\ud835\ude8a\ud835\ude97\ud835\ude8c\ud835\ude8e \ud835\ude8f\ud835\ude9b\ud835\ude98\ud835\ude96 \ud835\ude9f\ud835\ude8a\ud835\ude9b\ud835\ude92\ud835\ude98\ud835\ude9e\ud835\ude9c \ud835\ude8d\ud835\ude92\ud835\ude96\ud835\ude8e\ud835\ude97\ud835\ude9c\ud835\ude92\ud835\ude98\ud835\ude97\ud835\ude9c Python<pre><code># Parameter Analysis\n# Suppose that the `backbone` part of ExampleNet is frozen\n_ = model.backbone.requires_grad_(False)\nprint(model.param)\ntb, data = model.profile('param', no_tree=True)\n\n# Before measuring calculation you should first execute a feed-forward\nimport torch\ninput = torch.randn(1, 3, 32, 32)\noutput = model(input) # (1)\n\n# Computational Profiling\nprint(model.cal) # (2)\ntb, data = model.profile('cal', no_tree=True)\n\n# Memory Diagnostics\nprint(model.mem) # (3)\ntb, data = model.profile('mem', no_tree=True)\n\n# Performance Benchmarking\nprint(model.ittp) # (4)\ntb, data = model.profile('ittp', no_tree=True)\n\n# Overall Analytics\nprint(model.overview())\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f you do not need to concern about the device mismatch, just feed the model with the input.</li> <li>\ud83d\ude4b\u200d\u2642\ufe0f <code>cal</code> for calculation</li> <li>\ud83d\ude4b\u200d\u2642\ufe0f <code>mem</code> for memory</li> <li>\ud83d\ude4b\u200d\u2642\ufe0f <code>ittp</code> for inference time &amp; throughput</li> </ol>  \ud835\ude74\ud835\udea1\ud835\ude99\ud835\ude98\ud835\ude9b\ud835\ude9d \ud835\ude9b\ud835\ude8e\ud835\ude9c\ud835\ude9e\ud835\ude95\ud835\ude9d\ud835\ude9c \ud835\ude8f\ud835\ude98\ud835\ude9b \ud835\ude8f\ud835\ude9e\ud835\ude9b\ud835\ude9d\ud835\ude91\ud835\ude8e\ud835\ude9b \ud835\ude8a\ud835\ude97\ud835\ude8a\ud835\ude95\ud835\udea2\ud835\ude9c\ud835\ude92\ud835\ude9c Python<pre><code># export to csv\ntb, data = model.profile('param', show=False, save_to=\"params.csv\")\n\n# export to excel\ntb, data = model.profile('cal', show=False, save_to=\"../calculation.xlsx\")\n</code></pre>  \ud835\ude70\ud835\ude8d\ud835\ude9f\ud835\ude8a\ud835\ude97\ud835\ude8c\ud835\ude8e\ud835\ude8d \ud835\ude9e\ud835\ude9c\ud835\ude8a\ud835\ude90\ud835\ude8e <ol> <li>Attributes/methods access of underlying model </li> <li>Automatic device synchronization </li> <li>Smart module folding </li> <li>Performance gallery </li> <li>Customized visulization <ul> <li>for statistics overview </li> <li>for operation tree </li> <li>for tabular report </li> </ul> </li> <li>Best practice of programmable tabular report<ul> <li>Real-time structure adjustment  </li> <li>Real-time data analysis </li> </ul> </li> <li>Instant export and postponed export </li> <li>Centralized configuration management </li> <li>Submodule exploration </li> </ol>"},{"location":"#\ud835\udc9f-\ud835\udc9e\ud835\udc5c\ud835\udcc3\ud835\udcc9\ud835\udcc7\ud835\udcbe\ud835\udcb7\ud835\udcca\ud835\udcc9\ud835\udc52","title":"\ud835\udc9f. \ud835\udc9e\ud835\udc5c\ud835\udcc3\ud835\udcc9\ud835\udcc7\ud835\udcbe\ud835\udcb7\ud835\udcca\ud835\udcc9\ud835\udc52","text":"<p>Thank you for wanting to make <code>TorchMeter</code> even better!</p> <p>There are several ways to make a contribution:</p> <ul> <li> Asking questions </li> <li> Reporting bugs </li> <li> Contributing code </li> </ul> <p>Before jumping in, let's ensure smooth collaboration by reviewing our \ud83d\udccb contribution guidelines  first. </p> <p>Thanks again !</p>"},{"location":"#\u2130-\ud835\udc9e\ud835\udc5c\ud835\udcb9\ud835\udc52-\ud835\udc5c\ud835\udcbb-\ud835\udc9e\ud835\udc5c\ud835\udcc3\ud835\udcb9\ud835\udcca\ud835\udcb8\ud835\udcc9","title":"\u2130. \ud835\udc9e\ud835\udc5c\ud835\udcb9\ud835\udc52 \ud835\udc5c\ud835\udcbb \ud835\udc9e\ud835\udc5c\ud835\udcc3\ud835\udcb9\ud835\udcca\ud835\udcb8\ud835\udcc9","text":"<p>Refer to official code-of-conduct file  for more details.</p> <ul> <li> <p><code>TorchMeter</code> is an open-source project built by developers worldwide. We're committed to fostering a friendly, safe, and inclusive environment for all participants. </p> </li> <li> <p>This code applies to all community spaces including but not limited to GitHub repositories, community forums, etc.</p> </li> </ul>"},{"location":"#\u2131-\ud835\udc3f\ud835\udcbe\ud835\udcb8\ud835\udc52\ud835\udcc3\ud835\udcc8\ud835\udc52","title":"\u2131. \ud835\udc3f\ud835\udcbe\ud835\udcb8\ud835\udc52\ud835\udcc3\ud835\udcc8\ud835\udc52","text":"<ul> <li><code>TorchMeter</code> is released under the AGPL-3.0 License, see the LICENSE  file for the full text. </li> <li>Please carefully review the terms in the LICENSE  file before using or distributing <code>TorchMeter</code>. </li> <li>Ensure compliance with the licensing conditions, especially when integrating this project into larger systems or proprietary software.</li> </ul>"},{"location":"cheatsheet/","title":"Cheatsheet","text":""},{"location":"cheatsheet/#Default-Configuration","title":"Default Configuration","text":"<p>When retrieving a global config not from a file, <code>torchmeter</code> will initialize it using the following default configuration.   You can view it in a hierarchical way via:</p> Python<pre><code>from torchmeter import get_config\n\ncfg = get_config()\nprint(cfg)\n</code></pre> YAML<pre><code># time interval in displaying profile\nrender_interval: 0.15         # unit: second\n\n# Whether to fold the repeat part in rendering model structure tree\ntree_fold_repeat: True \n\n# Display settings for repeat blocks in the model structure tree\n# It actually is a rich.panel.Panel object, refer to https://rich.readthedocs.io/en/latest/reference/panel.html#rich.panel.Panel \ntree_repeat_block_args:\n  title: '[i]Repeat [[b]&lt;repeat_time&gt;[/b]] Times[/]' # Title of the repeat block, accept rich styling\n  title_align: center         # Title alignment, left, center, right\n  subtitle: null              # Subtitle of the repeat block, accept rich styling\n  subtitle_align: center      # Subtitle alignment, left, center, right\n\n  style: dark_goldenrod   # Style of the repeat block, execute `python -m rich.theme` to get more\n  highlight: true             # Whether to highlight the value (number, string...)\n  box: HEAVY_EDGE             # Box type, use its name directly like here!!! execute `python -m rich.box` to get more\n  border_style: dim           # Border style, execute `python -m rich.theme` to get more\n\n  width: null                 # Width of the repeat block, null means auto\n  height: null                # Height of the repeat block, null means auto\n  padding:                    # Padding of the repeat block\n    - 0                       # top/bottom padding\n    - 1                       # left/right padding\n  expand: false               # Whether to expand the repeat block to full screen size\n\n\n# Fine-grained display settings for each level in the model structure tree\n# It actually is a rich.tree.Tree object, refer to https://rich.readthedocs.io/en/latest/reference/tree.html#rich.tree.Tree\n# the `level` field is necessary!!!! It indicates that the following settings will be applied to that layer.\n# level 0 indicates the root node(i.e. the model itself), level 1 indicates the first layer of model children, and so on.\ntree_levels_args:\n  default:   # Necessary!!!! Alternatively, you can set use 'all' to apply below settings to all levels\n    label: '[b gray35](&lt;node_id&gt;) [green]&lt;name&gt;[/green] [cyan]&lt;type&gt;[/]' # node represent string, accept rich styling\n    style: tree               # Style of the node, execute `python -m rich.theme` to get more\n    guide_style: light_coral  # Guide style of the node, execute `python -m rich.theme` to get more\n    highlight: true           # Whether to highlight the value (number, string...)\n    hide_root: false          # Whether to not display the node in this level \n    expanded: true            # Whether to display the node's children\n\n  '0':   # Necessary!!!! The number indicates that the following settings will be applied to that layer.   \n    label: '[b light_coral]&lt;name&gt;[/]'\n    guide_style: light_coral\n    # if other settings is not specified, it will use the default settings defined by the `level default`\n\n\n# Display settings for each column in the profile table\n# It actually is a rich.table.Column object, refer to https://rich.readthedocs.io/en/latest/reference/table.html#rich.table.Column\ntable_column_args:\n  style: none       # Style of the column, execute `python -m rich.theme` to get more\n  justify: center   # Justify of the column, left, center, right\n  vertical: middle  # Vertical align of the column, top, middle, bottom\n  overflow: fold    # Overflow of the column, fold, crop, ellipsis, see https://rich.readthedocs.io/en/latest/console.html?highlight=overflow#overflow\n  no_wrap: false    # Prevent wrapping of text within the column.\n\n\n# Display settings for the profile table\n# It actually is a rich.table.Table object, refer to https://rich.readthedocs.io/en/latest/reference/table.html#rich.table.Table\ntable_display_args:\n  style: spring_green4        # Style of the table, execute `python -m rich.theme` to get more\n  highlight: true             # Whether to highlight the value (number, string...)\n\n  width: null                 # The width in characters of the table, or `null` to automatically fit\n  min_width: null             # The minimum width of the table, or `null` for no minimum\n  expand: false               # Whether to expand the table to full screen size\n  padding:                    # Padding for cells \n    - 0                       # top/bottom padding\n    - 1                       # left/right padding\n  collapse_padding: false     # Whether to enable collapsing of padding around cells\n  pad_edge: true              # Whether to enable padding of edge cells\n  leading: 0                  # Number of blank lines between rows (precludes `show_lines` below)\n\n  title: null                 # Title of the table, accept rich styling\n  title_style: bold           # Style of the title, execute `python -m rich.theme` to get more\n  title_justify: center       # Justify of the title, left, center, right\n  caption: null               # The table caption rendered below, accept rich styling\n  caption_style: null         # Style of the caption, execute `python -m rich.theme` to get more\n  caption_justify: center     # Justify of the caption, left, center, right\n\n  show_header: true           # Whether to show the header row\n  header_style: bold          # Style of the header, execute `python -m rich.theme` to get more\n\n  show_footer: false          # Whether to show the footer row\n  footer_style: italic        # Style of the footer, execute `python -m rich.theme` to get more\n\n  show_lines: false           # Whether to show lines between rows\n  row_styles: null            # Optional list of row styles, if more than one style is given then the styles will alternate\n\n  show_edge: true             # Whether to show the edge of the table\n  box: ROUNDED                # Box type, use its name directly like here!!! execute `python -m rich.box` to get more\n  safe_box: true              # Whether to disable box characters that don't display on windows legacy terminal with *raster* fonts\n  border_style: null          # Style of the border, execute `python -m rich.theme` to get more\n\n# Display settings about how to combine the tree and table in the profile\ncombine:\n  horizon_gap: 2  # horizontal gap in pixel between the tree and table\n</code></pre>"},{"location":"cheatsheet/#Tree-Level-Index","title":"Tree Level Index","text":""},{"location":"cheatsheet/#What-is-the-tree-level-index","title":"What is the tree level index?","text":"<p>As the name implies, it is the hierarchical index of a operation tree. </p> <p>Actually, the level index of a tree node equals to <code>len(tree_node.node_id.split('.'))</code></p> <pre><code>AnyNet\n\u251c\u2500\u2500 (1) layers Sequential\n\u2502   \u251c\u2500\u2500 (1.1) 0 BasicBlock\n\u2502   \u2502   \u251c\u2500\u2500 (1.1.1) conv1 Conv2d\n\u2502   \u2502   \u251c\u2500\u2500 (1.1.2) bn1 BatchNorm2d\n\u2502   \u2502   \u251c\u2500\u2500 (1.1.3) relu ReLU\n\u2502   \u2502   \u251c\u2500\u2500 (1.1.4) conv2 Conv2d\n\u2502   \u2502   \u251c\u2500\u2500 (1.1.5) bn2 BatchNorm2d\n\u2502   \u2502   \u2514\u2500\u2500 (1.1.6) downsample Sequential\n\u2502   \u2502       \u251c\u2500\u2500 (1.1.6.1) 0 Conv2d\n\u2502   \u2502       \u2514\u2500\u2500 (1.1.6.2) 1 BatchNorm2d\n\u2502   \u2514\u2500\u2500 (1.2) 1 BasicBlock\n\u2502       \u251c\u2500\u2500 (1.2.1) conv1 Conv2d\n\u2502       \u251c\u2500\u2500 (1.2.2) bn1 BatchNorm2d\n\u2502       \u251c\u2500\u2500 (1.2.3) relu ReLU\n\u2502       \u251c\u2500\u2500 (1.2.4) conv2 Conv2d\n\u2502       \u2514\u2500\u2500 (1.2.5) bn2 BatchNorm2d\n\u251c\u2500\u2500 (2) avgpool AdaptiveAvgPool2d\n\u2514\u2500\u2500 (3) fc Linear\n\n\u2191   \u2191   \u2191   \u2191\n\n0   1   2   3\n</code></pre>"},{"location":"cheatsheet/#How-to-use-the-tree-level-index","title":"How to use the tree level index?","text":"<p>A valid level index empowers you to customize the operation tree with meticulous precision. <code>torchmeter</code> regards the following value as a valid tree level index:</p> <ol> <li>A non-negative integer (e.g. <code>0</code>, <code>1</code>, <code>2</code>, ...): The configurations under a specific index apply only to the corresponding level.</li> <li><code>default</code>: The configurations under this index will be applied to all undefined levels.</li> <li><code>all</code>: The configurations under this index will be applied to all levels.</li> </ol> <p>Please refer to Customize the Hierarchical Display for specific usage scenarios.</p>"},{"location":"cheatsheet/#Tree-Node-Attributes","title":"Tree Node Attributes","text":""},{"location":"cheatsheet/#What-is-a-tree-node-attribute","title":"What is a tree node attribute?","text":"<ul> <li> <p>Upon the instantiation of a <code>torchmeter.Meter</code> in combination with a <code>Pytorch</code> model, an automated scan of the model's architecture will be executed. Subsequently, a tree structure will be produced to depict the model. </p> </li> <li> <p>This tree structure is realized via <code>torchmeter.engine.OperationTree</code>. In this tree, each node is an instance of <code>torchmeter.engine.OperationNode</code>, which represents a layer or operation (such as <code>nn.Conv2d</code>, <code>nn.ReLU</code>, etc.) within the model. </p> </li> <li> <p>Therefore, the attributes of a tree node are the attributes / properties of an instance of <code>OperationNode</code>.</p> </li> </ul>"},{"location":"cheatsheet/#What-can-a-tree-node-attribute-help-me","title":"What can a tree node attribute help me?","text":"<p>All the attributes that are available, as defined below, are intended to:</p> <ul> <li>facilitate your acquisition of supplementary information of a tree node;</li> <li>customize of the display of the tree structure during the rendering procedure. </li> </ul>"},{"location":"cheatsheet/#What-are-the-available-attributes-of-a-tree-node","title":"What are the available attributes of a tree node?","text":"Illustrative Example Python<pre><code>from collections import OrderedDict\nimport torch.nn as nn\n\nclass SimpleModel(nn.Module):\n    def __init__(self):\n        super(SimpleModel, self).__init__()\n\n        self.single_1 = nn.Linear(1, 10)\n\n        self.repeat_1x2 = nn.Sequential(OrderedDict({\n            \"A\": nn.Linear(10, 10),\n            \"B\": nn.Linear(10, 10),\n        }))\n\n        self.single_2 = nn.ReLU()\n\n        self.repeat_2x3 = nn.Sequential(OrderedDict({\n            \"C\": nn.Linear(10, 5),\n            \"D\": nn.ReLU(),\n            \"E\": nn.Linear(5, 10),\n\n            \"F\": nn.Linear(10, 5),\n            \"G\": nn.ReLU(),\n            \"H\": nn.Linear(5, 10),\n\n            \"I\": nn.Linear(10, 5),\n            \"J\": nn.ReLU(),\n            \"K\": nn.Linear(5, 10),\n        }))\n\n        self.single_3 = nn.Linear(10, 1)\n</code></pre> <p>Taking the above model as an example, the values of each attribute in each layer are as follows:</p> name  ,  type  ,  node_id  ,  is_leaf  ,  operation  ,  module_repr node_id name type is_leaf operation module_repr <code>0</code> <code>SimpleModel</code> <code>SimpleModel</code> <code>False</code> instance created via <code>SimpleModel()</code> <code>SimpleModel</code> <code>1</code> <code>single_1</code> <code>Linear</code> <code>True</code> instance created via <code>nn.Linear(1, 10)</code> in line <code>8</code> <code>Linear(in_features=1, out_features=10, bias=True)</code> <code>2</code> <code>repeat_1x2</code> <code>Sequential</code> <code>False</code> instance created via <code>nn.Sequential</code> in line <code>10</code> <code>Sequential</code> <code>2.1</code> <code>A</code> <code>Linear</code> <code>True</code> instance created via <code>nn.Linear(10, 10)</code> in line <code>11</code> <code>Linear(in_features=10, out_features=10, bias=True)</code> <code>2.2</code> <code>B</code> <code>Linear</code> <code>True</code> instance created via <code>nn.Linear(10, 10)</code> in line <code>12</code> <code>Linear(in_features=10, out_features=10, bias=True)</code> <code>3</code> <code>single_2</code> <code>ReLU</code> <code>True</code> instance created via <code>nn.ReLU()</code> in line <code>15</code> <code>ReLU()</code> <code>4</code> <code>repeat_2x3</code> <code>Sequential</code> <code>False</code> instance created via <code>nn.Sequential</code> in line <code>17</code> <code>Sequential</code> <code>4.1</code> <code>C</code> <code>Linear</code> <code>True</code> instance created via <code>nn.Linear(10, 5)</code> in line <code>18</code> <code>Linear(in_features=10, out_features=5, bias=True)</code> <code>4.2</code> <code>D</code> <code>ReLU</code> <code>True</code> instance created via <code>nn.ReLU()</code> in line <code>19</code> <code>ReLU()</code> <code>4.3</code> <code>E</code> <code>Linear</code> <code>True</code> instance created via <code>nn.Linear(5, 10)</code> in line <code>20</code> <code>Linear(in_features=5, out_features=10, bias=True)</code> <code>4.4</code> <code>F</code> <code>Linear</code> <code>True</code> instance created via <code>nn.Linear(10, 5)</code> in line <code>22</code> <code>Linear(in_features=10, out_features=5, bias=True)</code> <code>4.5</code> <code>G</code> <code>ReLU</code> <code>True</code> instance created via <code>nn.ReLU()</code> in line <code>23</code> <code>ReLU()</code> <code>4.6</code> <code>H</code> <code>Linear</code> <code>True</code> instance created via <code>nn.Linear(5, 10)</code> in line <code>24</code> <code>Linear(in_features=5, out_features=10, bias=True)</code> <code>4.7</code> <code>I</code> <code>Linear</code> <code>True</code> instance created via <code>nn.Linear(10, 5)</code> in line <code>26</code> <code>Linear(in_features=10, out_features=5, bias=True)</code> <code>4.8</code> <code>J</code> <code>ReLU</code> <code>True</code> instance created via <code>nn.ReLU()</code> in line <code>27</code> <code>ReLU()</code> <code>4.9</code> <code>K</code> <code>Linear</code> <code>True</code> instance created via <code>nn.Linear(5, 10)</code> in line <code>28</code> <code>Linear(in_features=5, out_features=10, bias=True)</code> <code>5</code> <code>single_3</code> <code>Linear</code> <code>True</code> instance created via <code>nn.Linear(10, 1)</code> in line <code>31</code> <code>Linear(in_features=10, out_features=1, bias=True)</code> parent &amp; childs <p>Here we use the node id of the parent and childs of each node to simplify the display.   In actual uage, a node's <code>parent</code> is <code>None</code> or an instance of <code>torchmeter.engine.OperationNode</code>;    while the <code>childs</code> is an orderdict with node id as key and the node instance as value.</p> node_id name type parent childs <code>0</code> <code>SimpleModel</code> <code>SimpleModel</code> <code>None</code> <code>1 ~ 5</code> <code>1</code> <code>single_1</code> <code>Linear</code> <code>0</code> <code>2</code> <code>repeat_1x2</code> <code>Sequential</code> <code>0</code> <code>2.1, 2.2</code> <code>2.1</code> <code>A</code> <code>Linear</code> <code>2</code> <code>2.2</code> <code>B</code> <code>Linear</code> <code>2</code> <code>3</code> <code>single_2</code> <code>ReLU</code> <code>0</code> <code>4</code> <code>repeat_2x3</code> <code>Sequential</code> <code>0</code> <code>4.1 ~ 4.9</code> <code>4.1</code> <code>C</code> <code>Linear</code> <code>4</code> <code>4.2</code> <code>D</code> <code>ReLU</code> <code>4</code> <code>4.3</code> <code>E</code> <code>Linear</code> <code>4</code> <code>4.4</code> <code>F</code> <code>Linear</code> <code>4</code> <code>4.5</code> <code>G</code> <code>ReLU</code> <code>4</code> <code>4.6</code> <code>H</code> <code>Linear</code> <code>4</code> <code>4.7</code> <code>I</code> <code>Linear</code> <code>4</code> <code>4.8</code> <code>J</code> <code>ReLU</code> <code>4</code> <code>4.9</code> <code>K</code> <code>Linear</code> <code>4</code> <code>5</code> <code>single_3</code> <code>Linear</code> <code>0</code> repeat_winsz &amp; repeat_time node_id name type repeat_winsz repeat_time explanation <code>0</code> <code>SimpleModel</code> <code>SimpleModel</code> <code>1</code> <code>1</code> no repeatition <code>1</code> <code>single_1</code> <code>Linear</code> <code>1</code> <code>1</code> no repeatition <code>2</code> <code>repeat_1x2</code> <code>Sequential</code> <code>1</code> <code>1</code> no repeatition <code>2.1</code> <code>A</code> <code>Linear</code> 1 2 Repeating windows cover <code>2.1</code> and <code>2.2</code>. The two layers have the same definition, so it can be considered that one module is repeated twice <code>2.2</code> <code>B</code> <code>Linear</code> <code>1</code> <code>1</code> Have been included in a repeating window. So skip repetitiveness analysis and use default values. <code>3</code> <code>single_2</code> <code>ReLU</code> <code>1</code> <code>1</code> no repeatition <code>4</code> <code>repeat_2x3</code> <code>Sequential</code> <code>1</code> <code>1</code> no repeatition <code>4.1</code> <code>C</code> <code>Linear</code> 3 3 Repeating windows taking <code>4.1 ~ 4.3</code> as a whole and cover <code>4.1 ~ 4.9</code>. <code>4.2</code> <code>D</code> <code>ReLU</code> <code>1</code> <code>1</code> Have been included in a repeating window. So skip repetitiveness analysis and use default values. <code>4.3</code> <code>E</code> <code>Linear</code> <code>1</code> <code>1</code> Have been included in a repeating window. So skip repetitiveness analysis and use default values. <code>4.4</code> <code>F</code> <code>Linear</code> <code>1</code> <code>1</code> Have been included in a repeating window. So skip repetitiveness analysis and use default values. <code>4.5</code> <code>G</code> <code>ReLU</code> <code>1</code> <code>1</code> Have been included in a repeating window. So skip repetitiveness analysis and use default values. <code>4.6</code> <code>H</code> <code>Linear</code> <code>1</code> <code>1</code> Have been included in a repeating window. So skip repetitiveness analysis and use default values. <code>4.7</code> <code>I</code> <code>Linear</code> <code>1</code> <code>1</code> Have been included in a repeating window. So skip repetitiveness analysis and use default values. <code>4.8</code> <code>J</code> <code>ReLU</code> <code>1</code> <code>1</code> Have been included in a repeating window. So skip repetitiveness analysis and use default values. <code>4.9</code> <code>K</code> <code>Linear</code> <code>1</code> <code>1</code> Have been included in a repeating window. So skip repetitiveness analysis and use default values. <code>5</code> <code>single_3</code> <code>Linear</code> <code>1</code> <code>1</code> no repeatition Attribute Type Explanation <code>operation</code> <code>torch.nn.Module</code> The underlying pytorch module <code>type</code> <code>str</code> The operation type. If the operation is a pytorch module, use the name of its class <code>name</code> <code>str</code> The module name defined in the underlying pytorch model <code>node_id</code> <code>str</code> A globally unique module identifier, formatted as <code>&lt;parent-node-identifier&gt;.&lt;current-level-index&gt;</code>. The index commences from <code>1</code>, cause the root is denoted as <code>0</code> <code>is_leaf</code> <code>bool</code> Whether the node is a leaf node (no child nodes) <code>module_repr</code> <code>str</code> The text representation of the current operation. For non-leaf nodes, it's the ndoe type. Conversely, it is the return of <code>__repr__()</code> method <code>parent</code> <code>torchmeter.engine.OperationNode</code> The parent node of this node. Each node has only one parent <code>childs</code> <code>OrderDict[str,  OperationNode]</code> An orderdict storing children of this node in feed-forward order. Key is <code>node_id</code> of child, value is the child node itself. <code>repeat_winsz</code> <code>int</code> The size of the repeating window for the current node. Default is 1, meaning no repetition (window has only the node itself) <code>repeat_time</code> <code>int</code> The number of repetitions of the window where the current module is located. Default is 1, meaning no repetition"},{"location":"cheatsheet/#How-to-use-the-attributes-of-a-tree-node","title":"How to use the attributes of a tree node?","text":"<p>In the scenarios described below, an attribute of a tree node can be utilized as a placeholder,  which enables the dynamic retrieval of its value during the tree-rendering process.</p> Global Configuration <p>About the <code>&lt;level-index&gt;</code> shown below, please refer to Tree Level Index .</p> configuration default value <code>tree_repeat_block_args</code> <code>'[i]Repeat [[b]&lt;repeat_time&gt;[/b]] Times[/]'</code> <code>tree_levels_args.default.label</code> <code>'[b gray35](&lt;node_id&gt;) [green]&lt;name&gt;[/green] [cyan]&lt;type&gt;[/]'</code> <code>tree_levels_args.0.label</code> <code>'[b light_coral]&lt;name&gt;[/]'</code> <code>tree_levels_args.&lt;level-index&gt;.label</code> same as the <code>tree_levels_args.default.label</code> if not specified Repeat Block Footer <p>Please refer to Customize the footer for more details.</p>"},{"location":"cheatsheet/#Unit-Explanation","title":"Unit Explanation","text":"<p>There are four types of units in <code>torchmeter</code>, listed as follows:</p> <p>The <code>raw-data</code> tag in the subsequent content indicates that the unit marked with this tag is used in the <code>raw data</code> mode</p>  Counting Units Binary Storage Units Time Units Inference Speed Units <p>Used by <code>param</code>, <code>cal</code></p> unit explanation tag example <code>null</code> Number of subjects <code>raw-data</code> <code>5</code>: There are <code>5</code> semantic subjects <code>K</code> \\(10^3\\) <code>5 K</code>: There are <code>5,000</code> ... <code>M</code> \\(10^6\\) <code>5 M</code>: There are <code>5,000,000</code> ... <code>G</code> \\(10^9\\) <code>5 G</code>: There are <code>5,000,000,000</code> ... <code>T</code> \\(10^{12}\\) <code>5 T</code>: There are <code>5,000,000,000,000</code> ... <p>Used by <code>mem</code></p> unit explanation tag example <code>B</code> \\(2^0=1\\) bytes <code>raw-data</code> <code>5 B</code>: \\(5 \\times 1 = 5\\)  bytes <code>KiB</code> \\(2^{10}=1024\\) bytes <code>5 KiB</code>: \\(5 \\times 2^{10} = 5120\\)  bytes <code>MiB</code> \\(2^{20}\\) bytes <code>5 MiB</code>: \\(5 \\times 2^{20} = 5242880\\)  bytes <code>GiB</code> \\(2^{30}\\) bytes <code>5 GiB</code>: \\(5 \\times 2^{30} = 5368709120\\)  bytes <code>TiB</code> \\(2^{40}\\) bytes <code>5 TiB</code>: \\(5 \\times 2^{40} = 5497558138880\\)  bytes <p>Used by <code>ittp</code> - inference time</p> unit explanation tag example <code>ns</code> nanosecond <code>5 ns</code>: \\(5 \\times 10^{-9}\\)  seconds <code>us</code> microsecond <code>5 us</code>: \\(5 \\times 10^{-6}\\)  seconds <code>ms</code> millisecond <code>5 ms</code>: \\(5 \\times 10^{-3}\\)  seconds <code>s</code> second <code>raw-data</code> <code>5 s</code>: \\(5 \\times 10^{0}\\)  seconds <code>min</code> minute <code>5 min</code>: \\(5 \\times 60^{1}\\)  seconds <code>h</code> hour <code>5 h</code>: \\(5 \\times 60^{2}\\)  seconds <p>Used by <code>ittp</code> - throughput</p> unit explanation tag example <code>IPS</code> Input Per Second <code>raw-data</code> <code>5 IPS</code>: process <code>5</code> inputs per second <code>KIPS</code> \\(10^3\\) IPS <code>5 KIPS</code>: process <code>5,000</code> inputs per second <code>MIPS</code> \\(10^6\\) IPS <code>5 MIPS</code>: process <code>5,000,000</code> inputs per second <code>GIPS</code> \\(10^9\\) IPS <code>5 GIPS</code>: process <code>5,000,000,000</code> inputs per second <code>TIPS</code> \\(10^{12}\\) IPS <code>5 TIPS</code>: process <code>5,000,000,000,000</code> inputs per second"},{"location":"demo/","title":"Tutorials","text":"In\u00a0[55]: Copied! <pre># installation\n\n## pip install torchmeter\n</pre> # installation  ## pip install torchmeter In\u00a0[\u00a0]: Copied! <pre>from torchvision import models\nfrom torchmeter import Meter\n\nunderlying_model = models.vgg19_bn()\nmodel = Meter(underlying_model)\n</pre> from torchvision import models from torchmeter import Meter  underlying_model = models.vgg19_bn() model = Meter(underlying_model) <pre></pre> <pre>Finish Scanning model in 0.0146 seconds\n</pre> In\u00a0[57]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# underlying_model: Your pytorch model\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nimport random\n\nunderlying_items = random.sample(underlying_model.__dir__(), 3)\nprint(f\"These attributes/methods are accessible in the underlying model: \\n{underlying_items}\")\n\nfor i in underlying_items:\n    print(f\"If `{i}` can be accessed through `Meter` instance \u2014\u2014\", hasattr(model, i))\n</pre> # Context # -------------------------------------------------------------------------------- # underlying_model: Your pytorch model # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  import random  underlying_items = random.sample(underlying_model.__dir__(), 3) print(f\"These attributes/methods are accessible in the underlying model: \\n{underlying_items}\")  for i in underlying_items:     print(f\"If `{i}` can be accessed through `Meter` instance \u2014\u2014\", hasattr(model, i)) <pre>These attributes/methods are accessible in the underlying model: \n['_forward_hooks_always_called', 'bfloat16', '__repr__']\n</pre> <pre>If `_forward_hooks_always_called` can be accessed through `Meter` instance \u2014\u2014 True\n</pre> <pre>If `bfloat16` can be accessed through `Meter` instance \u2014\u2014 True\n</pre> <pre>If `__repr__` can be accessed through `Meter` instance \u2014\u2014 True\n</pre> In\u00a0[58]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(f\"Model now on: {model.device}\")\nprint(f\"The number of benchmark iterations per operation in measuring `ittp` is {model.ittp_benchmark_time}\")\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(f\"Model now on: {model.device}\") print(f\"The number of benchmark iterations per operation in measuring `ittp` is {model.ittp_benchmark_time}\") <pre>Model now on: cpu\n</pre> <pre>The number of benchmark iterations per operation in measuring `ittp` is 100\n</pre> In\u00a0[\u00a0]: Copied! <pre>from torchvision import models\nfrom torchmeter import Meter\n\nunderlying_model = models.vgg19_bn()\n\n# Suppose your model happens to have an attribute named `ittp_warmup`, \n# which conflicts with an attribute of the Meter class in terms of name.\nunderlying_model.ittp_warmup = 55\n\n# Access the `ittp_warmup` attribute of the Meter class\nmodel = Meter(underlying_model)\nmodel.ittp_warmup = 66\nprint(f\"The `ittp_warmup` attribute of the Meter class is {model.ittp_warmup}\")\n\n# Access the `ittp_warmup` attribute of the underlying model through `ORIGIN_` prefix\nprint(f\"The `ittp_warmup` attribute of the underlying model is {model.ORIGIN_ittp_warmup}\")\n</pre> from torchvision import models from torchmeter import Meter  underlying_model = models.vgg19_bn()  # Suppose your model happens to have an attribute named `ittp_warmup`,  # which conflicts with an attribute of the Meter class in terms of name. underlying_model.ittp_warmup = 55  # Access the `ittp_warmup` attribute of the Meter class model = Meter(underlying_model) model.ittp_warmup = 66 print(f\"The `ittp_warmup` attribute of the Meter class is {model.ittp_warmup}\")  # Access the `ittp_warmup` attribute of the underlying model through `ORIGIN_` prefix print(f\"The `ittp_warmup` attribute of the underlying model is {model.ORIGIN_ittp_warmup}\") <pre></pre> <pre>Finish Scanning model in 0.0159 seconds\n</pre> <pre>The `ittp_warmup` attribute of the Meter class is 66\n</pre> <pre>The `ittp_warmup` attribute of the underlying model is 55\n</pre> In\u00a0[60]: Copied! <pre>import torch\nfrom torchmeter import Meter\nfrom torchvision import models\n\nmodel = Meter(models.vgg19_bn())\ninput = torch.randn(1, 3, 224, 224)\n\n# move to GPU if available\nif torch.cuda.is_available():\n    model.device = \"cuda:0\"\n    print(f\"The model now on: {model.device}, The input now on {input.device}\")\n    output = model(input)\nelse:\n    print(f\"The model now on: {model.device}, The input now on {input.device}\")\n    output = model(input)\n\nprint(\"Inference done !\")\n</pre> import torch from torchmeter import Meter from torchvision import models  model = Meter(models.vgg19_bn()) input = torch.randn(1, 3, 224, 224)  # move to GPU if available if torch.cuda.is_available():     model.device = \"cuda:0\"     print(f\"The model now on: {model.device}, The input now on {input.device}\")     output = model(input) else:     print(f\"The model now on: {model.device}, The input now on {input.device}\")     output = model(input)  print(\"Inference done !\") <pre></pre> <pre>Finish Scanning model in 0.0121 seconds\n</pre> <pre>The model now on: cuda:0, The input now on cpu\n</pre> <pre>Inference done !\n</pre> In\u00a0[61]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nfrom rich import print\n\n# default value is True\nmodel.tree_fold_repeat = True\nprint(model.structure)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  from rich import print  # default value is True model.tree_fold_repeat = True print(model.structure) <pre>VGG\n\u251c\u2500\u2500 (1) features Sequential\n\u2502   \u251c\u2500\u2500 (1.1) 0 Conv2d\n\u2502   \u251c\u2500\u2500 (1.2) 1 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.3) 2 ReLU\n\u2502   \u251c\u2500\u2500 (1.4) 3 Conv2d\n\u2502   \u251c\u2500\u2500 (1.5) 4 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.6) 5 ReLU\n\u2502   \u251c\u2500\u2500 (1.7) 6 MaxPool2d\n\u2502   \u251c\u2500\u2500 (1.8) 7 Conv2d\n\u2502   \u251c\u2500\u2500 (1.9) 8 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.10) 9 ReLU\n\u2502   \u251c\u2500\u2500 (1.11) 10 Conv2d\n\u2502   \u251c\u2500\u2500 (1.12) 11 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.13) 12 ReLU\n\u2502   \u251c\u2500\u2500 (1.14) 13 MaxPool2d\n\u2502   \u251c\u2500\u2500 (1.15) 14 Conv2d\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501 Repeat [3] Times \u2501\u2501\u2501\u2501\u2513\n\u2502   \u2502   \u2503 (1.x) 15 BatchNorm2d     \u2503\n\u2502   \u2502   \u2503 (1.(x+1)) 16 ReLU        \u2503\n\u2502   \u2502   \u2503 (1.(x+2)) 17 Conv2d      \u2503\n\u2502   \u2502   \u2503 ------------------------ \u2503\n\u2502   \u2502   \u2503 Where x = 16, 19, 22     \u2503\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\u2502   \u251c\u2500\u2500 (1.25) 24 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.26) 25 ReLU\n\u2502   \u251c\u2500\u2500 (1.27) 26 MaxPool2d\n\u2502   \u251c\u2500\u2500 (1.28) 27 Conv2d\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501 Repeat [3] Times \u2501\u2501\u2501\u2501\u2513\n\u2502   \u2502   \u2503 (1.y) 28 BatchNorm2d     \u2503\n\u2502   \u2502   \u2503 (1.(y+1)) 29 ReLU        \u2503\n\u2502   \u2502   \u2503 (1.(y+2)) 30 Conv2d      \u2503\n\u2502   \u2502   \u2503 ------------------------ \u2503\n\u2502   \u2502   \u2503 Where y = 29, 32, 35     \u2503\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\u2502   \u251c\u2500\u2500 (1.38) 37 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.39) 38 ReLU\n\u2502   \u251c\u2500\u2500 (1.40) 39 MaxPool2d\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501\u2501\u2501 Repeat [2] Times \u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2502   \u2502   \u2503 (1.i) 40 Conv2d              \u2503\n\u2502   \u2502   \u2503 (1.(i+1)) 41 BatchNorm2d     \u2503\n\u2502   \u2502   \u2503 (1.(i+2)) 42 ReLU            \u2503\n\u2502   \u2502   \u2503 (1.(i+3)) 43 Conv2d          \u2503\n\u2502   \u2502   \u2503 (1.(i+4)) 44 BatchNorm2d     \u2503\n\u2502   \u2502   \u2503 (1.(i+5)) 45 ReLU            \u2503\n\u2502   \u2502   \u2503 ---------------------------- \u2503\n\u2502   \u2502   \u2503 Where i = 41, 47             \u2503\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\u2502   \u2514\u2500\u2500 (1.53) 52 MaxPool2d\n\u251c\u2500\u2500 (2) avgpool AdaptiveAvgPool2d\n\u2514\u2500\u2500 (3) classifier Sequential\n    \u251c\u2500\u2500 (3.1) 0 Linear\n    \u251c\u2500\u2500 (3.2) 1 ReLU\n    \u251c\u2500\u2500 (3.3) 2 Dropout\n    \u251c\u2500\u2500 (3.4) 3 Linear\n    \u251c\u2500\u2500 (3.5) 4 ReLU\n    \u251c\u2500\u2500 (3.6) 5 Dropout\n    \u2514\u2500\u2500 (3.7) 6 Linear\n</pre> In\u00a0[62]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nfrom rich import print\n\n# If disable, the output will directly reflect the model structure, \n# and may be verbose and not clear when there exists repetitive structure.\n# If there are no repetitive structure in your model, there will be no difference whether it is enabled or not.\nmodel.tree_fold_repeat = False\nprint(model.structure)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  from rich import print  # If disable, the output will directly reflect the model structure,  # and may be verbose and not clear when there exists repetitive structure. # If there are no repetitive structure in your model, there will be no difference whether it is enabled or not. model.tree_fold_repeat = False print(model.structure) <pre>VGG\n\u251c\u2500\u2500 (1) features Sequential\n\u2502   \u251c\u2500\u2500 (1.1) 0 Conv2d\n\u2502   \u251c\u2500\u2500 (1.2) 1 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.3) 2 ReLU\n\u2502   \u251c\u2500\u2500 (1.4) 3 Conv2d\n\u2502   \u251c\u2500\u2500 (1.5) 4 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.6) 5 ReLU\n\u2502   \u251c\u2500\u2500 (1.7) 6 MaxPool2d\n\u2502   \u251c\u2500\u2500 (1.8) 7 Conv2d\n\u2502   \u251c\u2500\u2500 (1.9) 8 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.10) 9 ReLU\n\u2502   \u251c\u2500\u2500 (1.11) 10 Conv2d\n\u2502   \u251c\u2500\u2500 (1.12) 11 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.13) 12 ReLU\n\u2502   \u251c\u2500\u2500 (1.14) 13 MaxPool2d\n\u2502   \u251c\u2500\u2500 (1.15) 14 Conv2d\n\u2502   \u251c\u2500\u2500 (1.16) 15 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.17) 16 ReLU\n\u2502   \u251c\u2500\u2500 (1.18) 17 Conv2d\n\u2502   \u251c\u2500\u2500 (1.19) 18 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.20) 19 ReLU\n\u2502   \u251c\u2500\u2500 (1.21) 20 Conv2d\n\u2502   \u251c\u2500\u2500 (1.22) 21 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.23) 22 ReLU\n\u2502   \u251c\u2500\u2500 (1.24) 23 Conv2d\n\u2502   \u251c\u2500\u2500 (1.25) 24 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.26) 25 ReLU\n\u2502   \u251c\u2500\u2500 (1.27) 26 MaxPool2d\n\u2502   \u251c\u2500\u2500 (1.28) 27 Conv2d\n\u2502   \u251c\u2500\u2500 (1.29) 28 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.30) 29 ReLU\n\u2502   \u251c\u2500\u2500 (1.31) 30 Conv2d\n\u2502   \u251c\u2500\u2500 (1.32) 31 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.33) 32 ReLU\n\u2502   \u251c\u2500\u2500 (1.34) 33 Conv2d\n\u2502   \u251c\u2500\u2500 (1.35) 34 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.36) 35 ReLU\n\u2502   \u251c\u2500\u2500 (1.37) 36 Conv2d\n\u2502   \u251c\u2500\u2500 (1.38) 37 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.39) 38 ReLU\n\u2502   \u251c\u2500\u2500 (1.40) 39 MaxPool2d\n\u2502   \u251c\u2500\u2500 (1.41) 40 Conv2d\n\u2502   \u251c\u2500\u2500 (1.42) 41 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.43) 42 ReLU\n\u2502   \u251c\u2500\u2500 (1.44) 43 Conv2d\n\u2502   \u251c\u2500\u2500 (1.45) 44 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.46) 45 ReLU\n\u2502   \u251c\u2500\u2500 (1.47) 46 Conv2d\n\u2502   \u251c\u2500\u2500 (1.48) 47 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.49) 48 ReLU\n\u2502   \u251c\u2500\u2500 (1.50) 49 Conv2d\n\u2502   \u251c\u2500\u2500 (1.51) 50 BatchNorm2d\n\u2502   \u251c\u2500\u2500 (1.52) 51 ReLU\n\u2502   \u2514\u2500\u2500 (1.53) 52 MaxPool2d\n\u251c\u2500\u2500 (2) avgpool AdaptiveAvgPool2d\n\u2514\u2500\u2500 (3) classifier Sequential\n    \u251c\u2500\u2500 (3.1) 0 Linear\n    \u251c\u2500\u2500 (3.2) 1 ReLU\n    \u251c\u2500\u2500 (3.3) 2 Dropout\n    \u251c\u2500\u2500 (3.4) 3 Linear\n    \u251c\u2500\u2500 (3.5) 4 ReLU\n    \u251c\u2500\u2500 (3.6) 5 Dropout\n    \u2514\u2500\u2500 (3.7) 6 Linear\n</pre> In\u00a0[\u00a0]: Copied! <pre># To better show the feature of measuring total/learnable parameter numbers,    \n# we assume that the `features` part of the underlying model is frozen.\n\n_ = model.features.requires_grad_(False)\n</pre> # To better show the feature of measuring total/learnable parameter numbers,     # we assume that the `features` part of the underlying model is frozen.  _ = model.features.requires_grad_(False) In\u00a0[64]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(model.model_info)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(model.model_info) <pre>\u2022 Model    : VGG\n\u2022 Device   : cuda:0\n\u2022 Signature: forward(self, x)\n\u2022 Input    : \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;\n</pre> In\u00a0[65]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(model.overview())\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(model.overview()) <pre>Warming Up: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [00:00&lt;00:00, 330.15it/s]\nBenchmark Inference Time &amp; Throughput: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6400/6400 [00:00&lt;00:00, 6582.64module/s] \n</pre> <pre>            \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Model INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Param INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500      \n             \u2022 Model    : VGG                                           \u2022 Statistics: param                        \n             \u2022 Device   : cuda:0                                        \u2022 Learnable Parameters Num: 123.64 M       \n             \u2022 Signature: forward(self, x)                              \u2022 Total Parameters Num    : 143.68 M       \n             \u2022 Input    :                                              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500      \n                x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                                                               \n            \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                              \n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Cal INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Mem INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \n  \u2022 Statistics: cal                                                 \u2022 Statistics: mem                              \n  \u2022 FLOPs               : 39.34 G                                   \u2022 Parameters Memory Cost: 548.09 MiB, 82.12 %  \n  \u2022 MACs(aka MACC, MADD): 19.68 G                                   \u2022 Buffers Memory Cost   : 43.12 KiB, 0.01 %    \n  \u26a0  Warning: the result may be inaccurate, cause:                  \u2022 FeatureMap Memory Cost: 119.31 MiB, 17.88 %  \n    \u25b6  Some modules don't support calculation measurement yet.      \u2022 Total Memory Cost     : 667.44 MiB           \n    \u2611  use `Meter(your_model).profile('cal')` to see more.         \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                    \n           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Ittp INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                             \n            \u2022 Statistics: ittp                                                                                     \n            \u2022 Benchmark Times: 100                                                                                 \n            \u2022 Inference Elapse: 2.05 ms \u00b1 19.06 us                                                                 \n            \u2022 Throughput      : 488.77 IPS \u00b1 4.55 IPS                                                              \n           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                             \n</pre> In\u00a0[\u00a0]: Copied! <pre># This block is to disable the interval output to adapt to Jupyter Notebook output limits\n# In your daily use, you are not required to do this unless you do want to ban the output annimation.\n# This section is using the global configuration, which we will be discussed in section H of this tutorial.\n\nfrom torchmeter import get_config\n\ncfg = get_config()\ncfg.restore()\n\n## Disable interval output to adapt to Jupyter Notebook\ncfg.render_interval = 0\n</pre> # This block is to disable the interval output to adapt to Jupyter Notebook output limits # In your daily use, you are not required to do this unless you do want to ban the output annimation. # This section is using the global configuration, which we will be discussed in section H of this tutorial.  from torchmeter import get_config  cfg = get_config() cfg.restore()  ## Disable interval output to adapt to Jupyter Notebook cfg.render_interval = 0 In\u00a0[67]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(\"=\"*10, \" Overall Report \", \"=\"*10)\n\n# Total/trainable parameter quantification\nprint(model.param)  \n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(\"=\"*10, \" Overall Report \", \"=\"*10)  # Total/trainable parameter quantification print(model.param)   <pre>==========  Overall Report  ==========\n</pre> <pre>Params_INFO\n\u2022     Operation_Id = 0\n\u2022   Operation_Name = VGG\n\u2022   Operation_Type = VGG\n\u2022     Total_Params = 143678248.00 = 143.68 M\n\u2022 Learnable_Params = 123642856.00 = 123.64 M\n\n</pre> In\u00a0[\u00a0]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(\"=\"*10, \" Layer-wise Profile \", \"=\"*10)\n\n# Layer-wise parameter distribution analysis\n# Note that the data for each layer is only statistically analyzed for that layer and does not include sub-layers \u2757\u2757\u2757\ntb, data = model.profile('param', no_tree=True)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(\"=\"*10, \" Layer-wise Profile \", \"=\"*10)  # Layer-wise parameter distribution analysis # Note that the data for each layer is only statistically analyzed for that layer and does not include sub-layers \u2757\u2757\u2757 tb, data = model.profile('param', no_tree=True) <pre>==========  Layer-wise Profile  ==========\n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Operation_Id \u2502 Operation_Name \u2502  Operation_Type   \u2502 Param_Name \u2502 Requires_Grad \u2502 Numeric_Num \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      1       \u2502    features    \u2502    Sequential     \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.1      \u2502       0        \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   1.73 K    \u2502\n\u2502     1.1      \u2502       0        \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    64.00    \u2502\n\u2502     1.2      \u2502       1        \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    64.00    \u2502\n\u2502     1.2      \u2502       1        \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    64.00    \u2502\n\u2502     1.3      \u2502       2        \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.4      \u2502       3        \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   36.86 K   \u2502\n\u2502     1.4      \u2502       3        \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    64.00    \u2502\n\u2502     1.5      \u2502       4        \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    64.00    \u2502\n\u2502     1.5      \u2502       4        \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    64.00    \u2502\n\u2502     1.6      \u2502       5        \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.7      \u2502       6        \u2502     MaxPool2d     \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.8      \u2502       7        \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   73.73 K   \u2502\n\u2502     1.8      \u2502       7        \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   128.00    \u2502\n\u2502     1.9      \u2502       8        \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   128.00    \u2502\n\u2502     1.9      \u2502       8        \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   128.00    \u2502\n\u2502     1.10     \u2502       9        \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.11     \u2502       10       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  147.46 K   \u2502\n\u2502     1.11     \u2502       10       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   128.00    \u2502\n\u2502     1.12     \u2502       11       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   128.00    \u2502\n\u2502     1.12     \u2502       11       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   128.00    \u2502\n\u2502     1.13     \u2502       12       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.14     \u2502       13       \u2502     MaxPool2d     \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.15     \u2502       14       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  294.91 K   \u2502\n\u2502     1.15     \u2502       14       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   256.00    \u2502\n\u2502     1.16     \u2502       15       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   256.00    \u2502\n\u2502     1.16     \u2502       15       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   256.00    \u2502\n\u2502     1.17     \u2502       16       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.18     \u2502       17       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  589.82 K   \u2502\n\u2502     1.18     \u2502       17       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   256.00    \u2502\n\u2502     1.19     \u2502       18       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   256.00    \u2502\n\u2502     1.19     \u2502       18       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   256.00    \u2502\n\u2502     1.20     \u2502       19       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.21     \u2502       20       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  589.82 K   \u2502\n\u2502     1.21     \u2502       20       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   256.00    \u2502\n\u2502     1.22     \u2502       21       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   256.00    \u2502\n\u2502     1.22     \u2502       21       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   256.00    \u2502\n\u2502     1.23     \u2502       22       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.24     \u2502       23       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  589.82 K   \u2502\n\u2502     1.24     \u2502       23       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   256.00    \u2502\n\u2502     1.25     \u2502       24       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   256.00    \u2502\n\u2502     1.25     \u2502       24       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   256.00    \u2502\n\u2502     1.26     \u2502       25       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.27     \u2502       26       \u2502     MaxPool2d     \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.28     \u2502       27       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   1.18 M    \u2502\n\u2502     1.28     \u2502       27       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.29     \u2502       28       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   512.00    \u2502\n\u2502     1.29     \u2502       28       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.30     \u2502       29       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.31     \u2502       30       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   2.36 M    \u2502\n\u2502     1.31     \u2502       30       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.32     \u2502       31       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   512.00    \u2502\n\u2502     1.32     \u2502       31       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.33     \u2502       32       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.34     \u2502       33       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   2.36 M    \u2502\n\u2502     1.34     \u2502       33       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.35     \u2502       34       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   512.00    \u2502\n\u2502     1.35     \u2502       34       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.36     \u2502       35       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.37     \u2502       36       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   2.36 M    \u2502\n\u2502     1.37     \u2502       36       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.38     \u2502       37       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   512.00    \u2502\n\u2502     1.38     \u2502       37       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.39     \u2502       38       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.40     \u2502       39       \u2502     MaxPool2d     \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.41     \u2502       40       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   2.36 M    \u2502\n\u2502     1.41     \u2502       40       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.42     \u2502       41       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   512.00    \u2502\n\u2502     1.42     \u2502       41       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.43     \u2502       42       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.44     \u2502       43       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   2.36 M    \u2502\n\u2502     1.44     \u2502       43       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.45     \u2502       44       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   512.00    \u2502\n\u2502     1.45     \u2502       44       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.46     \u2502       45       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.47     \u2502       46       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   2.36 M    \u2502\n\u2502     1.47     \u2502       46       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.48     \u2502       47       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   512.00    \u2502\n\u2502     1.48     \u2502       47       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.49     \u2502       48       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.50     \u2502       49       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   2.36 M    \u2502\n\u2502     1.50     \u2502       49       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.51     \u2502       50       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502   512.00    \u2502\n\u2502     1.51     \u2502       50       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502   512.00    \u2502\n\u2502     1.52     \u2502       51       \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     1.53     \u2502       52       \u2502     MaxPool2d     \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502      2       \u2502    avgpool     \u2502 AdaptiveAvgPool2d \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502      3       \u2502   classifier   \u2502    Sequential     \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     3.1      \u2502       0        \u2502      Linear       \u2502   weight   \u2502     True      \u2502  102.76 M   \u2502\n\u2502     3.1      \u2502       0        \u2502      Linear       \u2502    bias    \u2502     True      \u2502   4.10 K    \u2502\n\u2502     3.2      \u2502       1        \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     3.3      \u2502       2        \u2502      Dropout      \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     3.4      \u2502       3        \u2502      Linear       \u2502   weight   \u2502     True      \u2502   16.78 M   \u2502\n\u2502     3.4      \u2502       3        \u2502      Linear       \u2502    bias    \u2502     True      \u2502   4.10 K    \u2502\n\u2502     3.5      \u2502       4        \u2502       ReLU        \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     3.6      \u2502       5        \u2502      Dropout      \u2502     -      \u2502       -       \u2502    0.00     \u2502\n\u2502     3.7      \u2502       6        \u2502      Linear       \u2502   weight   \u2502     True      \u2502   4.10 M    \u2502\n\u2502     3.7      \u2502       6        \u2502      Linear       \u2502    bias    \u2502     True      \u2502     1 K     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n---------------------------------------- s u m m a r y -----------------------------------------\n\u2022 Model    : VGG                                   \u2022 Statistics: param                          \n\u2022 Device   : cuda:0                                \u2022 Learnable Parameters Num: 123.64 M         \n\u2022 Signature: forward(self, x)                      \u2022 Total Parameters Num    : 143.68 M         \n\u2022 Input    :                                                                                    \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                                                         \n</pre> In\u00a0[69]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\n# give a feed-forward\n# highly recommend to use a single batch to make the result comparable to the other model\nimport torch\ninput = torch.randn(1, 3, 224, 224)\noutput = model(input)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  # give a feed-forward # highly recommend to use a single batch to make the result comparable to the other model import torch input = torch.randn(1, 3, 224, 224) output = model(input) In\u00a0[\u00a0]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(\"=\"*10, \" Overall Report \", \"=\"*10)\n\n# FLOPs/MACs measurement\nprint(model.cal)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(\"=\"*10, \" Overall Report \", \"=\"*10)  # FLOPs/MACs measurement print(model.cal) <pre>==========  Overall Report  ==========\n</pre> <pre>Calculation_INFO\n\u2022   Operation_Id = 0\n\u2022 Operation_Type = VGG\n\u2022 Operation_Name = VGG\n\u2022           MACs = 19681218048.00 = 19.68 G\n\u2022          FLOPs = 39342984704.00 = 39.34 G\n\n</pre> In\u00a0[\u00a0]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(\"=\"*10, \" Layer-wise Profile \", \"=\"*10)\n\n# Operation-wise calculation distribution analysis\n# Different from `param`, the value of each operation is taking its sub-operation into account.\ntb, data = model.profile('cal', no_tree=True)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(\"=\"*10, \" Layer-wise Profile \", \"=\"*10)  # Operation-wise calculation distribution analysis # Different from `param`, the value of each operation is taking its sub-operation into account. tb, data = model.profile('cal', no_tree=True) <pre>==========  Layer-wise Profile  ==========\n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Operation_ \u2502 Operation_ \u2502 Operation_ \u2502 Kernel_Siz \u2502      \u2502            \u2502            \u2502             \u2502            \u2502\n\u2502     Id     \u2502    Name    \u2502    Type    \u2502     e      \u2502 Bias \u2502   Input    \u2502   Output   \u2502    MACs     \u2502   FLOPs    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1      \u2502  features  \u2502 Sequential \u2502     -      \u2502  -   \u2502   [1, 3,   \u2502  [1, 512,  \u2502   19.56 G   \u2502  39.10 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 224, 224]  \u2502   7, 7]    \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.1     \u2502     0      \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502   [1, 3,   \u2502  [1, 64,   \u2502   86.70 M   \u2502  173.41 M  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 224, 224]  \u2502 224, 224]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.2     \u2502     1      \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 64,   \u2502  [1, 64,   \u2502   6.42 M    \u2502  12.85 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502 224, 224]  \u2502 224, 224]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.3     \u2502     2      \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 64,   \u2502  [1, 64,   \u2502   3.21 M    \u2502   3.21 M   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 224, 224]  \u2502 224, 224]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.4     \u2502     3      \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 64,   \u2502  [1, 64,   \u2502   1.85 G    \u2502   3.70 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 224, 224]  \u2502 224, 224]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.5     \u2502     4      \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 64,   \u2502  [1, 64,   \u2502   6.42 M    \u2502  12.85 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502 224, 224]  \u2502 224, 224]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.6     \u2502     5      \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 64,   \u2502  [1, 64,   \u2502   3.21 M    \u2502   3.21 M   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 224, 224]  \u2502 224, 224]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.7     \u2502     6      \u2502 MaxPool2d  \u2502   [2, 2]   \u2502  -   \u2502  [1, 64,   \u2502  [1, 64,   \u2502   2.41 M    \u2502   2.41 M   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 224, 224]  \u2502 112, 112]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.8     \u2502     7      \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 64,   \u2502  [1, 128,  \u2502  924.84 M   \u2502   1.85 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 112, 112]  \u2502 112, 112]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.9     \u2502     8      \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 128,  \u2502  [1, 128,  \u2502   3.21 M    \u2502   6.42 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502 112, 112]  \u2502 112, 112]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.10    \u2502     9      \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 128,  \u2502  [1, 128,  \u2502   1.61 M    \u2502   1.61 M   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 112, 112]  \u2502 112, 112]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.11    \u2502     10     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 128,  \u2502  [1, 128,  \u2502   1.85 G    \u2502   3.70 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 112, 112]  \u2502 112, 112]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.12    \u2502     11     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 128,  \u2502  [1, 128,  \u2502   3.21 M    \u2502   6.42 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502 112, 112]  \u2502 112, 112]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.13    \u2502     12     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 128,  \u2502  [1, 128,  \u2502   1.61 M    \u2502   1.61 M   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 112, 112]  \u2502 112, 112]  \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.14    \u2502     13     \u2502 MaxPool2d  \u2502   [2, 2]   \u2502  -   \u2502  [1, 128,  \u2502  [1, 128,  \u2502   1.20 M    \u2502   1.20 M   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502 112, 112]  \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.15    \u2502     14     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 128,  \u2502  [1, 256,  \u2502  924.84 M   \u2502   1.85 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.16    \u2502     15     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 256,  \u2502  [1, 256,  \u2502   1.61 M    \u2502   3.21 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.17    \u2502     16     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 256,  \u2502  [1, 256,  \u2502  802.82 K   \u2502  802.82 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.18    \u2502     17     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 256,  \u2502  [1, 256,  \u2502   1.85 G    \u2502   3.70 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.19    \u2502     18     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 256,  \u2502  [1, 256,  \u2502   1.61 M    \u2502   3.21 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.20    \u2502     19     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 256,  \u2502  [1, 256,  \u2502  802.82 K   \u2502  802.82 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.21    \u2502     20     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 256,  \u2502  [1, 256,  \u2502   1.85 G    \u2502   3.70 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.22    \u2502     21     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 256,  \u2502  [1, 256,  \u2502   1.61 M    \u2502   3.21 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.23    \u2502     22     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 256,  \u2502  [1, 256,  \u2502  802.82 K   \u2502  802.82 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.24    \u2502     23     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 256,  \u2502  [1, 256,  \u2502   1.85 G    \u2502   3.70 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.25    \u2502     24     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 256,  \u2502  [1, 256,  \u2502   1.61 M    \u2502   3.21 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.26    \u2502     25     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 256,  \u2502  [1, 256,  \u2502  802.82 K   \u2502  802.82 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  56, 56]   \u2502  56, 56]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.27    \u2502     26     \u2502 MaxPool2d  \u2502   [2, 2]   \u2502  -   \u2502  [1, 256,  \u2502  [1, 256,  \u2502  602.11 K   \u2502  602.11 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  56, 56]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.28    \u2502     27     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 256,  \u2502  [1, 512,  \u2502  924.84 M   \u2502   1.85 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.29    \u2502     28     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  802.82 K   \u2502   1.61 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.30    \u2502     29     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  401.41 K   \u2502  401.41 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.31    \u2502     30     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 512,  \u2502  [1, 512,  \u2502   1.85 G    \u2502   3.70 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.32    \u2502     31     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  802.82 K   \u2502   1.61 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.33    \u2502     32     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  401.41 K   \u2502  401.41 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.34    \u2502     33     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 512,  \u2502  [1, 512,  \u2502   1.85 G    \u2502   3.70 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.35    \u2502     34     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  802.82 K   \u2502   1.61 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.36    \u2502     35     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  401.41 K   \u2502  401.41 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.37    \u2502     36     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 512,  \u2502  [1, 512,  \u2502   1.85 G    \u2502   3.70 G   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.38    \u2502     37     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  802.82 K   \u2502   1.61 M   \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.39    \u2502     38     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  401.41 K   \u2502  401.41 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  28, 28]   \u2502  28, 28]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.40    \u2502     39     \u2502 MaxPool2d  \u2502   [2, 2]   \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  301.06 K   \u2502  301.06 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  28, 28]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.41    \u2502     40     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 512,  \u2502  [1, 512,  \u2502  462.42 M   \u2502  924.84 M  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.42    \u2502     41     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  200.70 K   \u2502  401.41 K  \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.43    \u2502     42     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  100.35 K   \u2502  100.35 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.44    \u2502     43     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 512,  \u2502  [1, 512,  \u2502  462.42 M   \u2502  924.84 M  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.45    \u2502     44     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  200.70 K   \u2502  401.41 K  \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.46    \u2502     45     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  100.35 K   \u2502  100.35 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.47    \u2502     46     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 512,  \u2502  [1, 512,  \u2502  462.42 M   \u2502  924.84 M  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.48    \u2502     47     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  200.70 K   \u2502  401.41 K  \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.49    \u2502     48     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  100.35 K   \u2502  100.35 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.50    \u2502     49     \u2502   Conv2d   \u2502   [3, 3]   \u2502 True \u2502  [1, 512,  \u2502  [1, 512,  \u2502  462.42 M   \u2502  924.84 M  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.51    \u2502     50     \u2502 BatchNorm2 \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  200.70 K   \u2502  401.41 K  \u2502\n\u2502            \u2502            \u2502     d      \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.52    \u2502     51     \u2502    ReLU    \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502  100.35 K   \u2502  100.35 K  \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  14, 14]   \u2502  14, 14]   \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    1.53    \u2502     52     \u2502 MaxPool2d  \u2502   [2, 2]   \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502   75.26 K   \u2502  75.26 K   \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502  14, 14]   \u2502   7, 7]    \u2502             \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     2      \u2502  avgpool   \u2502 AdaptiveAv \u2502     -      \u2502  -   \u2502  [1, 512,  \u2502  [1, 512,  \u2502     Not     \u2502    Not     \u2502\n\u2502            \u2502            \u2502  gPool2d   \u2502            \u2502      \u2502   7, 7]    \u2502   7, 7]    \u2502  Supported  \u2502 Supported  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     3      \u2502 classifier \u2502 Sequential \u2502     -      \u2502  -   \u2502 [1, 25088] \u2502 [1, 1000]  \u2502  123.64 M   \u2502  247.28 M  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    3.1     \u2502     0      \u2502   Linear   \u2502     -      \u2502 True \u2502 [1, 25088] \u2502 [1, 4096]  \u2502  102.76 M   \u2502  205.52 M  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    3.2     \u2502     1      \u2502    ReLU    \u2502     -      \u2502  -   \u2502 [1, 4096]  \u2502 [1, 4096]  \u2502   4.10 K    \u2502   4.10 K   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    3.3     \u2502     2      \u2502  Dropout   \u2502     -      \u2502  -   \u2502 [1, 4096]  \u2502 [1, 4096]  \u2502     Not     \u2502    Not     \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502            \u2502            \u2502  Supported  \u2502 Supported  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    3.4     \u2502     3      \u2502   Linear   \u2502     -      \u2502 True \u2502 [1, 4096]  \u2502 [1, 4096]  \u2502   16.78 M   \u2502  33.55 M   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    3.5     \u2502     4      \u2502    ReLU    \u2502     -      \u2502  -   \u2502 [1, 4096]  \u2502 [1, 4096]  \u2502   4.10 K    \u2502   4.10 K   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    3.6     \u2502     5      \u2502  Dropout   \u2502     -      \u2502  -   \u2502 [1, 4096]  \u2502 [1, 4096]  \u2502     Not     \u2502    Not     \u2502\n\u2502            \u2502            \u2502            \u2502            \u2502      \u2502            \u2502            \u2502  Supported  \u2502 Supported  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    3.7     \u2502     6      \u2502   Linear   \u2502     -      \u2502 True \u2502 [1, 4096]  \u2502 [1, 1000]  \u2502   4.10 M    \u2502   8.19 M   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n------------------------------------------------- s u m m a r y -------------------------------------------------\n\u2022 Model    : VGG                                                \u2022 Statistics: cal                                \n\u2022 Device   : cuda:0                                             \u2022 FLOPs               : 39.34 G                  \n\u2022 Signature: forward(self, x)                                   \u2022 MACs(aka MACC, MADD): 19.68 G                  \n\u2022 Input    :                                                                                                     \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                                                                          \n</pre> In\u00a0[72]: Copied! <pre># Give a feed-forward here if you have not yet.\n# We did it when measuring calculation, therefore we don't need to do it again\n</pre> # Give a feed-forward here if you have not yet. # We did it when measuring calculation, therefore we don't need to do it again In\u00a0[\u00a0]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(\"=\"*10, \" Overall Report \", \"=\"*10)\n\nprint(model.mem)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(\"=\"*10, \" Overall Report \", \"=\"*10)  print(model.mem) <pre>==========  Overall Report  ==========\n</pre> <pre>Memory_INFO\n\u2022   Operation_Id = 0\n\u2022 Operation_Type = VGG\n\u2022 Operation_Name = VGG\n\u2022     Param_Cost = 574712992.00 = 548.09 MiB\n\u2022    Buffer_Cost = 44160.00 = 43.12 KiB\n\u2022    Output_Cost = 125108128.00 = 119.31 MiB\n\u2022          Total = 699865280.00 = 667.44 MiB\n\n</pre> In\u00a0[\u00a0]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(\"=\"*10, \" Layer-wise Profile \", \"=\"*10)\n\n# Hierarchical memory consumption analysis\n# Same as `cal`, the value of each operation is taking its sub-operation into account\ntb, data = model.profile('mem', no_tree=True)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(\"=\"*10, \" Layer-wise Profile \", \"=\"*10)  # Hierarchical memory consumption analysis # Same as `cal`, the value of each operation is taking its sub-operation into account tb, data = model.profile('mem', no_tree=True) <pre>==========  Layer-wise Profile  ==========\n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Operation_Id \u2502 Operation_Name \u2502  Operation_Type   \u2502 Param_Cost \u2502 Buffer_Cost \u2502 Output_Cost \u2502   Total    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      1       \u2502    features    \u2502    Sequential     \u2502 76.43 MiB  \u2502  43.12 KiB  \u2502 119.15 MiB  \u2502 195.62 MiB \u2502\n\u2502     1.1      \u2502       0        \u2502      Conv2d       \u2502   7 KiB    \u2502      -      \u2502  12.25 MiB  \u2502 12.26 MiB  \u2502\n\u2502     1.2      \u2502       1        \u2502    BatchNorm2d    \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502     1.3      \u2502       2        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.4      \u2502       3        \u2502      Conv2d       \u2502 144.25 KiB \u2502      -      \u2502  12.25 MiB  \u2502 12.39 MiB  \u2502\n\u2502     1.5      \u2502       4        \u2502    BatchNorm2d    \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502     1.6      \u2502       5        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.7      \u2502       6        \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502  3.06 MiB   \u2502  3.06 MiB  \u2502\n\u2502     1.8      \u2502       7        \u2502      Conv2d       \u2502 288.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.41 MiB  \u2502\n\u2502     1.9      \u2502       8        \u2502    BatchNorm2d    \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502     1.10     \u2502       9        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.11     \u2502       10       \u2502      Conv2d       \u2502 576.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.69 MiB  \u2502\n\u2502     1.12     \u2502       11       \u2502    BatchNorm2d    \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502     1.13     \u2502       12       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.14     \u2502       13       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502  1.53 MiB   \u2502  1.53 MiB  \u2502\n\u2502     1.15     \u2502       14       \u2502      Conv2d       \u2502  1.13 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  4.19 MiB  \u2502\n\u2502     1.16     \u2502       15       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502     1.17     \u2502       16       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.18     \u2502       17       \u2502      Conv2d       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502     1.19     \u2502       18       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502     1.20     \u2502       19       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.21     \u2502       20       \u2502      Conv2d       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502     1.22     \u2502       21       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502     1.23     \u2502       22       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.24     \u2502       23       \u2502      Conv2d       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502     1.25     \u2502       24       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502     1.26     \u2502       25       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.27     \u2502       26       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502   784 KiB   \u2502  784 KiB   \u2502\n\u2502     1.28     \u2502       27       \u2502      Conv2d       \u2502  4.50 MiB  \u2502      -      \u2502  1.53 MiB   \u2502  6.03 MiB  \u2502\n\u2502     1.29     \u2502       28       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502     1.30     \u2502       29       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.31     \u2502       30       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502     1.32     \u2502       31       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502     1.33     \u2502       32       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.34     \u2502       33       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502     1.35     \u2502       34       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502     1.36     \u2502       35       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.37     \u2502       36       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502     1.38     \u2502       37       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502     1.39     \u2502       38       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.40     \u2502       39       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502   392 KiB   \u2502  392 KiB   \u2502\n\u2502     1.41     \u2502       40       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502     1.42     \u2502       41       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502     1.43     \u2502       42       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.44     \u2502       43       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502     1.45     \u2502       44       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502     1.46     \u2502       45       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.47     \u2502       46       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502     1.48     \u2502       47       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502     1.49     \u2502       48       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.50     \u2502       49       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502     1.51     \u2502       50       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502     1.52     \u2502       51       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     1.53     \u2502       52       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502      2       \u2502    avgpool     \u2502 AdaptiveAvgPool2d \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502      3       \u2502   classifier   \u2502    Sequential     \u2502 471.66 MiB \u2502    0.00     \u2502  67.91 KiB  \u2502 471.73 MiB \u2502\n\u2502     3.1      \u2502       0        \u2502      Linear       \u2502 392.02 MiB \u2502      -      \u2502   16 KiB    \u2502 392.03 MiB \u2502\n\u2502     3.2      \u2502       1        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     3.3      \u2502       2        \u2502      Dropout      \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502     3.4      \u2502       3        \u2502      Linear       \u2502 64.02 MiB  \u2502      -      \u2502   16 KiB    \u2502 64.03 MiB  \u2502\n\u2502     3.5      \u2502       4        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     3.6      \u2502       5        \u2502      Dropout      \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502     3.7      \u2502       6        \u2502      Linear       \u2502 15.63 MiB  \u2502      -      \u2502  3.91 KiB   \u2502 15.63 MiB  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n---------------------------------------------- s u m m a r y ----------------------------------------------\n\u2022 Model    : VGG                                   \u2022 Statistics: mem                                       \n\u2022 Device   : cuda:0                                \u2022 Parameters Memory Cost: 548.09 MiB, 82.12 %           \n\u2022 Signature: forward(self, x)                      \u2022 Buffers Memory Cost   : 43.12 KiB, 0.01 %             \n\u2022 Input    :                                       \u2022 FeatureMap Memory Cost: 119.31 MiB, 17.88 %           \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;            \u2022 Total Memory Cost     : 667.44 MiB                    \n</pre> In\u00a0[75]: Copied! <pre># Give a feed-forward here if you have not yet.\n# We did it when measuring calculation, therefore we don't need to do it again\n</pre> # Give a feed-forward here if you have not yet. # We did it when measuring calculation, therefore we don't need to do it again In\u00a0[76]: Copied! <pre># There are two hyper parameters to promise the correctness of the measurement.\n\n# 1. ittp_warmup: Number of warm-up(i.e., feed-forward inference) iterations before `ittp` measurement.\n# Default to 50.\nmodel.ittp_warmup = 10   \n\n# 2. ittp_benchmark_time: Number of benchmark iterations per operation in measuring `ittp`. \n# Default to 100.\nmodel.ittp_benchmark_time = 20\n</pre> # There are two hyper parameters to promise the correctness of the measurement.  # 1. ittp_warmup: Number of warm-up(i.e., feed-forward inference) iterations before `ittp` measurement. # Default to 50. model.ittp_warmup = 10     # 2. ittp_benchmark_time: Number of benchmark iterations per operation in measuring `ittp`.  # Default to 100. model.ittp_benchmark_time = 20 In\u00a0[\u00a0]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(\"=\"*10, \" Overall Report \", \"=\"*10)\n\n# Inference latency  &amp; Throughput Benchmarking\n# Same as `param`, the data for each operation is only statistically analyzed for that operation and does not include sub-operations \u2757\u2757\u2757\n# The result unit `IPS` means `Input Per Second`, where the input refer to the input given for feed-forward before.\n# You can check the input via `model.ipt` \nprint(model.ittp)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(\"=\"*10, \" Overall Report \", \"=\"*10)  # Inference latency  &amp; Throughput Benchmarking # Same as `param`, the data for each operation is only statistically analyzed for that operation and does not include sub-operations \u2757\u2757\u2757 # The result unit `IPS` means `Input Per Second`, where the input refer to the input given for feed-forward before. # You can check the input via `model.ipt`  print(model.ittp) <pre>==========  Overall Report  ==========\n</pre> <pre>Warming Up: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 181.68it/s]\nBenchmark Inference Time &amp; Throughput: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1280/1280 [00:00&lt;00:00, 5424.65module/s]\n</pre> <pre>InferTime_Throughput_INFO\n\u2022   Operation_Id = 0\n\u2022 Operation_Name = VGG\n\u2022 Operation_Type = VGG\n\u2022     Infer_Time = 2.06 ms \u00b1 173.78 us\n\u2022     Throughput = 485.85 IPS \u00b1 37.97 IPS\n\n</pre> In\u00a0[78]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(\"=\"*10, \" Layer-wise Profile \", \"=\"*10)\n\n# The result unit `IPS` means `Input Per Second`, where the input refer to the input given for feed-forward before.\n# You can check the input via `model.ipt` \ntb, data = model.profile('ittp', no_tree=True)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(\"=\"*10, \" Layer-wise Profile \", \"=\"*10)  # The result unit `IPS` means `Input Per Second`, where the input refer to the input given for feed-forward before. # You can check the input via `model.ipt`  tb, data = model.profile('ittp', no_tree=True) <pre>==========  Layer-wise Profile  ==========\n</pre> <pre>Warming Up: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 556.83it/s]\nBenchmark Inference Time &amp; Throughput: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1280/1280 [00:00&lt;00:00, 6193.69module/s] \n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Operation_Id \u2502 Operation_Name \u2502  Operation_Type   \u2502      Infer_Time       \u2502       Throughput        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      1       \u2502    features    \u2502    Sequential     \u2502  1.43 ms \u00b1 134.30 us  \u2502 699.11 IPS \u00b1 61.65 IPS  \u2502\n\u2502     1.1      \u2502       0        \u2502      Conv2d       \u2502  66.53 us \u00b1 2.42 us   \u2502 15.03 KIPS \u00b1 542.73 IPS \u2502\n\u2502     1.2      \u2502       1        \u2502    BatchNorm2d    \u2502  49.68 us \u00b1 1.65 us   \u2502 20.13 KIPS \u00b1 679.42 IPS \u2502\n\u2502     1.3      \u2502       2        \u2502       ReLU        \u2502 23.22 us \u00b1 968.00 ns  \u2502 43.07 KIPS \u00b1 1.82 KIPS  \u2502\n\u2502     1.4      \u2502       3        \u2502      Conv2d       \u2502  114.64 us \u00b1 4.13 us  \u2502 8.72 KIPS \u00b1 325.37 IPS  \u2502\n\u2502     1.5      \u2502       4        \u2502    BatchNorm2d    \u2502  50.18 us \u00b1 1.83 us   \u2502 19.93 KIPS \u00b1 725.58 IPS \u2502\n\u2502     1.6      \u2502       5        \u2502       ReLU        \u2502 23.55 us \u00b1 280.00 ns  \u2502 42.46 KIPS \u00b1 509.36 IPS \u2502\n\u2502     1.7      \u2502       6        \u2502     MaxPool2d     \u2502  30.18 us \u00b1 1.02 us   \u2502 33.14 KIPS \u00b1 1.12 KIPS  \u2502\n\u2502     1.8      \u2502       7        \u2502      Conv2d       \u2502 78.77 us \u00b1 319.99 ns  \u2502 12.70 KIPS \u00b1 51.68 IPS  \u2502\n\u2502     1.9      \u2502       8        \u2502    BatchNorm2d    \u2502 50.18 us \u00b1 744.00 ns  \u2502 19.93 KIPS \u00b1 299.96 IPS \u2502\n\u2502     1.10     \u2502       9        \u2502       ReLU        \u2502  23.36 us \u00b1 1.02 us   \u2502 42.81 KIPS \u00b1 1.93 KIPS  \u2502\n\u2502     1.11     \u2502       10       \u2502      Conv2d       \u2502 101.30 us \u00b1 664.00 ns \u2502  9.87 KIPS \u00b1 64.46 IPS  \u2502\n\u2502     1.12     \u2502       11       \u2502    BatchNorm2d    \u2502  45.20 us \u00b1 6.14 us   \u2502 22.13 KIPS \u00b1 2.91 KIPS  \u2502\n\u2502     1.13     \u2502       12       \u2502       ReLU        \u2502  21.26 us \u00b1 3.33 us   \u2502 47.14 KIPS \u00b1 7.50 KIPS  \u2502\n\u2502     1.14     \u2502       13       \u2502     MaxPool2d     \u2502  28.11 us \u00b1 4.41 us   \u2502 35.69 KIPS \u00b1 5.69 KIPS  \u2502\n\u2502     1.15     \u2502       14       \u2502      Conv2d       \u2502 70.66 us \u00b1 160.00 ns  \u2502 14.15 KIPS \u00b1 32.12 IPS  \u2502\n\u2502     1.16     \u2502       15       \u2502    BatchNorm2d    \u2502  45.50 us \u00b1 6.15 us   \u2502 21.98 KIPS \u00b1 2.91 KIPS  \u2502\n\u2502     1.17     \u2502       16       \u2502       ReLU        \u2502  20.98 us \u00b1 2.75 us   \u2502 47.71 KIPS \u00b1 6.03 KIPS  \u2502\n\u2502     1.18     \u2502       17       \u2502      Conv2d       \u2502 103.17 us \u00b1 928.00 ns \u2502  9.69 KIPS \u00b1 87.55 IPS  \u2502\n\u2502     1.19     \u2502       18       \u2502    BatchNorm2d    \u2502 50.18 us \u00b1 352.00 ns  \u2502 19.93 KIPS \u00b1 141.03 IPS \u2502\n\u2502     1.20     \u2502       19       \u2502       ReLU        \u2502 22.59 us \u00b1 800.00 ns  \u2502 44.26 KIPS \u00b1 1.53 KIPS  \u2502\n\u2502     1.21     \u2502       20       \u2502      Conv2d       \u2502  102.40 us \u00b1 5.23 us  \u2502 9.77 KIPS \u00b1 515.19 IPS  \u2502\n\u2502     1.22     \u2502       21       \u2502    BatchNorm2d    \u2502  43.71 us \u00b1 2.86 us   \u2502 22.88 KIPS \u00b1 1.43 KIPS  \u2502\n\u2502     1.23     \u2502       22       \u2502       ReLU        \u2502  20.43 us \u00b1 2.82 us   \u2502 48.94 KIPS \u00b1 6.20 KIPS  \u2502\n\u2502     1.24     \u2502       23       \u2502      Conv2d       \u2502  98.30 us \u00b1 1.06 us   \u2502 10.17 KIPS \u00b1 109.48 IPS \u2502\n\u2502     1.25     \u2502       24       \u2502    BatchNorm2d    \u2502 43.01 us \u00b1 584.00 ns  \u2502 23.25 KIPS \u00b1 312.60 IPS \u2502\n\u2502     1.26     \u2502       25       \u2502       ReLU        \u2502 20.32 us \u00b1 904.00 ns  \u2502 49.21 KIPS \u00b1 2.17 KIPS  \u2502\n\u2502     1.27     \u2502       26       \u2502     MaxPool2d     \u2502  30.45 us \u00b1 1.26 us   \u2502 32.84 KIPS \u00b1 1.37 KIPS  \u2502\n\u2502     1.28     \u2502       27       \u2502      Conv2d       \u2502  72.93 us \u00b1 1.34 us   \u2502 13.71 KIPS \u00b1 247.66 IPS \u2502\n\u2502     1.29     \u2502       28       \u2502    BatchNorm2d    \u2502  50.18 us \u00b1 2.02 us   \u2502 19.93 KIPS \u00b1 803.87 IPS \u2502\n\u2502     1.30     \u2502       29       \u2502       ReLU        \u2502  23.55 us \u00b1 1.02 us   \u2502 42.46 KIPS \u00b1 1.77 KIPS  \u2502\n\u2502     1.31     \u2502       30       \u2502      Conv2d       \u2502  105.47 us \u00b1 1.21 us  \u2502 9.48 KIPS \u00b1 109.38 IPS  \u2502\n\u2502     1.32     \u2502       31       \u2502    BatchNorm2d    \u2502 42.96 us \u00b1 488.00 ns  \u2502 23.28 KIPS \u00b1 266.26 IPS \u2502\n\u2502     1.33     \u2502       32       \u2502       ReLU        \u2502 19.68 us \u00b1 600.00 ns  \u2502 50.81 KIPS \u00b1 1.52 KIPS  \u2502\n\u2502     1.34     \u2502       33       \u2502      Conv2d       \u2502 100.35 us \u00b1 383.99 ns \u2502  9.96 KIPS \u00b1 37.93 IPS  \u2502\n\u2502     1.35     \u2502       34       \u2502    BatchNorm2d    \u2502 43.01 us \u00b1 304.00 ns  \u2502 23.25 KIPS \u00b1 164.05 IPS \u2502\n\u2502     1.36     \u2502       35       \u2502       ReLU        \u2502 20.19 us \u00b1 928.00 ns  \u2502 49.52 KIPS \u00b1 2.32 KIPS  \u2502\n\u2502     1.37     \u2502       36       \u2502      Conv2d       \u2502 100.35 us \u00b1 464.00 ns \u2502  9.96 KIPS \u00b1 45.80 IPS  \u2502\n\u2502     1.38     \u2502       37       \u2502    BatchNorm2d    \u2502 43.07 us \u00b1 248.00 ns  \u2502 23.22 KIPS \u00b1 133.29 IPS \u2502\n\u2502     1.39     \u2502       38       \u2502       ReLU        \u2502  20.38 us \u00b1 1.15 us   \u2502 49.06 KIPS \u00b1 2.76 KIPS  \u2502\n\u2502     1.40     \u2502       39       \u2502     MaxPool2d     \u2502 30.72 us \u00b1 168.00 ns  \u2502 32.55 KIPS \u00b1 179.00 IPS \u2502\n\u2502     1.41     \u2502       40       \u2502      Conv2d       \u2502  69.79 us \u00b1 8.31 us   \u2502 14.33 KIPS \u00b1 1.54 KIPS  \u2502\n\u2502     1.42     \u2502       41       \u2502    BatchNorm2d    \u2502  43.74 us \u00b1 1.09 us   \u2502 22.86 KIPS \u00b1 575.54 IPS \u2502\n\u2502     1.43     \u2502       42       \u2502       ReLU        \u2502 20.19 us \u00b1 760.00 ns  \u2502 49.53 KIPS \u00b1 1.90 KIPS  \u2502\n\u2502     1.44     \u2502       43       \u2502      Conv2d       \u2502  69.49 us \u00b1 1.28 us   \u2502 14.39 KIPS \u00b1 266.38 IPS \u2502\n\u2502     1.45     \u2502       44       \u2502    BatchNorm2d    \u2502  43.10 us \u00b1 1.02 us   \u2502 23.20 KIPS \u00b1 540.73 IPS \u2502\n\u2502     1.46     \u2502       45       \u2502       ReLU        \u2502 19.55 us \u00b1 896.00 ns  \u2502 51.15 KIPS \u00b1 2.26 KIPS  \u2502\n\u2502     1.47     \u2502       46       \u2502      Conv2d       \u2502  69.63 us \u00b1 1.25 us   \u2502 14.36 KIPS \u00b1 259.96 IPS \u2502\n\u2502     1.48     \u2502       47       \u2502    BatchNorm2d    \u2502 43.01 us \u00b1 488.00 ns  \u2502 23.25 KIPS \u00b1 266.81 IPS \u2502\n\u2502     1.49     \u2502       48       \u2502       ReLU        \u2502 20.05 us \u00b1 968.00 ns  \u2502 49.88 KIPS \u00b1 2.42 KIPS  \u2502\n\u2502     1.50     \u2502       49       \u2502      Conv2d       \u2502 68.82 us \u00b1 904.00 ns  \u2502 14.53 KIPS \u00b1 189.55 IPS \u2502\n\u2502     1.51     \u2502       50       \u2502    BatchNorm2d    \u2502 43.01 us \u00b1 800.00 ns  \u2502 23.25 KIPS \u00b1 426.38 IPS \u2502\n\u2502     1.52     \u2502       51       \u2502       ReLU        \u2502 19.49 us \u00b1 856.00 ns  \u2502 51.31 KIPS \u00b1 2.16 KIPS  \u2502\n\u2502     1.53     \u2502       52       \u2502     MaxPool2d     \u2502 26.64 us \u00b1 696.00 ns  \u2502 37.54 KIPS \u00b1 958.52 IPS \u2502\n\u2502      2       \u2502    avgpool     \u2502 AdaptiveAvgPool2d \u2502 28.50 us \u00b1 904.00 ns  \u2502 35.09 KIPS \u00b1 1.14 KIPS  \u2502\n\u2502      3       \u2502   classifier   \u2502    Sequential     \u2502  585.07 us \u00b1 1.28 us  \u2502  1.71 KIPS \u00b1 3.73 IPS   \u2502\n\u2502     3.1      \u2502       0        \u2502      Linear       \u2502  488.45 us \u00b1 2.37 us  \u2502  2.05 KIPS \u00b1 9.92 IPS   \u2502\n\u2502     3.2      \u2502       1        \u2502       ReLU        \u2502 19.62 us \u00b1 824.00 ns  \u2502 50.98 KIPS \u00b1 2.09 KIPS  \u2502\n\u2502     3.3      \u2502       2        \u2502      Dropout      \u2502 15.36 us \u00b1 432.00 ns  \u2502 65.10 KIPS \u00b1 1.89 KIPS  \u2502\n\u2502     3.4      \u2502       3        \u2502      Linear       \u2502 35.84 us \u00b1 224.00 ns  \u2502 27.90 KIPS \u00b1 172.36 IPS \u2502\n\u2502     3.5      \u2502       4        \u2502       ReLU        \u2502 18.24 us \u00b1 976.00 ns  \u2502 54.82 KIPS \u00b1 3.03 KIPS  \u2502\n\u2502     3.6      \u2502       5        \u2502      Dropout      \u2502 14.30 us \u00b1 632.00 ns  \u2502 69.91 KIPS \u00b1 3.07 KIPS  \u2502\n\u2502     3.7      \u2502       6        \u2502      Linear       \u2502 36.86 us \u00b1 784.00 ns  \u2502 27.13 KIPS \u00b1 581.71 IPS \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n-------------------------------------------- s u m m a r y --------------------------------------------\n\u2022 Model    : VGG                                   \u2022 Statistics: ittp                                  \n\u2022 Device   : cuda:0                                \u2022 Benchmark Times: 20                               \n\u2022 Signature: forward(self, x)                      \u2022 Inference Elapse: 2.07 ms \u00b1 63.78 us              \n\u2022 Input    :                                       \u2022 Throughput      : 483.33 IPS \u00b1 14.49 IPS          \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                                                                \n</pre> In\u00a0[79]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\n# Just pass in the names and orders of the statistics you want to display in `model.overview()`\n# they will be displayed in the order you pass them in after the model information.\nprint(model.overview(\"param\", \"mem\"))\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  # Just pass in the names and orders of the statistics you want to display in `model.overview()` # they will be displayed in the order you pass them in after the model information. print(model.overview(\"param\", \"mem\")) <pre>           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Model INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Param INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500       \n            \u2022 Model    : VGG                                           \u2022 Statistics: param                         \n            \u2022 Device   : cuda:0                                        \u2022 Learnable Parameters Num: 123.64 M        \n            \u2022 Signature: forward(self, x)                              \u2022 Total Parameters Num    : 143.68 M        \n            \u2022 Input    :                                              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500       \n               x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                                                                \n           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                               \n        \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Mem INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                            \n         \u2022 Statistics: mem                                                                                         \n         \u2022 Parameters Memory Cost: 548.09 MiB, 82.12 %                                                             \n         \u2022 Buffers Memory Cost   : 43.12 KiB, 0.01 %                                                               \n         \u2022 FeatureMap Memory Cost: 119.31 MiB, 17.88 %                                                             \n         \u2022 Total Memory Cost     : 667.44 MiB                                                                      \n        \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                            \n</pre> In\u00a0[80]: Copied! <pre>print(model.overview(show_warning=False))\n</pre> print(model.overview(show_warning=False)) <pre>Warming Up: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 432.77it/s]\nBenchmark Inference Time &amp; Throughput: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1280/1280 [00:00&lt;00:00, 5649.95module/s]\n</pre> <pre>       \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Model INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Param INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \n        \u2022 Model    : VGG                                            \u2022 Statistics: param                            \n        \u2022 Device   : cuda:0                                         \u2022 Learnable Parameters Num: 123.64 M           \n        \u2022 Signature: forward(self, x)                               \u2022 Total Parameters Num    : 143.68 M           \n        \u2022 Input    :                                               \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \n           x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                                                                    \n       \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                                   \n           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Cal INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Mem INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500      \n            \u2022 Statistics: cal                                  \u2022 Statistics: mem                                   \n            \u2022 FLOPs               : 39.34 G                    \u2022 Parameters Memory Cost: 548.09 MiB, 82.12 %       \n            \u2022 MACs(aka MACC, MADD): 19.68 G                    \u2022 Buffers Memory Cost   : 43.12 KiB, 0.01 %         \n           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                   \u2022 FeatureMap Memory Cost: 119.31 MiB, 17.88 %       \n                                                               \u2022 Total Memory Cost     : 667.44 MiB                \n                                                              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500      \n      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Ittp INFO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                                 \n       \u2022 Statistics: ittp                                                                                          \n       \u2022 Benchmark Times: 20                                                                                       \n       \u2022 Inference Elapse: 2.26 ms \u00b1 175.01 us                                                                     \n       \u2022 Throughput      : 442.99 IPS \u00b1 36.73 IPS                                                                  \n      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                                 \n</pre> In\u00a0[81]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\n# modify related configurations via attribute access (Suitable for small-scale, one-on-one modification)\nmodel.tree_levels_args.default.label = \"[b gray35](&lt;node_id&gt;) [green]&lt;name&gt;[/green] [cyan]&lt;module_repr&gt;[/]\"\n\n# modify related configurations via dict (Suitable for a large number of modifications)\nmodel.tree_levels_args = {\n    \"default\": {\"guide_style\": \"yellow\"},\n    \"1\": {\"guide_style\": \"cornflower_blue\"}\n}\n\nprint(model.structure)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  # modify related configurations via attribute access (Suitable for small-scale, one-on-one modification) model.tree_levels_args.default.label = \"[b gray35]() [green][/green] [cyan][/]\"  # modify related configurations via dict (Suitable for a large number of modifications) model.tree_levels_args = {     \"default\": {\"guide_style\": \"yellow\"},     \"1\": {\"guide_style\": \"cornflower_blue\"} }  print(model.structure) <pre>VGG\n\u251c\u2500\u2500 (1) features Sequential\n\u2502   \u251c\u2500\u2500 (1.1) 0 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.2) 1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.3) 2 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.4) 3 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.5) 4 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.6) 5 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.7) 6 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 (1.8) 7 Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.9) 8 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.10) 9 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.11) 10 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.12) 11 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.13) 12 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.14) 13 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 (1.15) 14 Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 Repeat [3] Times \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2502   \u2502   \u2503 (1.j) 15 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2503\n\u2502   \u2502   \u2503 (1.(j+1)) 16 ReLU(inplace=True)                                                               \u2503\n\u2502   \u2502   \u2503 (1.(j+2)) 17 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))              \u2503\n\u2502   \u2502   \u2503 --------------------------------------------------------------------------------------------- \u2503\n\u2502   \u2502   \u2503 Where j = 16, 19, 22                                                                          \u2503\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\u2502   \u251c\u2500\u2500 (1.25) 24 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.26) 25 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.27) 26 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 (1.28) 27 Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 Repeat [3] Times \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2502   \u2502   \u2503 (1.k) 28 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2503\n\u2502   \u2502   \u2503 (1.(k+1)) 29 ReLU(inplace=True)                                                               \u2503\n\u2502   \u2502   \u2503 (1.(k+2)) 30 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))              \u2503\n\u2502   \u2502   \u2503 --------------------------------------------------------------------------------------------- \u2503\n\u2502   \u2502   \u2503 Where k = 29, 32, 35                                                                          \u2503\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\u2502   \u251c\u2500\u2500 (1.38) 37 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.39) 38 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.40) 39 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 Repeat [2] Times \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2502   \u2502   \u2503 (1.a) 40 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                      \u2503\n\u2502   \u2502   \u2503 (1.(a+1)) 41 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2503\n\u2502   \u2502   \u2503 (1.(a+2)) 42 ReLU(inplace=True)                                                                   \u2503\n\u2502   \u2502   \u2503 (1.(a+3)) 43 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                  \u2503\n\u2502   \u2502   \u2503 (1.(a+4)) 44 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2503\n\u2502   \u2502   \u2503 (1.(a+5)) 45 ReLU(inplace=True)                                                                   \u2503\n\u2502   \u2502   \u2503 ------------------------------------------------------------------------------------------------- \u2503\n\u2502   \u2502   \u2503 Where a = 41, 47                                                                                  \u2503\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\u2502   \u2514\u2500\u2500 (1.53) 52 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u251c\u2500\u2500 (2) avgpool AdaptiveAvgPool2d(output_size=(7, 7))\n\u2514\u2500\u2500 (3) classifier Sequential\n    \u251c\u2500\u2500 (3.1) 0 Linear(in_features=25088, out_features=4096, bias=True)\n    \u251c\u2500\u2500 (3.2) 1 ReLU(inplace=True)\n    \u251c\u2500\u2500 (3.3) 2 Dropout(p=0.5, inplace=False)\n    \u251c\u2500\u2500 (3.4) 3 Linear(in_features=4096, out_features=4096, bias=True)\n    \u251c\u2500\u2500 (3.5) 4 ReLU(inplace=True)\n    \u251c\u2500\u2500 (3.6) 5 Dropout(p=0.5, inplace=False)\n    \u2514\u2500\u2500 (3.7) 6 Linear(in_features=4096, out_features=1000, bias=True)\n</pre> In\u00a0[82]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\n# modify related configurations via attribute access (Suitable for small-scale, one-on-one modification)\nmodel.tree_repeat_block_args.title = \"[[b]&lt;repeat_time&gt;[/b]] [i]Times Repeated[/]\"\nmodel.tree_repeat_block_args.title_align = \"right\"\n\nprint(model.structure)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  # modify related configurations via attribute access (Suitable for small-scale, one-on-one modification) model.tree_repeat_block_args.title = \"[[b][/b]] [i]Times Repeated[/]\" model.tree_repeat_block_args.title_align = \"right\"  print(model.structure) <pre>VGG\n\u251c\u2500\u2500 (1) features Sequential\n\u2502   \u251c\u2500\u2500 (1.1) 0 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.2) 1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.3) 2 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.4) 3 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.5) 4 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.6) 5 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.7) 6 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 (1.8) 7 Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.9) 8 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.10) 9 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.11) 10 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.12) 11 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.13) 12 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.14) 13 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 (1.15) 14 Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 [3] Times Repeated \u2501\u2513\n\u2502   \u2502   \u2503 (1.b) 15 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2503\n\u2502   \u2502   \u2503 (1.(b+1)) 16 ReLU(inplace=True)                                                               \u2503\n\u2502   \u2502   \u2503 (1.(b+2)) 17 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))              \u2503\n\u2502   \u2502   \u2503 --------------------------------------------------------------------------------------------- \u2503\n\u2502   \u2502   \u2503 Where b = 16, 19, 22                                                                          \u2503\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\u2502   \u251c\u2500\u2500 (1.25) 24 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.26) 25 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.27) 26 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 (1.28) 27 Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 [3] Times Repeated \u2501\u2513\n\u2502   \u2502   \u2503 (1.c) 28 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2503\n\u2502   \u2502   \u2503 (1.(c+1)) 29 ReLU(inplace=True)                                                               \u2503\n\u2502   \u2502   \u2503 (1.(c+2)) 30 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))              \u2503\n\u2502   \u2502   \u2503 --------------------------------------------------------------------------------------------- \u2503\n\u2502   \u2502   \u2503 Where c = 29, 32, 35                                                                          \u2503\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\u2502   \u251c\u2500\u2500 (1.38) 37 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.39) 38 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.40) 39 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 [2] Times Repeated \u2501\u2513\n\u2502   \u2502   \u2503 (1.d) 40 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                      \u2503\n\u2502   \u2502   \u2503 (1.(d+1)) 41 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2503\n\u2502   \u2502   \u2503 (1.(d+2)) 42 ReLU(inplace=True)                                                                   \u2503\n\u2502   \u2502   \u2503 (1.(d+3)) 43 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                  \u2503\n\u2502   \u2502   \u2503 (1.(d+4)) 44 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2503\n\u2502   \u2502   \u2503 (1.(d+5)) 45 ReLU(inplace=True)                                                                   \u2503\n\u2502   \u2502   \u2503 ------------------------------------------------------------------------------------------------- \u2503\n\u2502   \u2502   \u2503 Where d = 41, 47                                                                                  \u2503\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\u2502   \u2514\u2500\u2500 (1.53) 52 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u251c\u2500\u2500 (2) avgpool AdaptiveAvgPool2d(output_size=(7, 7))\n\u2514\u2500\u2500 (3) classifier Sequential\n    \u251c\u2500\u2500 (3.1) 0 Linear(in_features=25088, out_features=4096, bias=True)\n    \u251c\u2500\u2500 (3.2) 1 ReLU(inplace=True)\n    \u251c\u2500\u2500 (3.3) 2 Dropout(p=0.5, inplace=False)\n    \u251c\u2500\u2500 (3.4) 3 Linear(in_features=4096, out_features=4096, bias=True)\n    \u251c\u2500\u2500 (3.5) 4 ReLU(inplace=True)\n    \u251c\u2500\u2500 (3.6) 5 Dropout(p=0.5, inplace=False)\n    \u2514\u2500\u2500 (3.7) 6 Linear(in_features=4096, out_features=1000, bias=True)\n</pre> In\u00a0[83]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nfrom rich.box import ROUNDED\n\n# modify related configurations via dict (Suitable for a large number of modifications)\nmodel.tree_repeat_block_args = {\n    \"style\": \"purple\",\n    \"box\": ROUNDED,\n}\n\nprint(model.structure)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  from rich.box import ROUNDED  # modify related configurations via dict (Suitable for a large number of modifications) model.tree_repeat_block_args = {     \"style\": \"purple\",     \"box\": ROUNDED, }  print(model.structure) <pre>VGG\n\u251c\u2500\u2500 (1) features Sequential\n\u2502   \u251c\u2500\u2500 (1.1) 0 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.2) 1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.3) 2 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.4) 3 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.5) 4 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.6) 5 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.7) 6 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 (1.8) 7 Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.9) 8 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.10) 9 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.11) 10 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 (1.12) 11 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.13) 12 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.14) 13 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 (1.15) 14 Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [3] Times Repeated \u2500\u256e\n\u2502   \u2502   \u2502 (1.e) 15 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2502\n\u2502   \u2502   \u2502 (1.(e+1)) 16 ReLU(inplace=True)                                                               \u2502\n\u2502   \u2502   \u2502 (1.(e+2)) 17 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))              \u2502\n\u2502   \u2502   \u2502 --------------------------------------------------------------------------------------------- \u2502\n\u2502   \u2502   \u2502 Where e = 16, 19, 22                                                                          \u2502\n\u2502   \u2502   \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u2502   \u251c\u2500\u2500 (1.25) 24 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.26) 25 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.27) 26 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 (1.28) 27 Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\u2502   \u251c\u2500\u2500 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [3] Times Repeated \u2500\u256e\n\u2502   \u2502   \u2502 (1.f) 28 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2502\n\u2502   \u2502   \u2502 (1.(f+1)) 29 ReLU(inplace=True)                                                               \u2502\n\u2502   \u2502   \u2502 (1.(f+2)) 30 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))              \u2502\n\u2502   \u2502   \u2502 --------------------------------------------------------------------------------------------- \u2502\n\u2502   \u2502   \u2502 Where f = 29, 32, 35                                                                          \u2502\n\u2502   \u2502   \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u2502   \u251c\u2500\u2500 (1.38) 37 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\u2502   \u251c\u2500\u2500 (1.39) 38 ReLU(inplace=True)\n\u2502   \u251c\u2500\u2500 (1.40) 39 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u2502   \u251c\u2500\u2500 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [2] Times Repeated \u2500\u256e\n\u2502   \u2502   \u2502 (1.g) 40 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                      \u2502\n\u2502   \u2502   \u2502 (1.(g+1)) 41 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2502\n\u2502   \u2502   \u2502 (1.(g+2)) 42 ReLU(inplace=True)                                                                   \u2502\n\u2502   \u2502   \u2502 (1.(g+3)) 43 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))                  \u2502\n\u2502   \u2502   \u2502 (1.(g+4)) 44 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)     \u2502\n\u2502   \u2502   \u2502 (1.(g+5)) 45 ReLU(inplace=True)                                                                   \u2502\n\u2502   \u2502   \u2502 ------------------------------------------------------------------------------------------------- \u2502\n\u2502   \u2502   \u2502 Where g = 41, 47                                                                                  \u2502\n\u2502   \u2502   \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u2502   \u2514\u2500\u2500 (1.53) 52 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n\u251c\u2500\u2500 (2) avgpool AdaptiveAvgPool2d(output_size=(7, 7))\n\u2514\u2500\u2500 (3) classifier Sequential\n    \u251c\u2500\u2500 (3.1) 0 Linear(in_features=25088, out_features=4096, bias=True)\n    \u251c\u2500\u2500 (3.2) 1 ReLU(inplace=True)\n    \u251c\u2500\u2500 (3.3) 2 Dropout(p=0.5, inplace=False)\n    \u251c\u2500\u2500 (3.4) 3 Linear(in_features=4096, out_features=4096, bias=True)\n    \u251c\u2500\u2500 (3.5) 4 ReLU(inplace=True)\n    \u251c\u2500\u2500 (3.6) 5 Dropout(p=0.5, inplace=False)\n    \u2514\u2500\u2500 (3.7) 6 Linear(in_features=4096, out_features=1000, bias=True)\n</pre> <p>There are three ways to customize the footer, which can be classified according to the degree of setting freedom:</p> <ol> <li>Fixed text</li> <li>Dynamic text based on attributes of the tree node.</li> <li>Dynamic text based on function</li> </ol> <p>For the convenience of demonstration, we need a simpler model, namely the <code>RepeatModel</code> below.</p> In\u00a0[84]: Copied! <pre>import torch.nn as nn\nfrom random import sample\nfrom torchmeter import Meter\n\nclass RepeatModel(nn.Module):\n    def __init__(self, repeat_winsz:int=1, repeat_time:int=2):\n        super(RepeatModel, self).__init__()\n        \n        layer_candidates = [\n            nn.Linear(10, 10), \n            nn.ReLU(),\n            nn.Identity()\n        ]\n\n        pick_modules = sample(layer_candidates, repeat_winsz)\n        all_modules = pick_modules * repeat_time\n\n        self.layers = nn.ModuleList(all_modules)\n\nfooter_model = Meter(\n    RepeatModel(repeat_winsz=2, repeat_time=3), \n    device=\"cpu\"\n)\n\nprint(\"The default footer:\")\nprint(footer_model.structure)\n</pre> import torch.nn as nn from random import sample from torchmeter import Meter  class RepeatModel(nn.Module):     def __init__(self, repeat_winsz:int=1, repeat_time:int=2):         super(RepeatModel, self).__init__()                  layer_candidates = [             nn.Linear(10, 10),              nn.ReLU(),             nn.Identity()         ]          pick_modules = sample(layer_candidates, repeat_winsz)         all_modules = pick_modules * repeat_time          self.layers = nn.ModuleList(all_modules)  footer_model = Meter(     RepeatModel(repeat_winsz=2, repeat_time=3),      device=\"cpu\" )  print(\"The default footer:\") print(footer_model.structure) <pre></pre> <pre>Finish Scanning model in 0.0013 seconds\n</pre> <pre>The default footer:\n</pre> <pre>RepeatModel\n\u2514\u2500\u2500 (1) layers ModuleList\n    \u2514\u2500\u2500 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [3] Times Repeated \u2500\u256e\n        \u2502 (1.x) 0 ReLU()                                                     \u2502\n        \u2502 (1.(x+1)) 1 Linear(in_features=10, out_features=10, bias=True)     \u2502\n        \u2502 ------------------------------------------------------------------ \u2502\n        \u2502 Where x = 1, 3, 5                                                  \u2502\n        \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> In\u00a0[85]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# footer_model: Instance of `torchmeter.Meter` created from RepeatModel in F.c.2.3\n\nfooter_model.tree_renderer.repeat_footer = \"My custom footer\"\n\nprint(footer_model.structure)\n</pre> # Context # -------------------------------------------------------------------------------- # footer_model: Instance of `torchmeter.Meter` created from RepeatModel in F.c.2.3  footer_model.tree_renderer.repeat_footer = \"My custom footer\"  print(footer_model.structure) <pre>RepeatModel\n\u2514\u2500\u2500 (1) layers ModuleList\n    \u2514\u2500\u2500 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [3] Times Repeated \u2500\u256e\n        \u2502 (1.y) 0 ReLU()                                                     \u2502\n        \u2502 (1.(y+1)) 1 Linear(in_features=10, out_features=10, bias=True)     \u2502\n        \u2502 ------------------------------------------------------------------ \u2502\n        \u2502 My custom footer                                                   \u2502\n        \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> In\u00a0[86]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# footer_model: Instance of `torchmeter.Meter` created from RepeatModel in F.c.2.3\n\nfooter_model.tree_renderer.repeat_footer = \"The type of first module is &lt;type&gt;\"\n\nprint(footer_model.structure)\n</pre> # Context # -------------------------------------------------------------------------------- # footer_model: Instance of `torchmeter.Meter` created from RepeatModel in F.c.2.3  footer_model.tree_renderer.repeat_footer = \"The type of first module is \"  print(footer_model.structure) <pre>RepeatModel\n\u2514\u2500\u2500 (1) layers ModuleList\n    \u2514\u2500\u2500 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [3] Times Repeated \u2500\u256e\n        \u2502 (1.i) 0 ReLU()                                                     \u2502\n        \u2502 (1.(i+1)) 1 Linear(in_features=10, out_features=10, bias=True)     \u2502\n        \u2502 ------------------------------------------------------------------ \u2502\n        \u2502 The type of first module is ReLU                                   \u2502\n        \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> In\u00a0[87]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# footer_model: Instance of `torchmeter.Meter` created from RepeatModel in F.c.2.3\n\nfrom typing import Dict, Any\n\ndef my_footer(attr_dict: Dict[str, Any]) -&gt; str:\n    \"\"\" Footer function requirements\n    \n    1. must have only one argument(name irrelevant) to receive a dictionary of attributes \n      (key: attribute name | value: attribute value)\n    \n    2. must return a string, the string can still contain a place holder like `&lt;repeat_winsz&gt;` \n      to be replaced with the corresponding attribute value before rendering.\n    \"\"\"\n\n    repeat_win_size = attr_dict[\"repeat_winsz\"]\n    if repeat_win_size &gt; 1:\n        return f\"There are {repeat_win_size} modules in a repeat window\"\n    else:\n        return \"The repeat window only contains one module\"\n\nfooter_model.tree_renderer.repeat_footer = my_footer\n\nprint(footer_model.structure)\n</pre> # Context # -------------------------------------------------------------------------------- # footer_model: Instance of `torchmeter.Meter` created from RepeatModel in F.c.2.3  from typing import Dict, Any  def my_footer(attr_dict: Dict[str, Any]) -&gt; str:     \"\"\" Footer function requirements          1. must have only one argument(name irrelevant) to receive a dictionary of attributes        (key: attribute name | value: attribute value)          2. must return a string, the string can still contain a place holder like ``        to be replaced with the corresponding attribute value before rendering.     \"\"\"      repeat_win_size = attr_dict[\"repeat_winsz\"]     if repeat_win_size &gt; 1:         return f\"There are {repeat_win_size} modules in a repeat window\"     else:         return \"The repeat window only contains one module\"  footer_model.tree_renderer.repeat_footer = my_footer  print(footer_model.structure) <pre>RepeatModel\n\u2514\u2500\u2500 (1) layers ModuleList\n    \u2514\u2500\u2500 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 [3] Times Repeated \u2500\u256e\n        \u2502 (1.j) 0 ReLU()                                                     \u2502\n        \u2502 (1.(j+1)) 1 Linear(in_features=10, out_features=10, bias=True)     \u2502\n        \u2502 ------------------------------------------------------------------ \u2502\n        \u2502 There are 2 modules in a repeat window                             \u2502\n        \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> In\u00a0[88]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\n# customize column display settings\n# modify related configurations via attribute access (Suitable for small-scale, one-on-one modification)\nmodel.table_column_args.justify = \"left\"\n\n# customize the display for the whole table\n# modify related configurations via dict (Suitable for a large number of modifications)\nmodel.table_display_args = {\n    \"style\": \"#af8700\", # or rgb(175,135,0)\n    \"show_lines\": True,\n    \"show_edge\": False    \n}\n\ntb, data = model.profile(\"param\", no_tree=True)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  # customize column display settings # modify related configurations via attribute access (Suitable for small-scale, one-on-one modification) model.table_column_args.justify = \"left\"  # customize the display for the whole table # modify related configurations via dict (Suitable for a large number of modifications) model.table_display_args = {     \"style\": \"#af8700\", # or rgb(175,135,0)     \"show_lines\": True,     \"show_edge\": False     }  tb, data = model.profile(\"param\", no_tree=True) <pre> Operation_Id \u2502 Operation_Name \u2502 Operation_Type    \u2502 Param_Name \u2502 Requires_Grad \u2502 Numeric_Num \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1            \u2502 features       \u2502 Sequential        \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.1          \u2502 0              \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 1.73 K      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.1          \u2502 0              \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 64.00       \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.2          \u2502 1              \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 64.00       \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.2          \u2502 1              \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 64.00       \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.3          \u2502 2              \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.4          \u2502 3              \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 36.86 K     \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.4          \u2502 3              \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 64.00       \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.5          \u2502 4              \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 64.00       \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.5          \u2502 4              \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 64.00       \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.6          \u2502 5              \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.7          \u2502 6              \u2502 MaxPool2d         \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.8          \u2502 7              \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 73.73 K     \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.8          \u2502 7              \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 128.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.9          \u2502 8              \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 128.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.9          \u2502 8              \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 128.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.10         \u2502 9              \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.11         \u2502 10             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 147.46 K    \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.11         \u2502 10             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 128.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.12         \u2502 11             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 128.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.12         \u2502 11             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 128.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.13         \u2502 12             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.14         \u2502 13             \u2502 MaxPool2d         \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.15         \u2502 14             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 294.91 K    \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.15         \u2502 14             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.16         \u2502 15             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.16         \u2502 15             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.17         \u2502 16             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.18         \u2502 17             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 589.82 K    \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.18         \u2502 17             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.19         \u2502 18             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.19         \u2502 18             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.20         \u2502 19             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.21         \u2502 20             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 589.82 K    \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.21         \u2502 20             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.22         \u2502 21             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.22         \u2502 21             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.23         \u2502 22             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.24         \u2502 23             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 589.82 K    \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.24         \u2502 23             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.25         \u2502 24             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.25         \u2502 24             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 256.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.26         \u2502 25             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.27         \u2502 26             \u2502 MaxPool2d         \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.28         \u2502 27             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 1.18 M      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.28         \u2502 27             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.29         \u2502 28             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.29         \u2502 28             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.30         \u2502 29             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.31         \u2502 30             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 2.36 M      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.31         \u2502 30             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.32         \u2502 31             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.32         \u2502 31             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.33         \u2502 32             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.34         \u2502 33             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 2.36 M      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.34         \u2502 33             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.35         \u2502 34             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.35         \u2502 34             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.36         \u2502 35             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.37         \u2502 36             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 2.36 M      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.37         \u2502 36             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.38         \u2502 37             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.38         \u2502 37             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.39         \u2502 38             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.40         \u2502 39             \u2502 MaxPool2d         \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.41         \u2502 40             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 2.36 M      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.41         \u2502 40             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.42         \u2502 41             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.42         \u2502 41             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.43         \u2502 42             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.44         \u2502 43             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 2.36 M      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.44         \u2502 43             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.45         \u2502 44             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.45         \u2502 44             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.46         \u2502 45             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.47         \u2502 46             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 2.36 M      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.47         \u2502 46             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.48         \u2502 47             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.48         \u2502 47             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.49         \u2502 48             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.50         \u2502 49             \u2502 Conv2d            \u2502 weight     \u2502 False         \u2502 2.36 M      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.50         \u2502 49             \u2502 Conv2d            \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.51         \u2502 50             \u2502 BatchNorm2d       \u2502 weight     \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.51         \u2502 50             \u2502 BatchNorm2d       \u2502 bias       \u2502 False         \u2502 512.00      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.52         \u2502 51             \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 1.53         \u2502 52             \u2502 MaxPool2d         \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 2            \u2502 avgpool        \u2502 AdaptiveAvgPool2d \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3            \u2502 classifier     \u2502 Sequential        \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3.1          \u2502 0              \u2502 Linear            \u2502 weight     \u2502 True          \u2502 102.76 M    \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3.1          \u2502 0              \u2502 Linear            \u2502 bias       \u2502 True          \u2502 4.10 K      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3.2          \u2502 1              \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3.3          \u2502 2              \u2502 Dropout           \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3.4          \u2502 3              \u2502 Linear            \u2502 weight     \u2502 True          \u2502 16.78 M     \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3.4          \u2502 3              \u2502 Linear            \u2502 bias       \u2502 True          \u2502 4.10 K      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3.5          \u2502 4              \u2502 ReLU              \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3.6          \u2502 5              \u2502 Dropout           \u2502 -          \u2502 -             \u2502 0.00        \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3.7          \u2502 6              \u2502 Linear            \u2502 weight     \u2502 True          \u2502 4.10 M      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 3.7          \u2502 6              \u2502 Linear            \u2502 bias       \u2502 True          \u2502 1 K         \n--------------------------------------- s u m m a r y ----------------------------------------\n\u2022 Model    : VGG                                  \u2022 Statistics: param                         \n\u2022 Device   : cuda:0                               \u2022 Learnable Parameters Num: 123.64 M        \n\u2022 Signature: forward(self, x)                     \u2022 Total Parameters Num    : 143.68 M        \n\u2022 Input    :                                                                                  \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                                                       \n</pre> In\u00a0[89]: Copied! <pre>## Discard above customization settings\ncfg.restore()\n\n## Disable interval output to adapt to Jupyter Notebook\ncfg.render_interval = 0\n</pre> ## Discard above customization settings cfg.restore()  ## Disable interval output to adapt to Jupyter Notebook cfg.render_interval = 0 In\u00a0[90]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\n# here we use param report instead of the mem report, cause it has smaller width requirement\ntb, data = model.profile(\"param\", no_tree=False)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  # here we use param report instead of the mem report, cause it has smaller width requirement tb, data = model.profile(\"param\", no_tree=False) <pre>VGG                                       \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u251c\u2500\u2500 (1) features Sequential               \u2502 Operation \u2502 Operation \u2502 Operation \u2502 Param_Nam \u2502 Requires_ \u2502 Numeric_N \u2502\n\u2502   \u251c\u2500\u2500 (1.1) 0 Conv2d                    \u2502    _Id    \u2502   _Name   \u2502   _Type   \u2502     e     \u2502   Grad    \u2502    um     \u2502\n\u2502   \u251c\u2500\u2500 (1.2) 1 BatchNorm2d               \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u251c\u2500\u2500 (1.3) 2 ReLU                      \u2502     1     \u2502 features  \u2502 Sequentia \u2502     -     \u2502     -     \u2502   0.00    \u2502\n\u2502   \u251c\u2500\u2500 (1.4) 3 Conv2d                    \u2502           \u2502           \u2502     l     \u2502           \u2502           \u2502           \u2502\n\u2502   \u251c\u2500\u2500 (1.5) 4 BatchNorm2d               \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u251c\u2500\u2500 (1.6) 5 ReLU                      \u2502    1.1    \u2502     0     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  1.73 K   \u2502\n\u2502   \u251c\u2500\u2500 (1.7) 6 MaxPool2d                 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u251c\u2500\u2500 (1.8) 7 Conv2d                    \u2502    1.1    \u2502     0     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502   64.00   \u2502\n\u2502   \u251c\u2500\u2500 (1.9) 8 BatchNorm2d               \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u251c\u2500\u2500 (1.10) 9 ReLU                     \u2502    1.2    \u2502     1     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502   64.00   \u2502\n\u2502   \u251c\u2500\u2500 (1.11) 10 Conv2d                  \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n\u2502   \u251c\u2500\u2500 (1.12) 11 BatchNorm2d             \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u251c\u2500\u2500 (1.13) 12 ReLU                    \u2502    1.2    \u2502     1     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502   64.00   \u2502\n\u2502   \u251c\u2500\u2500 (1.14) 13 MaxPool2d               \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n\u2502   \u251c\u2500\u2500 (1.15) 14 Conv2d                  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501 Repeat [3] Times \u2501\u2501\u2501\u2501\u2513      \u2502    1.3    \u2502     2     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n\u2502   \u2502   \u2503 (1.h) 15 BatchNorm2d     \u2503      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u2502   \u2503 (1.(h+1)) 16 ReLU        \u2503      \u2502    1.4    \u2502     3     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  36.86 K  \u2502\n\u2502   \u2502   \u2503 (1.(h+2)) 17 Conv2d      \u2503      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u2502   \u2503 ------------------------ \u2503      \u2502    1.4    \u2502     3     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502   64.00   \u2502\n\u2502   \u2502   \u2503 Where h = 16, 19, 22     \u2503      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b      \u2502    1.5    \u2502     4     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502   64.00   \u2502\n\u2502   \u251c\u2500\u2500 (1.25) 24 BatchNorm2d             \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n\u2502   \u251c\u2500\u2500 (1.26) 25 ReLU                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u251c\u2500\u2500 (1.27) 26 MaxPool2d               \u2502    1.5    \u2502     4     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502   64.00   \u2502\n\u2502   \u251c\u2500\u2500 (1.28) 27 Conv2d                  \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501 Repeat [3] Times \u2501\u2501\u2501\u2501\u2513      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u2502   \u2503 (1.l) 28 BatchNorm2d     \u2503      \u2502    1.6    \u2502     5     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n\u2502   \u2502   \u2503 (1.(l+1)) 29 ReLU        \u2503      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u2502   \u2503 (1.(l+2)) 30 Conv2d      \u2503      \u2502    1.7    \u2502     6     \u2502 MaxPool2d \u2502     -     \u2502     -     \u2502   0.00    \u2502\n\u2502   \u2502   \u2503 ------------------------ \u2503      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u2502   \u2503 Where l = 29, 32, 35     \u2503      \u2502    1.8    \u2502     7     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  73.73 K  \u2502\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u251c\u2500\u2500 (1.38) 37 BatchNorm2d             \u2502    1.8    \u2502     7     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  128.00   \u2502\n\u2502   \u251c\u2500\u2500 (1.39) 38 ReLU                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u251c\u2500\u2500 (1.40) 39 MaxPool2d               \u2502    1.9    \u2502     8     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  128.00   \u2502\n\u2502   \u251c\u2500\u2500 \u250f\u2501\u2501\u2501\u2501\u2501\u2501 Repeat [2] Times \u2501\u2501\u2501\u2501\u2501\u2501\u2513  \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n\u2502   \u2502   \u2503 (1.m) 40 Conv2d              \u2503  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u2502   \u2503 (1.(m+1)) 41 BatchNorm2d     \u2503  \u2502    1.9    \u2502     8     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  128.00   \u2502\n\u2502   \u2502   \u2503 (1.(m+2)) 42 ReLU            \u2503  \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n\u2502   \u2502   \u2503 (1.(m+3)) 43 Conv2d          \u2503  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u2502   \u2503 (1.(m+4)) 44 BatchNorm2d     \u2503  \u2502   1.10    \u2502     9     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n\u2502   \u2502   \u2503 (1.(m+5)) 45 ReLU            \u2503  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u2502   \u2503 ---------------------------- \u2503  \u2502   1.11    \u2502    10     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502 147.46 K  \u2502\n\u2502   \u2502   \u2503 Where m = 41, 47             \u2503  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   \u2502   \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b  \u2502   1.11    \u2502    10     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  128.00   \u2502\n\u2502   \u2514\u2500\u2500 (1.53) 52 MaxPool2d               \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u251c\u2500\u2500 (2) avgpool AdaptiveAvgPool2d         \u2502   1.12    \u2502    11     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  128.00   \u2502\n\u2514\u2500\u2500 (3) classifier Sequential             \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n    \u251c\u2500\u2500 (3.1) 0 Linear                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u251c\u2500\u2500 (3.2) 1 ReLU                      \u2502   1.12    \u2502    11     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  128.00   \u2502\n    \u251c\u2500\u2500 (3.3) 2 Dropout                   \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n    \u251c\u2500\u2500 (3.4) 3 Linear                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u251c\u2500\u2500 (3.5) 4 ReLU                      \u2502   1.13    \u2502    12     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n    \u251c\u2500\u2500 (3.6) 5 Dropout                   \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2514\u2500\u2500 (3.7) 6 Linear                    \u2502   1.14    \u2502    13     \u2502 MaxPool2d \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.15    \u2502    14     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502 294.91 K  \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.15    \u2502    14     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  256.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.16    \u2502    15     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  256.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.16    \u2502    15     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  256.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.17    \u2502    16     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.18    \u2502    17     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502 589.82 K  \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.18    \u2502    17     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  256.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.19    \u2502    18     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  256.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.19    \u2502    18     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  256.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.20    \u2502    19     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.21    \u2502    20     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502 589.82 K  \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.21    \u2502    20     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  256.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.22    \u2502    21     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  256.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.22    \u2502    21     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  256.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.23    \u2502    22     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.24    \u2502    23     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502 589.82 K  \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.24    \u2502    23     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  256.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.25    \u2502    24     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  256.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.25    \u2502    24     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  256.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.26    \u2502    25     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.27    \u2502    26     \u2502 MaxPool2d \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.28    \u2502    27     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  1.18 M   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.28    \u2502    27     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.29    \u2502    28     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.29    \u2502    28     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.30    \u2502    29     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.31    \u2502    30     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  2.36 M   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.31    \u2502    30     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.32    \u2502    31     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.32    \u2502    31     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.33    \u2502    32     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.34    \u2502    33     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  2.36 M   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.34    \u2502    33     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.35    \u2502    34     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.35    \u2502    34     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.36    \u2502    35     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.37    \u2502    36     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  2.36 M   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.37    \u2502    36     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.38    \u2502    37     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.38    \u2502    37     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.39    \u2502    38     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.40    \u2502    39     \u2502 MaxPool2d \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.41    \u2502    40     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  2.36 M   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.41    \u2502    40     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.42    \u2502    41     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.42    \u2502    41     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.43    \u2502    42     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.44    \u2502    43     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  2.36 M   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.44    \u2502    43     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.45    \u2502    44     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.45    \u2502    44     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.46    \u2502    45     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.47    \u2502    46     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  2.36 M   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.47    \u2502    46     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.48    \u2502    47     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.48    \u2502    47     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.49    \u2502    48     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.50    \u2502    49     \u2502  Conv2d   \u2502  weight   \u2502   False   \u2502  2.36 M   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.50    \u2502    49     \u2502  Conv2d   \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.51    \u2502    50     \u2502 BatchNorm \u2502  weight   \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.51    \u2502    50     \u2502 BatchNorm \u2502   bias    \u2502   False   \u2502  512.00   \u2502\n                                          \u2502           \u2502           \u2502    2d     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.52    \u2502    51     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502   1.53    \u2502    52     \u2502 MaxPool2d \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502     2     \u2502  avgpool  \u2502 AdaptiveA \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u2502           \u2502           \u2502 vgPool2d  \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502     3     \u2502 classifie \u2502 Sequentia \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u2502           \u2502     r     \u2502     l     \u2502           \u2502           \u2502           \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502    3.1    \u2502     0     \u2502  Linear   \u2502  weight   \u2502   True    \u2502 102.76 M  \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502    3.1    \u2502     0     \u2502  Linear   \u2502   bias    \u2502   True    \u2502  4.10 K   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502    3.2    \u2502     1     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502    3.3    \u2502     2     \u2502  Dropout  \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502    3.4    \u2502     3     \u2502  Linear   \u2502  weight   \u2502   True    \u2502  16.78 M  \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502    3.4    \u2502     3     \u2502  Linear   \u2502   bias    \u2502   True    \u2502  4.10 K   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502    3.5    \u2502     4     \u2502   ReLU    \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502    3.6    \u2502     5     \u2502  Dropout  \u2502     -     \u2502     -     \u2502   0.00    \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502    3.7    \u2502     6     \u2502  Linear   \u2502  weight   \u2502   True    \u2502  4.10 M   \u2502\n                                          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                          \u2502    3.7    \u2502     6     \u2502  Linear   \u2502   bias    \u2502   True    \u2502    1 K    \u2502\n                                          \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n-------------------------------------------------- s u m m a r y --------------------------------------------------\n\u2022 Model    : VGG                                             \u2022 Statistics: param                                   \n\u2022 Device   : cuda:0                                          \u2022 Learnable Parameters Num: 123.64 M                  \n\u2022 Signature: forward(self, x)                                \u2022 Total Parameters Num    : 143.68 M                  \n\u2022 Input    :                                                                                                       \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                                                                            \n</pre> In\u00a0[91]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(f\"origin column names of mem report are: {model.table_cols('mem')}\")\n\ntb, data = model.profile(\n    \"mem\",\n    no_tree=True,\n    custom_cols={\n        \"Operation_Id\": \"ID\",\n        \"Param_Cost\": \"Param Cost\", \n    },\n    keep_custom_name = True # whether to keep the custom column name from now on\n)\n\n# if keep_custom_name = False\n# this command will output a same set of column names as before\nprint(f\"after customization, column names of mem report are: {model.table_cols('mem')}\")\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(f\"origin column names of mem report are: {model.table_cols('mem')}\")  tb, data = model.profile(     \"mem\",     no_tree=True,     custom_cols={         \"Operation_Id\": \"ID\",         \"Param_Cost\": \"Param Cost\",      },     keep_custom_name = True # whether to keep the custom column name from now on )  # if keep_custom_name = False # this command will output a same set of column names as before print(f\"after customization, column names of mem report are: {model.table_cols('mem')}\") <pre>origin column names of mem report are: ('Operation_Id', 'Operation_Name', 'Operation_Type', 'Param_Cost', \n'Buffer_Cost', 'Output_Cost', 'Total')\n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502  ID  \u2502 Operation_Name \u2502  Operation_Type   \u2502 Param Cost \u2502 Buffer_Cost \u2502 Output_Cost \u2502   Total    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  1   \u2502    features    \u2502    Sequential     \u2502 76.43 MiB  \u2502  43.12 KiB  \u2502 119.15 MiB  \u2502 195.62 MiB \u2502\n\u2502 1.1  \u2502       0        \u2502      Conv2d       \u2502   7 KiB    \u2502      -      \u2502  12.25 MiB  \u2502 12.26 MiB  \u2502\n\u2502 1.2  \u2502       1        \u2502    BatchNorm2d    \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502 1.3  \u2502       2        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.4  \u2502       3        \u2502      Conv2d       \u2502 144.25 KiB \u2502      -      \u2502  12.25 MiB  \u2502 12.39 MiB  \u2502\n\u2502 1.5  \u2502       4        \u2502    BatchNorm2d    \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502 1.6  \u2502       5        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.7  \u2502       6        \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502  3.06 MiB   \u2502  3.06 MiB  \u2502\n\u2502 1.8  \u2502       7        \u2502      Conv2d       \u2502 288.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.41 MiB  \u2502\n\u2502 1.9  \u2502       8        \u2502    BatchNorm2d    \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502 1.10 \u2502       9        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.11 \u2502       10       \u2502      Conv2d       \u2502 576.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.69 MiB  \u2502\n\u2502 1.12 \u2502       11       \u2502    BatchNorm2d    \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502 1.13 \u2502       12       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.14 \u2502       13       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502  1.53 MiB   \u2502  1.53 MiB  \u2502\n\u2502 1.15 \u2502       14       \u2502      Conv2d       \u2502  1.13 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  4.19 MiB  \u2502\n\u2502 1.16 \u2502       15       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.17 \u2502       16       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.18 \u2502       17       \u2502      Conv2d       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502 1.19 \u2502       18       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.20 \u2502       19       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.21 \u2502       20       \u2502      Conv2d       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502 1.22 \u2502       21       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.23 \u2502       22       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.24 \u2502       23       \u2502      Conv2d       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502 1.25 \u2502       24       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.26 \u2502       25       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.27 \u2502       26       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502   784 KiB   \u2502  784 KiB   \u2502\n\u2502 1.28 \u2502       27       \u2502      Conv2d       \u2502  4.50 MiB  \u2502      -      \u2502  1.53 MiB   \u2502  6.03 MiB  \u2502\n\u2502 1.29 \u2502       28       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.30 \u2502       29       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.31 \u2502       30       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502 1.32 \u2502       31       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.33 \u2502       32       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.34 \u2502       33       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502 1.35 \u2502       34       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.36 \u2502       35       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.37 \u2502       36       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502 1.38 \u2502       37       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.39 \u2502       38       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.40 \u2502       39       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502   392 KiB   \u2502  392 KiB   \u2502\n\u2502 1.41 \u2502       40       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.42 \u2502       41       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.43 \u2502       42       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.44 \u2502       43       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.45 \u2502       44       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.46 \u2502       45       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.47 \u2502       46       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.48 \u2502       47       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.49 \u2502       48       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.50 \u2502       49       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.51 \u2502       50       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.52 \u2502       51       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.53 \u2502       52       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502  2   \u2502    avgpool     \u2502 AdaptiveAvgPool2d \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502  3   \u2502   classifier   \u2502    Sequential     \u2502 471.66 MiB \u2502    0.00     \u2502  67.91 KiB  \u2502 471.73 MiB \u2502\n\u2502 3.1  \u2502       0        \u2502      Linear       \u2502 392.02 MiB \u2502      -      \u2502   16 KiB    \u2502 392.03 MiB \u2502\n\u2502 3.2  \u2502       1        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 3.3  \u2502       2        \u2502      Dropout      \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502 3.4  \u2502       3        \u2502      Linear       \u2502 64.02 MiB  \u2502      -      \u2502   16 KiB    \u2502 64.03 MiB  \u2502\n\u2502 3.5  \u2502       4        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 3.6  \u2502       5        \u2502      Dropout      \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502 3.7  \u2502       6        \u2502      Linear       \u2502 15.63 MiB  \u2502      -      \u2502  3.91 KiB   \u2502 15.63 MiB  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n------------------------------------------ s u m m a r y ------------------------------------------\n\u2022 Model    : VGG                               \u2022 Statistics: mem                                   \n\u2022 Device   : cuda:0                            \u2022 Parameters Memory Cost: 548.09 MiB, 82.12 %       \n\u2022 Signature: forward(self, x)                  \u2022 Buffers Memory Cost   : 43.12 KiB, 0.01 %         \n\u2022 Input    :                                   \u2022 FeatureMap Memory Cost: 119.31 MiB, 17.88 %       \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;        \u2022 Total Memory Cost     : 667.44 MiB                \n</pre> <pre>after customization, column names of mem report are: ('ID', 'Operation_Name', 'Operation_Type', 'Param Cost', \n'Buffer_Cost', 'Output_Cost', 'Total')\n</pre> In\u00a0[92]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(f\"origin column order of mem report is: {model.table_cols('mem')}\")\n\n# method 1\ntb, data = model.profile(\n    \"mem\",\n    no_tree=True,\n    pick_cols=[\n        \"Operation_Type\", \n        \"Operation_Name\", \n        \"ID\",\n        \"Param Cost\", \n        \"Buffer_Cost\", \n        \"Output_Cost\", \n        \"Total\"\n    ],\n)\n\nprint(f\"after customization, column order of mem report is: {model.table_cols('mem')}\")\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(f\"origin column order of mem report is: {model.table_cols('mem')}\")  # method 1 tb, data = model.profile(     \"mem\",     no_tree=True,     pick_cols=[         \"Operation_Type\",          \"Operation_Name\",          \"ID\",         \"Param Cost\",          \"Buffer_Cost\",          \"Output_Cost\",          \"Total\"     ], )  print(f\"after customization, column order of mem report is: {model.table_cols('mem')}\") <pre>origin column order of mem report is: ('ID', 'Operation_Name', 'Operation_Type', 'Param Cost', 'Buffer_Cost', \n'Output_Cost', 'Total')\n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502  Operation_Type   \u2502 Operation_Name \u2502  ID  \u2502 Param Cost \u2502 Buffer_Cost \u2502 Output_Cost \u2502   Total    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    Sequential     \u2502    features    \u2502  1   \u2502 76.43 MiB  \u2502  43.12 KiB  \u2502 119.15 MiB  \u2502 195.62 MiB \u2502\n\u2502      Conv2d       \u2502       0        \u2502 1.1  \u2502   7 KiB    \u2502      -      \u2502  12.25 MiB  \u2502 12.26 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       1        \u2502 1.2  \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       2        \u2502 1.3  \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       3        \u2502 1.4  \u2502 144.25 KiB \u2502      -      \u2502  12.25 MiB  \u2502 12.39 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       4        \u2502 1.5  \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       5        \u2502 1.6  \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     MaxPool2d     \u2502       6        \u2502 1.7  \u2502     -      \u2502      -      \u2502  3.06 MiB   \u2502  3.06 MiB  \u2502\n\u2502      Conv2d       \u2502       7        \u2502 1.8  \u2502 288.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.41 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       8        \u2502 1.9  \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       9        \u2502 1.10 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       10       \u2502 1.11 \u2502 576.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.69 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       11       \u2502 1.12 \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       12       \u2502 1.13 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     MaxPool2d     \u2502       13       \u2502 1.14 \u2502     -      \u2502      -      \u2502  1.53 MiB   \u2502  1.53 MiB  \u2502\n\u2502      Conv2d       \u2502       14       \u2502 1.15 \u2502  1.13 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  4.19 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       15       \u2502 1.16 \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       16       \u2502 1.17 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       17       \u2502 1.18 \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       18       \u2502 1.19 \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       19       \u2502 1.20 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       20       \u2502 1.21 \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       21       \u2502 1.22 \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       22       \u2502 1.23 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       23       \u2502 1.24 \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       24       \u2502 1.25 \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       25       \u2502 1.26 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     MaxPool2d     \u2502       26       \u2502 1.27 \u2502     -      \u2502      -      \u2502   784 KiB   \u2502  784 KiB   \u2502\n\u2502      Conv2d       \u2502       27       \u2502 1.28 \u2502  4.50 MiB  \u2502      -      \u2502  1.53 MiB   \u2502  6.03 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       28       \u2502 1.29 \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       29       \u2502 1.30 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       30       \u2502 1.31 \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       31       \u2502 1.32 \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       32       \u2502 1.33 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       33       \u2502 1.34 \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       34       \u2502 1.35 \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       35       \u2502 1.36 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       36       \u2502 1.37 \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       37       \u2502 1.38 \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       38       \u2502 1.39 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     MaxPool2d     \u2502       39       \u2502 1.40 \u2502     -      \u2502      -      \u2502   392 KiB   \u2502  392 KiB   \u2502\n\u2502      Conv2d       \u2502       40       \u2502 1.41 \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       41       \u2502 1.42 \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502   ReLU(inplace)   \u2502       42       \u2502 1.43 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       43       \u2502 1.44 \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       44       \u2502 1.45 \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502   ReLU(inplace)   \u2502       45       \u2502 1.46 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       46       \u2502 1.47 \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       47       \u2502 1.48 \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502   ReLU(inplace)   \u2502       48       \u2502 1.49 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Conv2d       \u2502       49       \u2502 1.50 \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502    BatchNorm2d    \u2502       50       \u2502 1.51 \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502   ReLU(inplace)   \u2502       51       \u2502 1.52 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502     MaxPool2d     \u2502       52       \u2502 1.53 \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502 AdaptiveAvgPool2d \u2502    avgpool     \u2502  2   \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502    Sequential     \u2502   classifier   \u2502  3   \u2502 471.66 MiB \u2502    0.00     \u2502  67.91 KiB  \u2502 471.73 MiB \u2502\n\u2502      Linear       \u2502       0        \u2502 3.1  \u2502 392.02 MiB \u2502      -      \u2502   16 KiB    \u2502 392.03 MiB \u2502\n\u2502   ReLU(inplace)   \u2502       1        \u2502 3.2  \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Dropout      \u2502       2        \u2502 3.3  \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502      Linear       \u2502       3        \u2502 3.4  \u2502 64.02 MiB  \u2502      -      \u2502   16 KiB    \u2502 64.03 MiB  \u2502\n\u2502   ReLU(inplace)   \u2502       4        \u2502 3.5  \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502      Dropout      \u2502       5        \u2502 3.6  \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502      Linear       \u2502       6        \u2502 3.7  \u2502 15.63 MiB  \u2502      -      \u2502  3.91 KiB   \u2502 15.63 MiB  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n------------------------------------------ s u m m a r y ------------------------------------------\n\u2022 Model    : VGG                               \u2022 Statistics: mem                                   \n\u2022 Device   : cuda:0                            \u2022 Parameters Memory Cost: 548.09 MiB, 82.12 %       \n\u2022 Signature: forward(self, x)                  \u2022 Buffers Memory Cost   : 43.12 KiB, 0.01 %         \n\u2022 Input    :                                   \u2022 FeatureMap Memory Cost: 119.31 MiB, 17.88 %       \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;        \u2022 Total Memory Cost     : 667.44 MiB                \n</pre> <pre>after customization, column order of mem report is: ('ID', 'Operation_Name', 'Operation_Type', 'Param Cost', \n'Buffer_Cost', 'Output_Cost', 'Total')\n</pre> In\u00a0[93]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(f\"origin column set of mem report is: {model.table_cols('mem')}\")\n\n# Method 1\ntb, data = model.profile(\n    \"mem\",\n    no_tree=True,\n    exclude_cols=[\"Operation_Type\"],\n)\n\nprint(f\"after customization, column set of mem report is: {model.table_cols('mem')}\")\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(f\"origin column set of mem report is: {model.table_cols('mem')}\")  # Method 1 tb, data = model.profile(     \"mem\",     no_tree=True,     exclude_cols=[\"Operation_Type\"], )  print(f\"after customization, column set of mem report is: {model.table_cols('mem')}\") <pre>origin column set of mem report is: ('ID', 'Operation_Name', 'Operation_Type', 'Param Cost', 'Buffer_Cost', \n'Output_Cost', 'Total')\n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502  ID  \u2502 Operation_Name \u2502 Param Cost \u2502 Buffer_Cost \u2502 Output_Cost \u2502   Total    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  1   \u2502    features    \u2502 76.43 MiB  \u2502  43.12 KiB  \u2502 119.15 MiB  \u2502 195.62 MiB \u2502\n\u2502 1.1  \u2502       0        \u2502   7 KiB    \u2502      -      \u2502  12.25 MiB  \u2502 12.26 MiB  \u2502\n\u2502 1.2  \u2502       1        \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502 1.3  \u2502       2        \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.4  \u2502       3        \u2502 144.25 KiB \u2502      -      \u2502  12.25 MiB  \u2502 12.39 MiB  \u2502\n\u2502 1.5  \u2502       4        \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502 1.6  \u2502       5        \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.7  \u2502       6        \u2502     -      \u2502      -      \u2502  3.06 MiB   \u2502  3.06 MiB  \u2502\n\u2502 1.8  \u2502       7        \u2502 288.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.41 MiB  \u2502\n\u2502 1.9  \u2502       8        \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502 1.10 \u2502       9        \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.11 \u2502       10       \u2502 576.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.69 MiB  \u2502\n\u2502 1.12 \u2502       11       \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502 1.13 \u2502       12       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.14 \u2502       13       \u2502     -      \u2502      -      \u2502  1.53 MiB   \u2502  1.53 MiB  \u2502\n\u2502 1.15 \u2502       14       \u2502  1.13 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  4.19 MiB  \u2502\n\u2502 1.16 \u2502       15       \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.17 \u2502       16       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.18 \u2502       17       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502 1.19 \u2502       18       \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.20 \u2502       19       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.21 \u2502       20       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502 1.22 \u2502       21       \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.23 \u2502       22       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.24 \u2502       23       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502 1.25 \u2502       24       \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.26 \u2502       25       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.27 \u2502       26       \u2502     -      \u2502      -      \u2502   784 KiB   \u2502  784 KiB   \u2502\n\u2502 1.28 \u2502       27       \u2502  4.50 MiB  \u2502      -      \u2502  1.53 MiB   \u2502  6.03 MiB  \u2502\n\u2502 1.29 \u2502       28       \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.30 \u2502       29       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.31 \u2502       30       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502 1.32 \u2502       31       \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.33 \u2502       32       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.34 \u2502       33       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502 1.35 \u2502       34       \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.36 \u2502       35       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.37 \u2502       36       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502 1.38 \u2502       37       \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.39 \u2502       38       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.40 \u2502       39       \u2502     -      \u2502      -      \u2502   392 KiB   \u2502  392 KiB   \u2502\n\u2502 1.41 \u2502       40       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.42 \u2502       41       \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.43 \u2502       42       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.44 \u2502       43       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.45 \u2502       44       \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.46 \u2502       45       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.47 \u2502       46       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.48 \u2502       47       \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.49 \u2502       48       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.50 \u2502       49       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.51 \u2502       50       \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.52 \u2502       51       \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.53 \u2502       52       \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502  2   \u2502    avgpool     \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502  3   \u2502   classifier   \u2502 471.66 MiB \u2502    0.00     \u2502  67.91 KiB  \u2502 471.73 MiB \u2502\n\u2502 3.1  \u2502       0        \u2502 392.02 MiB \u2502      -      \u2502   16 KiB    \u2502 392.03 MiB \u2502\n\u2502 3.2  \u2502       1        \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 3.3  \u2502       2        \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502 3.4  \u2502       3        \u2502 64.02 MiB  \u2502      -      \u2502   16 KiB    \u2502 64.03 MiB  \u2502\n\u2502 3.5  \u2502       4        \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 3.6  \u2502       5        \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502 3.7  \u2502       6        \u2502 15.63 MiB  \u2502      -      \u2502  3.91 KiB   \u2502 15.63 MiB  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n-------------------------------- s u m m a r y --------------------------------\n\u2022 Model    : VGG                                                               \n\u2022 Device   : cuda:0                                                            \n\u2022 Signature: forward(self, x)                                                  \n\u2022 Input    :                                                                   \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                                        \n                                                                               \n\u2022 Statistics: mem                                                              \n\u2022 Parameters Memory Cost: 548.09 MiB, 82.12 %                                  \n\u2022 Buffers Memory Cost   : 43.12 KiB, 0.01 %                                    \n\u2022 FeatureMap Memory Cost: 119.31 MiB, 17.88 %                                  \n\u2022 Total Memory Cost     : 667.44 MiB                                           \n</pre> <pre>after customization, column set of mem report is: ('ID', 'Operation_Name', 'Operation_Type', 'Param Cost', \n'Buffer_Cost', 'Output_Cost', 'Total')\n</pre> In\u00a0[94]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(f\"origin column set of mem report is: {model.table_cols('mem')}\")\n\n# Method 2\ntb, data = model.profile(\n    \"mem\",\n    no_tree=True,\n    pick_cols=[\n        \"ID\",\n        \"Param Cost\", \n        \"Buffer_Cost\", \n        \"Output_Cost\", \n        \"Total\"\n    ],\n)\n\nprint(f\"after customization, column set of mem report is: {model.table_cols('mem')}\")\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(f\"origin column set of mem report is: {model.table_cols('mem')}\")  # Method 2 tb, data = model.profile(     \"mem\",     no_tree=True,     pick_cols=[         \"ID\",         \"Param Cost\",          \"Buffer_Cost\",          \"Output_Cost\",          \"Total\"     ], )  print(f\"after customization, column set of mem report is: {model.table_cols('mem')}\") <pre>origin column set of mem report is: ('ID', 'Operation_Name', 'Operation_Type', 'Param Cost', 'Buffer_Cost', \n'Output_Cost', 'Total')\n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502  ID  \u2502 Param Cost \u2502 Buffer_Cost \u2502 Output_Cost \u2502   Total    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  1   \u2502 76.43 MiB  \u2502  43.12 KiB  \u2502 119.15 MiB  \u2502 195.62 MiB \u2502\n\u2502 1.1  \u2502   7 KiB    \u2502      -      \u2502  12.25 MiB  \u2502 12.26 MiB  \u2502\n\u2502 1.2  \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502 1.3  \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.4  \u2502 144.25 KiB \u2502      -      \u2502  12.25 MiB  \u2502 12.39 MiB  \u2502\n\u2502 1.5  \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502 1.6  \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.7  \u2502     -      \u2502      -      \u2502  3.06 MiB   \u2502  3.06 MiB  \u2502\n\u2502 1.8  \u2502 288.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.41 MiB  \u2502\n\u2502 1.9  \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502 1.10 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.11 \u2502 576.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.69 MiB  \u2502\n\u2502 1.12 \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502 1.13 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.14 \u2502     -      \u2502      -      \u2502  1.53 MiB   \u2502  1.53 MiB  \u2502\n\u2502 1.15 \u2502  1.13 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  4.19 MiB  \u2502\n\u2502 1.16 \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.17 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.18 \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502 1.19 \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.20 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.21 \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502 1.22 \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.23 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.24 \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502 1.25 \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502 1.26 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.27 \u2502     -      \u2502      -      \u2502   784 KiB   \u2502  784 KiB   \u2502\n\u2502 1.28 \u2502  4.50 MiB  \u2502      -      \u2502  1.53 MiB   \u2502  6.03 MiB  \u2502\n\u2502 1.29 \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.30 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.31 \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502 1.32 \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.33 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.34 \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502 1.35 \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.36 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.37 \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502 1.38 \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502 1.39 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.40 \u2502     -      \u2502      -      \u2502   392 KiB   \u2502  392 KiB   \u2502\n\u2502 1.41 \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.42 \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.43 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.44 \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.45 \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.46 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.47 \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.48 \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.49 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.50 \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502 1.51 \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502 1.52 \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 1.53 \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502  2   \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502  3   \u2502 471.66 MiB \u2502    0.00     \u2502  67.91 KiB  \u2502 471.73 MiB \u2502\n\u2502 3.1  \u2502 392.02 MiB \u2502      -      \u2502   16 KiB    \u2502 392.03 MiB \u2502\n\u2502 3.2  \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 3.3  \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502 3.4  \u2502 64.02 MiB  \u2502      -      \u2502   16 KiB    \u2502 64.03 MiB  \u2502\n\u2502 3.5  \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502 3.6  \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502 3.7  \u2502 15.63 MiB  \u2502      -      \u2502  3.91 KiB   \u2502 15.63 MiB  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n----------------------- s u m m a r y ------------------------\n\u2022 Model    : VGG                                              \n\u2022 Device   : cuda:0                                           \n\u2022 Signature: forward(self, x)                                 \n\u2022 Input    :                                                  \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                       \n                                                              \n\u2022 Statistics: mem                                             \n\u2022 Parameters Memory Cost: 548.09 MiB, 82.12 %                 \n\u2022 Buffers Memory Cost   : 43.12 KiB, 0.01 %                   \n\u2022 FeatureMap Memory Cost: 119.31 MiB, 17.88 %                 \n\u2022 Total Memory Cost     : 667.44 MiB                          \n</pre> <pre>after customization, column set of mem report is: ('ID', 'Operation_Name', 'Operation_Type', 'Param Cost', \n'Buffer_Cost', 'Output_Cost', 'Total')\n</pre> In\u00a0[95]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nimport polars as pl\nfrom polars.series.series import ArrayLike\n\ndef newcol_logic(df: pl.DataFrame) -&gt; ArrayLike:\n    \"\"\"Requirements for the function to generate a new column:\n    \n    1. must have only one argument(name irrelevant) to receive a `polars.DataFrame` object, \n      which is the underlying datasheet of the report for corresponding statistic. For safty reason,\n      the pass-in value is a copy of the original dataframe.\n\n    2. must return a 1D array-like data such as polars.Series, lists, tuples, ndarrays, etc.\n\n    3. the length of the return value must match the row number of the pass-in dataframe.\n      For instance , should be equal to `len(df.rows())` in this example.\n\n    Tips: For each data in the table, you can obtain its raw data(see I.1 below) through the `val` attribute.\n      - For `param`, `cal`, and `mem` data, this will return their values in the statistical unit.\n        (see `Customization` tab \u2192 `Units in Raw Data Mode`)\n      - For `ittp` data, it will return a tuple in the format of (benchmark median, benchmark interquartile range).\n    \"\"\"\n    \n    col = df['Total']\n    return col.map_elements(\n        lambda x: f\"{100 * x / model.mem.TotalCost:.4f} %\",\n        return_dtype=str\n    )\n\nprint(f\"origin column set of mem report is: {model.table_cols('mem')}\")\n\n# Add a new column at the left most position to \n# show the percentage of memory each operation uses in the model's total memory.\ntb, data = model.profile(\n    'mem', \n    no_tree = True,\n    newcol_name='Percentage',\n    newcol_func=newcol_logic, # Should be a function to generate a 1D array-like data\n    newcol_type=str, # Data type of the new column\n    # Position index of new column.  Negative indexing is allowed. \n    # If negative index exceeds limit, it's at far left. If positive index exceeds limit, it's at far right. \n    newcol_idx=0, \n    keep_new_col=True # Whether to keep the new column from now on\n)\n\n# if keep_new_col = False\n# this command will output a same set of column names as before\nprint(f\"after customization, column set of mem report is: {model.table_cols('mem')}\")\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  import polars as pl from polars.series.series import ArrayLike  def newcol_logic(df: pl.DataFrame) -&gt; ArrayLike:     \"\"\"Requirements for the function to generate a new column:          1. must have only one argument(name irrelevant) to receive a `polars.DataFrame` object,        which is the underlying datasheet of the report for corresponding statistic. For safty reason,       the pass-in value is a copy of the original dataframe.      2. must return a 1D array-like data such as polars.Series, lists, tuples, ndarrays, etc.      3. the length of the return value must match the row number of the pass-in dataframe.       For instance , should be equal to `len(df.rows())` in this example.      Tips: For each data in the table, you can obtain its raw data(see I.1 below) through the `val` attribute.       - For `param`, `cal`, and `mem` data, this will return their values in the statistical unit.         (see `Customization` tab \u2192 `Units in Raw Data Mode`)       - For `ittp` data, it will return a tuple in the format of (benchmark median, benchmark interquartile range).     \"\"\"          col = df['Total']     return col.map_elements(         lambda x: f\"{100 * x / model.mem.TotalCost:.4f} %\",         return_dtype=str     )  print(f\"origin column set of mem report is: {model.table_cols('mem')}\")  # Add a new column at the left most position to  # show the percentage of memory each operation uses in the model's total memory. tb, data = model.profile(     'mem',      no_tree = True,     newcol_name='Percentage',     newcol_func=newcol_logic, # Should be a function to generate a 1D array-like data     newcol_type=str, # Data type of the new column     # Position index of new column.  Negative indexing is allowed.      # If negative index exceeds limit, it's at far left. If positive index exceeds limit, it's at far right.      newcol_idx=0,      keep_new_col=True # Whether to keep the new column from now on )  # if keep_new_col = False # this command will output a same set of column names as before print(f\"after customization, column set of mem report is: {model.table_cols('mem')}\") <pre>origin column set of mem report is: ('ID', 'Operation_Name', 'Operation_Type', 'Param Cost', 'Buffer_Cost', \n'Output_Cost', 'Total')\n</pre> <pre>\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Percentage \u2502  ID  \u2502 Operation_Name \u2502  Operation_Type   \u2502 Param Cost \u2502 Buffer_Cost \u2502 Output_Cost \u2502   Total    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 29.3091 %  \u2502  1   \u2502    features    \u2502    Sequential     \u2502 76.43 MiB  \u2502  43.12 KiB  \u2502 119.15 MiB  \u2502 195.62 MiB \u2502\n\u2502  1.8364 %  \u2502 1.1  \u2502       0        \u2502      Conv2d       \u2502   7 KiB    \u2502      -      \u2502  12.25 MiB  \u2502 12.26 MiB  \u2502\n\u2502  1.8355 %  \u2502 1.2  \u2502       1        \u2502    BatchNorm2d    \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502     -      \u2502 1.3  \u2502       2        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  1.8565 %  \u2502 1.4  \u2502       3        \u2502      Conv2d       \u2502 144.25 KiB \u2502      -      \u2502  12.25 MiB  \u2502 12.39 MiB  \u2502\n\u2502  1.8355 %  \u2502 1.5  \u2502       4        \u2502    BatchNorm2d    \u2502   512 B    \u2502    520 B    \u2502  12.25 MiB  \u2502 12.25 MiB  \u2502\n\u2502     -      \u2502 1.6  \u2502       5        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  0.4588 %  \u2502 1.7  \u2502       6        \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502  3.06 MiB   \u2502  3.06 MiB  \u2502\n\u2502  0.9599 %  \u2502 1.8  \u2502       7        \u2502      Conv2d       \u2502 288.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.41 MiB  \u2502\n\u2502  0.9180 %  \u2502 1.9  \u2502       8        \u2502    BatchNorm2d    \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502     -      \u2502 1.10 \u2502       9        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  1.0020 %  \u2502 1.11 \u2502       10       \u2502      Conv2d       \u2502 576.50 KiB \u2502      -      \u2502  6.12 MiB   \u2502  6.69 MiB  \u2502\n\u2502  0.9180 %  \u2502 1.12 \u2502       11       \u2502    BatchNorm2d    \u2502   1 KiB    \u2502  1.01 KiB   \u2502  6.12 MiB   \u2502  6.13 MiB  \u2502\n\u2502     -      \u2502 1.13 \u2502       12       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  0.2294 %  \u2502 1.14 \u2502       13       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502  1.53 MiB   \u2502  1.53 MiB  \u2502\n\u2502  0.6275 %  \u2502 1.15 \u2502       14       \u2502      Conv2d       \u2502  1.13 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  4.19 MiB  \u2502\n\u2502  0.4594 %  \u2502 1.16 \u2502       15       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502     -      \u2502 1.17 \u2502       16       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  0.7961 %  \u2502 1.18 \u2502       17       \u2502      Conv2d       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502  0.4594 %  \u2502 1.19 \u2502       18       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502     -      \u2502 1.20 \u2502       19       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  0.7961 %  \u2502 1.21 \u2502       20       \u2502      Conv2d       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502  0.4594 %  \u2502 1.22 \u2502       21       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502     -      \u2502 1.23 \u2502       22       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  0.7961 %  \u2502 1.24 \u2502       23       \u2502      Conv2d       \u2502  2.25 MiB  \u2502      -      \u2502  3.06 MiB   \u2502  5.31 MiB  \u2502\n\u2502  0.4594 %  \u2502 1.25 \u2502       24       \u2502    BatchNorm2d    \u2502   2 KiB    \u2502  2.01 KiB   \u2502  3.06 MiB   \u2502  3.07 MiB  \u2502\n\u2502     -      \u2502 1.26 \u2502       25       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  0.1147 %  \u2502 1.27 \u2502       26       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502   784 KiB   \u2502  784 KiB   \u2502\n\u2502  0.9039 %  \u2502 1.28 \u2502       27       \u2502      Conv2d       \u2502  4.50 MiB  \u2502      -      \u2502  1.53 MiB   \u2502  6.03 MiB  \u2502\n\u2502  0.2306 %  \u2502 1.29 \u2502       28       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502     -      \u2502 1.30 \u2502       29       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  1.5781 %  \u2502 1.31 \u2502       30       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502  0.2306 %  \u2502 1.32 \u2502       31       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502     -      \u2502 1.33 \u2502       32       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  1.5781 %  \u2502 1.34 \u2502       33       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502  0.2306 %  \u2502 1.35 \u2502       34       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502     -      \u2502 1.36 \u2502       35       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  1.5781 %  \u2502 1.37 \u2502       36       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502  1.53 MiB   \u2502 10.53 MiB  \u2502\n\u2502  0.2306 %  \u2502 1.38 \u2502       37       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502  1.53 MiB   \u2502  1.54 MiB  \u2502\n\u2502     -      \u2502 1.39 \u2502       38       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  0.0574 %  \u2502 1.40 \u2502       39       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502   392 KiB   \u2502  392 KiB   \u2502\n\u2502  1.4061 %  \u2502 1.41 \u2502       40       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502  0.0585 %  \u2502 1.42 \u2502       41       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502     -      \u2502 1.43 \u2502       42       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  1.4061 %  \u2502 1.44 \u2502       43       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502  0.0585 %  \u2502 1.45 \u2502       44       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502     -      \u2502 1.46 \u2502       45       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  1.4061 %  \u2502 1.47 \u2502       46       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502  0.0585 %  \u2502 1.48 \u2502       47       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502     -      \u2502 1.49 \u2502       48       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  1.4061 %  \u2502 1.50 \u2502       49       \u2502      Conv2d       \u2502  9.00 MiB  \u2502      -      \u2502   392 KiB   \u2502  9.38 MiB  \u2502\n\u2502  0.0585 %  \u2502 1.51 \u2502       50       \u2502    BatchNorm2d    \u2502   4 KiB    \u2502  4.01 KiB   \u2502   392 KiB   \u2502 400.01 KiB \u2502\n\u2502     -      \u2502 1.52 \u2502       51       \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  0.0143 %  \u2502 1.53 \u2502       52       \u2502     MaxPool2d     \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502  0.0143 %  \u2502  2   \u2502    avgpool     \u2502 AdaptiveAvgPool2d \u2502     -      \u2502      -      \u2502   98 KiB    \u2502   98 KiB   \u2502\n\u2502 70.6766 %  \u2502  3   \u2502   classifier   \u2502    Sequential     \u2502 471.66 MiB \u2502    0.00     \u2502  67.91 KiB  \u2502 471.73 MiB \u2502\n\u2502 58.7362 %  \u2502 3.1  \u2502       0        \u2502      Linear       \u2502 392.02 MiB \u2502      -      \u2502   16 KiB    \u2502 392.03 MiB \u2502\n\u2502     -      \u2502 3.2  \u2502       1        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  0.0023 %  \u2502 3.3  \u2502       2        \u2502      Dropout      \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502  9.5935 %  \u2502 3.4  \u2502       3        \u2502      Linear       \u2502 64.02 MiB  \u2502      -      \u2502   16 KiB    \u2502 64.03 MiB  \u2502\n\u2502     -      \u2502 3.5  \u2502       4        \u2502   ReLU(inplace)   \u2502     -      \u2502      -      \u2502      -      \u2502     -      \u2502\n\u2502  0.0023 %  \u2502 3.6  \u2502       5        \u2502      Dropout      \u2502     -      \u2502      -      \u2502   16 KiB    \u2502   16 KiB   \u2502\n\u2502  2.3422 %  \u2502 3.7  \u2502       6        \u2502      Linear       \u2502 15.63 MiB  \u2502      -      \u2502  3.91 KiB   \u2502 15.63 MiB  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n------------------------------------------------ s u m m a r y -------------------------------------------------\n\u2022 Model    : VGG                                     \u2022 Statistics: mem                                          \n\u2022 Device   : cuda:0                                  \u2022 Parameters Memory Cost: 548.09 MiB, 82.12 %              \n\u2022 Signature: forward(self, x)                        \u2022 Buffers Memory Cost   : 43.12 KiB, 0.01 %                \n\u2022 Input    :                                         \u2022 FeatureMap Memory Cost: 119.31 MiB, 17.88 %              \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;              \u2022 Total Memory Cost     : 667.44 MiB                       \n</pre> <pre>after customization, column set of mem report is: ('Percentage', 'ID', 'Operation_Name', 'Operation_Type', 'Param \nCost', 'Buffer_Cost', 'Output_Cost', 'Total')\n</pre> In\u00a0[96]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\n\"\"\"\nAbout arguments `save_to` and `save_format`:\n\n1. `save_to`: If a directory path is given, `save_format` is needed to create a file path. The file name will be \n  `&lt;model-name&gt;_&lt;statistic-name&gt;` by default. Note that the path doesn't need to exist in advance, `TorchMeter` will \n  automatically create all missing intermediate folders for you.\n\n2. `save_format`: should be a valid file extension. If `save_to` is a file path, and `save_format` is given, then the \n  extension of the given file will be replaced by `save_format`. Now, `TorchMeter` supports export the tarbular report \n  as a `.xlsx` and `.csv` file.\n\"\"\"\n\ntb, data = model.profile(\n    'param',  \n    show=False, # If you just want to export the report instead of displaying it, set `show = False` to avoid additional overhead.\n    save_to='./param_report.xlsx', # or csv\n    save_format=\"xlsx\"\n)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  \"\"\" About arguments `save_to` and `save_format`:  1. `save_to`: If a directory path is given, `save_format` is needed to create a file path. The file name will be    `_` by default. Note that the path doesn't need to exist in advance, `TorchMeter` will    automatically create all missing intermediate folders for you.  2. `save_format`: should be a valid file extension. If `save_to` is a file path, and `save_format` is given, then the    extension of the given file will be replaced by `save_format`. Now, `TorchMeter` supports export the tarbular report    as a `.xlsx` and `.csv` file. \"\"\"  tb, data = model.profile(     'param',       show=False, # If you just want to export the report instead of displaying it, set `show = False` to avoid additional overhead.     save_to='./param_report.xlsx', # or csv     save_format=\"xlsx\" ) <pre>Param data saved to /home/hzy/project/TorchMeter/param_report.xlsx\n</pre> In\u00a0[\u00a0]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\n# You can access the underlying dataframe of a statistic by querying the `table_renderer.stats_data` attribute \n# with its name. Actually, `torchmeter.Meter.table_renderer.stats_data` maintains a dictionary to map the name of a \n# statistic to its dataframe.\nparam_dataframe: pl.DataFrame = model.table_renderer.stats_data[\"param\"]\n\n\n# Then, with the dataframe, you can export it via `torchmeter.Meter.table_renderer.export` method.\n# Here, you can specify the suffix of the file with `file_suffix` argument. Or course, you can save the raw data (see I.1)\n# instead of the readable value by setting `raw_data` argument to `True`.\nmodel.table_renderer.export(\n    df=param_dataframe,\n    save_path=\".\",\n    ext=\"csv\",\n    file_suffix=\"custom_suffix\",\n    raw_data=True\n)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  # You can access the underlying dataframe of a statistic by querying the `table_renderer.stats_data` attribute  # with its name. Actually, `torchmeter.Meter.table_renderer.stats_data` maintains a dictionary to map the name of a  # statistic to its dataframe. param_dataframe: pl.DataFrame = model.table_renderer.stats_data[\"param\"]   # Then, with the dataframe, you can export it via `torchmeter.Meter.table_renderer.export` method. # Here, you can specify the suffix of the file with `file_suffix` argument. Or course, you can save the raw data (see I.1) # instead of the readable value by setting `raw_data` argument to `True`. model.table_renderer.export(     df=param_dataframe,     save_path=\".\",     ext=\"csv\",     file_suffix=\"custom_suffix\",     raw_data=True ) <pre>Custom_suffix data saved to /home/hzy/project/TorchMeter/VGG_custom_suffix.csv\n</pre> In\u00a0[98]: Copied! <pre>from torchmeter import get_config\n\ncfg = get_config()\n\n# just print it, the output will be hierarchically organized\nprint(cfg)\n</pre> from torchmeter import get_config  cfg = get_config()  # just print it, the output will be hierarchically organized print(cfg) <pre>\u2022 Config file: None(default setting below)\n\n\u2022 render_interval: 0 | &lt;int&gt;\n\n\u2022 tree_fold_repeat: True | &lt;bool&gt;\n\n\u2022 tree_repeat_block_args: namespace{\n\u2502   title = [i]Repeat [[b]&lt;repeat_time&gt;[/b]] Times[/] | &lt;str&gt;\n\u2502   title_align = center | &lt;str&gt;\n\u2502   subtitle = None | &lt;NoneType&gt;\n\u2502   subtitle_align = center | &lt;str&gt;\n\u2502   style = dark_goldenrod | &lt;str&gt;\n\u2502   highlight = True | &lt;bool&gt;\n\u2502   box = HEAVY_EDGE | &lt;str&gt;\n\u2502   border_style = dim | &lt;str&gt;\n\u2502   width = None | &lt;NoneType&gt;\n\u2502   height = None | &lt;NoneType&gt;\n\u2502   padding = list(\n\u2502   \u2502   - 0 | &lt;int&gt;\n\u2502   \u2502   - 1 | &lt;int&gt;\n\u2502   \u2514\u2500  )\n\u2502   expand = False | &lt;bool&gt;\n\u2514\u2500  }\n\n\u2022 tree_levels_args: namespace{\n\u2502   default = namespace{\n\u2502   \u2502   label = [b gray35](&lt;node_id&gt;) [green]&lt;name&gt;[/green] [cyan]&lt;type&gt;[/] | &lt;str&gt;\n\u2502   \u2502   style = tree | &lt;str&gt;\n\u2502   \u2502   guide_style = light_coral | &lt;str&gt;\n\u2502   \u2502   highlight = True | &lt;bool&gt;\n\u2502   \u2502   hide_root = False | &lt;bool&gt;\n\u2502   \u2502   expanded = True | &lt;bool&gt;\n\u2502   \u2514\u2500  }\n\u2502   0 = namespace{\n\u2502   \u2502   label = [b light_coral]&lt;name&gt;[/] | &lt;str&gt;\n\u2502   \u2502   guide_style = light_coral | &lt;str&gt;\n\u2502   \u2514\u2500  }\n\u2514\u2500  }\n\n\u2022 table_column_args: namespace{\n\u2502   style = none | &lt;str&gt;\n\u2502   justify = center | &lt;str&gt;\n\u2502   vertical = middle | &lt;str&gt;\n\u2502   overflow = fold | &lt;str&gt;\n\u2502   no_wrap = False | &lt;bool&gt;\n\u2514\u2500  }\n\n\u2022 table_display_args: namespace{\n\u2502   style = spring_green4 | &lt;str&gt;\n\u2502   highlight = True | &lt;bool&gt;\n\u2502   width = None | &lt;NoneType&gt;\n\u2502   min_width = None | &lt;NoneType&gt;\n\u2502   expand = False | &lt;bool&gt;\n\u2502   padding = list(\n\u2502   \u2502   - 0 | &lt;int&gt;\n\u2502   \u2502   - 1 | &lt;int&gt;\n\u2502   \u2514\u2500  )\n\u2502   collapse_padding = False | &lt;bool&gt;\n\u2502   pad_edge = True | &lt;bool&gt;\n\u2502   leading = 0 | &lt;int&gt;\n\u2502   title = None | &lt;NoneType&gt;\n\u2502   title_style = bold | &lt;str&gt;\n\u2502   title_justify = center | &lt;str&gt;\n\u2502   caption = None | &lt;NoneType&gt;\n\u2502   caption_style = None | &lt;NoneType&gt;\n\u2502   caption_justify = center | &lt;str&gt;\n\u2502   show_header = True | &lt;bool&gt;\n\u2502   header_style = bold | &lt;str&gt;\n\u2502   show_footer = False | &lt;bool&gt;\n\u2502   footer_style = italic | &lt;str&gt;\n\u2502   show_lines = False | &lt;bool&gt;\n\u2502   row_styles = None | &lt;NoneType&gt;\n\u2502   show_edge = True | &lt;bool&gt;\n\u2502   box = ROUNDED | &lt;str&gt;\n\u2502   safe_box = True | &lt;bool&gt;\n\u2502   border_style = None | &lt;NoneType&gt;\n\u2514\u2500  }\n\n\u2022 combine: namespace{\n\u2502   horizon_gap = 2 | &lt;int&gt;\n\u2514\u2500  }\n\n\n</pre> In\u00a0[99]: Copied! <pre># Context\n# ------------------------------\n# cfg: the global config object\n\n# access a setting through the way of visiting an attribute\nprint(\n    f\"config_file: {cfg.config_file}\", \n    f\"render time interval: {cfg.render_interval}\",\n    f\"tree default guide line style: {cfg.tree_levels_args.default.guide_style}\",\n    f\"table col justify: {cfg.table_column_args.justify}\",\n    f\"gap between tree and table in profiling: {cfg.combine.horizon_gap}\",\n    sep=\"\\n\"\n)\n</pre> # Context # ------------------------------ # cfg: the global config object  # access a setting through the way of visiting an attribute print(     f\"config_file: {cfg.config_file}\",      f\"render time interval: {cfg.render_interval}\",     f\"tree default guide line style: {cfg.tree_levels_args.default.guide_style}\",     f\"table col justify: {cfg.table_column_args.justify}\",     f\"gap between tree and table in profiling: {cfg.combine.horizon_gap}\",     sep=\"\\n\" ) <pre>config_file: None\nrender time interval: 0\ntree default guide line style: light_coral\ntable col justify: center\ngap between tree and table in profiling: 2\n</pre> In\u00a0[\u00a0]: Copied! <pre># Context\n# ------------------------------\n# cfg: the global config object\n\norigin_val = {\n    \"render_interval\": cfg.render_interval,\n    \"tree_levels_args.default.guide_style\": cfg.tree_levels_args.default.guide_style,\n    \"table_display_args.highlight\": cfg.table_display_args.highlight,\n    \"table_display_args.show_edge\": cfg.table_display_args.show_edge\n}\n\n# You can modify the configuration one-on-one through this way (like attribute access)\ncfg.render_interval = 0.1\ncfg.tree_levels_args.default.guide_style = \"red\"\n\n# For configuration items with sub-configurations, you can make batch modifications in the form of a dictionary.\n# Under the top level, the configuration items which have sub-configurations are: (you can check the structure in H.a)\n# `tree_repeat_block_args`, `tree_levels_args`, `table_column_args`, `table_display_args` and `combine`\ncfg.table_display_args = {\n    \"highlight\": False,\n    \"show_edge\": False\n}\n\n\nfrom operator import attrgetter\nfor i, v in origin_val.items():\n    print(f\"{i}: {v} -&gt; {attrgetter(i)(cfg)}\")\n</pre> # Context # ------------------------------ # cfg: the global config object  origin_val = {     \"render_interval\": cfg.render_interval,     \"tree_levels_args.default.guide_style\": cfg.tree_levels_args.default.guide_style,     \"table_display_args.highlight\": cfg.table_display_args.highlight,     \"table_display_args.show_edge\": cfg.table_display_args.show_edge }  # You can modify the configuration one-on-one through this way (like attribute access) cfg.render_interval = 0.1 cfg.tree_levels_args.default.guide_style = \"red\"  # For configuration items with sub-configurations, you can make batch modifications in the form of a dictionary. # Under the top level, the configuration items which have sub-configurations are: (you can check the structure in H.a) # `tree_repeat_block_args`, `tree_levels_args`, `table_column_args`, `table_display_args` and `combine` cfg.table_display_args = {     \"highlight\": False,     \"show_edge\": False }   from operator import attrgetter for i, v in origin_val.items():     print(f\"{i}: {v} -&gt; {attrgetter(i)(cfg)}\") <pre>render_interval: 0 -&gt; 0.1\n</pre> <pre>tree_levels_args.default.guide_style: light_coral -&gt; red\n</pre> <pre>table_display_args.highlight: True -&gt; False\n</pre> <pre>table_display_args.show_edge: True -&gt; False\n</pre> In\u00a0[101]: Copied! <pre># Context\n# ------------------------------\n# cfg: the global config object\n\ndes = \"./my_config.yaml\"\ncfg.dump(save_path=des)\n\nimport os\nabs_des = os.path.abspath(des)\nif os.path.exists(abs_des):\n    print(f\"config dumped successfully to {abs_des}\")\n</pre> # Context # ------------------------------ # cfg: the global config object  des = \"./my_config.yaml\" cfg.dump(save_path=des)  import os abs_des = os.path.abspath(des) if os.path.exists(abs_des):     print(f\"config dumped successfully to {abs_des}\") <pre>config dumped successfully to /home/hzy/project/TorchMeter/my_config.yaml\n</pre> In\u00a0[102]: Copied! <pre># Context\n# ------------------------------\n# cfg: the global config object\n\norigin_val = {\n    \"render_interval\": cfg.render_interval,\n    \"tree_levels_args.default.guide_style\": cfg.tree_levels_args.default.guide_style,\n    \"table_display_args.highlight\": cfg.table_display_args.highlight,\n    \"table_display_args.show_edge\": cfg.table_display_args.show_edge\n}\n\n# cause the config object is not created by a yaml file,\n# so the `restore()` method will take all configurations to its default value we provided.\ncfg.restore()\n\nfrom operator import attrgetter\nfor i, v in origin_val.items():\n    print(f\"{i}: {v} -&gt; {attrgetter(i)(cfg)}\")\n</pre> # Context # ------------------------------ # cfg: the global config object  origin_val = {     \"render_interval\": cfg.render_interval,     \"tree_levels_args.default.guide_style\": cfg.tree_levels_args.default.guide_style,     \"table_display_args.highlight\": cfg.table_display_args.highlight,     \"table_display_args.show_edge\": cfg.table_display_args.show_edge }  # cause the config object is not created by a yaml file, # so the `restore()` method will take all configurations to its default value we provided. cfg.restore()  from operator import attrgetter for i, v in origin_val.items():     print(f\"{i}: {v} -&gt; {attrgetter(i)(cfg)}\") <pre>render_interval: 0.1 -&gt; 0.15\n</pre> <pre>tree_levels_args.default.guide_style: red -&gt; light_coral\n</pre> <pre>table_display_args.highlight: False -&gt; True\n</pre> <pre>table_display_args.show_edge: False -&gt; True\n</pre> In\u00a0[\u00a0]: Copied! <pre># Context\n# ------------------------------\n# cfg: the global config object\n\nfrom torchmeter import get_config\n\norigin_val = {\n    \"render_interval\": cfg.render_interval,\n    \"tree_levels_args.default.guide_style\": cfg.tree_levels_args.default.guide_style,\n    \"table_display_args.highlight\": cfg.table_display_args.highlight,\n    \"table_display_args.show_edge\": cfg.table_display_args.show_edge\n}\n\nreload_cfg = get_config(config_path=abs_des)\n\nfrom operator import attrgetter\nfor i, v in origin_val.items():\n    print(f\"{i}: {v} -&gt; {attrgetter(i)(cfg)}\")\n</pre> # Context # ------------------------------ # cfg: the global config object  from torchmeter import get_config  origin_val = {     \"render_interval\": cfg.render_interval,     \"tree_levels_args.default.guide_style\": cfg.tree_levels_args.default.guide_style,     \"table_display_args.highlight\": cfg.table_display_args.highlight,     \"table_display_args.show_edge\": cfg.table_display_args.show_edge }  reload_cfg = get_config(config_path=abs_des)  from operator import attrgetter for i, v in origin_val.items():     print(f\"{i}: {v} -&gt; {attrgetter(i)(cfg)}\") <pre>render_interval: 0.15 -&gt; 0.1\n</pre> <pre>tree_levels_args.default.guide_style: light_coral -&gt; red\n</pre> <pre>table_display_args.highlight: True -&gt; False\n</pre> <pre>table_display_args.show_edge: True -&gt; False\n</pre> In\u00a0[104]: Copied! <pre># Before proceeding, discard the previous settings\n\n# Discard above customization settings\ncfg.restore()\n\n# Disable interval output to adapt to Jupyter Notebook\ncfg.render_interval = 0\n</pre> # Before proceeding, discard the previous settings  # Discard above customization settings cfg.restore()  # Disable interval output to adapt to Jupyter Notebook cfg.render_interval = 0 In\u00a0[105]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\ntb, data = model.profile(\"param\", no_tree=True, raw_data=True)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  tb, data = model.profile(\"param\", no_tree=True, raw_data=True) <pre> Operation_Id \u2502 Operation_Name \u2502  Operation_Type   \u2502 Param_Name \u2502 Requires_Grad \u2502 Numeric_Num \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n      1       \u2502    features    \u2502    Sequential     \u2502     -      \u2502       -       \u2502     0.0     \n     1.1      \u2502       0        \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   1728.0    \n     1.1      \u2502       0        \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    64.0     \n     1.2      \u2502       1        \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    64.0     \n     1.2      \u2502       1        \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    64.0     \n     1.3      \u2502       2        \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.4      \u2502       3        \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   36864.0   \n     1.4      \u2502       3        \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    64.0     \n     1.5      \u2502       4        \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    64.0     \n     1.5      \u2502       4        \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    64.0     \n     1.6      \u2502       5        \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.7      \u2502       6        \u2502     MaxPool2d     \u2502     -      \u2502       -       \u2502     0.0     \n     1.8      \u2502       7        \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502   73728.0   \n     1.8      \u2502       7        \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    128.0    \n     1.9      \u2502       8        \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    128.0    \n     1.9      \u2502       8        \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    128.0    \n     1.10     \u2502       9        \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.11     \u2502       10       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  147456.0   \n     1.11     \u2502       10       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    128.0    \n     1.12     \u2502       11       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    128.0    \n     1.12     \u2502       11       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    128.0    \n     1.13     \u2502       12       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.14     \u2502       13       \u2502     MaxPool2d     \u2502     -      \u2502       -       \u2502     0.0     \n     1.15     \u2502       14       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  294912.0   \n     1.15     \u2502       14       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    256.0    \n     1.16     \u2502       15       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    256.0    \n     1.16     \u2502       15       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    256.0    \n     1.17     \u2502       16       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.18     \u2502       17       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  589824.0   \n     1.18     \u2502       17       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    256.0    \n     1.19     \u2502       18       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    256.0    \n     1.19     \u2502       18       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    256.0    \n     1.20     \u2502       19       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.21     \u2502       20       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  589824.0   \n     1.21     \u2502       20       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    256.0    \n     1.22     \u2502       21       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    256.0    \n     1.22     \u2502       21       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    256.0    \n     1.23     \u2502       22       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.24     \u2502       23       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  589824.0   \n     1.24     \u2502       23       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    256.0    \n     1.25     \u2502       24       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    256.0    \n     1.25     \u2502       24       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    256.0    \n     1.26     \u2502       25       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.27     \u2502       26       \u2502     MaxPool2d     \u2502     -      \u2502       -       \u2502     0.0     \n     1.28     \u2502       27       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  1179648.0  \n     1.28     \u2502       27       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    512.0    \n     1.29     \u2502       28       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    512.0    \n     1.29     \u2502       28       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    512.0    \n     1.30     \u2502       29       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.31     \u2502       30       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  2359296.0  \n     1.31     \u2502       30       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    512.0    \n     1.32     \u2502       31       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    512.0    \n     1.32     \u2502       31       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    512.0    \n     1.33     \u2502       32       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.34     \u2502       33       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  2359296.0  \n     1.34     \u2502       33       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    512.0    \n     1.35     \u2502       34       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    512.0    \n     1.35     \u2502       34       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    512.0    \n     1.36     \u2502       35       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.37     \u2502       36       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  2359296.0  \n     1.37     \u2502       36       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    512.0    \n     1.38     \u2502       37       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    512.0    \n     1.38     \u2502       37       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    512.0    \n     1.39     \u2502       38       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.40     \u2502       39       \u2502     MaxPool2d     \u2502     -      \u2502       -       \u2502     0.0     \n     1.41     \u2502       40       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  2359296.0  \n     1.41     \u2502       40       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    512.0    \n     1.42     \u2502       41       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    512.0    \n     1.42     \u2502       41       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    512.0    \n     1.43     \u2502       42       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.44     \u2502       43       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  2359296.0  \n     1.44     \u2502       43       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    512.0    \n     1.45     \u2502       44       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    512.0    \n     1.45     \u2502       44       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    512.0    \n     1.46     \u2502       45       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.47     \u2502       46       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  2359296.0  \n     1.47     \u2502       46       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    512.0    \n     1.48     \u2502       47       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    512.0    \n     1.48     \u2502       47       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    512.0    \n     1.49     \u2502       48       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.50     \u2502       49       \u2502      Conv2d       \u2502   weight   \u2502     False     \u2502  2359296.0  \n     1.50     \u2502       49       \u2502      Conv2d       \u2502    bias    \u2502     False     \u2502    512.0    \n     1.51     \u2502       50       \u2502    BatchNorm2d    \u2502   weight   \u2502     False     \u2502    512.0    \n     1.51     \u2502       50       \u2502    BatchNorm2d    \u2502    bias    \u2502     False     \u2502    512.0    \n     1.52     \u2502       51       \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     1.53     \u2502       52       \u2502     MaxPool2d     \u2502     -      \u2502       -       \u2502     0.0     \n      2       \u2502    avgpool     \u2502 AdaptiveAvgPool2d \u2502     -      \u2502       -       \u2502     0.0     \n      3       \u2502   classifier   \u2502    Sequential     \u2502     -      \u2502       -       \u2502     0.0     \n     3.1      \u2502       0        \u2502      Linear       \u2502   weight   \u2502     True      \u2502 102760448.0 \n     3.1      \u2502       0        \u2502      Linear       \u2502    bias    \u2502     True      \u2502   4096.0    \n     3.2      \u2502       1        \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     3.3      \u2502       2        \u2502      Dropout      \u2502     -      \u2502       -       \u2502     0.0     \n     3.4      \u2502       3        \u2502      Linear       \u2502   weight   \u2502     True      \u2502 16777216.0  \n     3.4      \u2502       3        \u2502      Linear       \u2502    bias    \u2502     True      \u2502   4096.0    \n     3.5      \u2502       4        \u2502       ReLU        \u2502     -      \u2502       -       \u2502     0.0     \n     3.6      \u2502       5        \u2502      Dropout      \u2502     -      \u2502       -       \u2502     0.0     \n     3.7      \u2502       6        \u2502      Linear       \u2502   weight   \u2502     True      \u2502  4096000.0  \n     3.7      \u2502       6        \u2502      Linear       \u2502    bias    \u2502     True      \u2502   1000.0    \n--------------------------------------- s u m m a r y ----------------------------------------\n\u2022 Model    : VGG                                  \u2022 Statistics: param                         \n\u2022 Device   : cuda:0                               \u2022 Learnable Parameters Num: 123.64 M        \n\u2022 Signature: forward(self, x)                     \u2022 Total Parameters Num    : 143.68 M        \n\u2022 Input    :                                                                                  \n   x = Shape([1, 3, 224, 224]) &lt;Tensor&gt;                                                       \n</pre> In\u00a0[106]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nfor s in (\"param\", \"cal\", \"mem\", \"ittp\"):\n    print(f\"Default column set of {s} report is: \\n{model.table_cols(s)}\")\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  for s in (\"param\", \"cal\", \"mem\", \"ittp\"):     print(f\"Default column set of {s} report is: \\n{model.table_cols(s)}\") <pre>Default column set of param report is: \n('Operation_Id', 'Operation_Name', 'Operation_Type', 'Param_Name', 'Requires_Grad', 'Numeric_Num')\n</pre> <pre>Default column set of cal report is: \n('Operation_Id', 'Operation_Name', 'Operation_Type', 'Kernel_Size', 'Bias', 'Input', 'Output', 'MACs', 'FLOPs')\n</pre> <pre>Default column set of mem report is: \n('Percentage', 'ID', 'Operation_Name', 'Operation_Type', 'Param Cost', 'Buffer_Cost', 'Output_Cost', 'Total')\n</pre> <pre>Default column set of ittp report is: \n('Operation_Id', 'Operation_Name', 'Operation_Type', 'Infer_Time', 'Throughput')\n</pre> In\u00a0[107]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\nprint(f\"model now on {model.device}\")\n\nmodel.to(\"cpu\")\nprint(f\"model now on {model.device}\")\n\nmodel.device = \"cuda:0\"\nprint(f\"model now on {model.device}\")\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  print(f\"model now on {model.device}\")  model.to(\"cpu\") print(f\"model now on {model.device}\")  model.device = \"cuda:0\" print(f\"model now on {model.device}\") <pre>model now on cuda:0\n</pre> <pre>model now on cpu\n</pre> <pre>model now on cuda:0\n</pre> In\u00a0[\u00a0]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\n# output a list of tuples, each item represents a node in the operation tree with format (node-id, layer-name)\nprint(model.subnodes)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  # output a list of tuples, each item represents a node in the operation tree with format (node-id, layer-name) print(model.subnodes) <pre>[\n    '(0) VGG',\n    '(1) features',\n    '(2) avgpool',\n    '(3) classifier',\n    '(1.1) 0',\n    '(1.2) 1',\n    '(1.3) 2',\n    '(1.4) 3',\n    '(1.5) 4',\n    '(1.6) 5',\n    '(1.7) 6',\n    '(1.8) 7',\n    '(1.9) 8',\n    '(1.10) 9',\n    '(1.11) 10',\n    '(1.12) 11',\n    '(1.13) 12',\n    '(1.14) 13',\n    '(1.15) 14',\n    '(1.16) 15',\n    '(1.17) 16',\n    '(1.18) 17',\n    '(1.19) 18',\n    '(1.20) 19',\n    '(1.21) 20',\n    '(1.22) 21',\n    '(1.23) 22',\n    '(1.24) 23',\n    '(1.25) 24',\n    '(1.26) 25',\n    '(1.27) 26',\n    '(1.28) 27',\n    '(1.29) 28',\n    '(1.30) 29',\n    '(1.31) 30',\n    '(1.32) 31',\n    '(1.33) 32',\n    '(1.34) 33',\n    '(1.35) 34',\n    '(1.36) 35',\n    '(1.37) 36',\n    '(1.38) 37',\n    '(1.39) 38',\n    '(1.40) 39',\n    '(1.41) 40',\n    '(1.42) 41',\n    '(1.43) 42',\n    '(1.44) 43',\n    '(1.45) 44',\n    '(1.46) 45',\n    '(1.47) 46',\n    '(1.48) 47',\n    '(1.49) 48',\n    '(1.50) 49',\n    '(1.51) 50',\n    '(1.52) 51',\n    '(1.53) 52',\n    '(3.1) 0',\n    '(3.2) 1',\n    '(3.3) 2',\n    '(3.4) 3',\n    '(3.5) 4',\n    '(3.6) 5',\n    '(3.7) 6'\n]\n</pre> In\u00a0[\u00a0]: Copied! <pre># Context\n# --------------------------------------------------------------------------------\n# model: Instance of `torchmeter.Meter` which acts like a decorator of your model\n\n# Input the node ID, which is the former part of an item in the output of `torchmeter.Meter.subnodes`, as shown above.\nclassify_head = model.rebase(\"3\")\n\n# now the model analysis scope changes to its submodule \u2014\u2014 the `classifier`\nprint(classify_head.structure)\n</pre> # Context # -------------------------------------------------------------------------------- # model: Instance of `torchmeter.Meter` which acts like a decorator of your model  # Input the node ID, which is the former part of an item in the output of `torchmeter.Meter.subnodes`, as shown above. classify_head = model.rebase(\"3\")  # now the model analysis scope changes to its submodule \u2014\u2014 the `classifier` print(classify_head.structure) <pre></pre> <pre>Finish Scanning model in 0.0017 seconds\n</pre> <pre>Sequential\n\u251c\u2500\u2500 (1) 0 Linear\n\u251c\u2500\u2500 (2) 1 ReLU\n\u251c\u2500\u2500 (3) 2 Dropout\n\u251c\u2500\u2500 (4) 3 Linear\n\u251c\u2500\u2500 (5) 4 ReLU\n\u251c\u2500\u2500 (6) 5 Dropout\n\u2514\u2500\u2500 (7) 6 Linear\n</pre>"},{"location":"demo/#a-wrap-your-model-with-meter","title":"A. Wrap your model with Meter\u00b6","text":""},{"location":"demo/#b-zero-intrusion-proxy","title":"B. Zero-Intrusion Proxy\u00b6","text":"<p>Use the instance of <code>Meter</code> as like using the underlying model</p>"},{"location":"demo/#ba-access-attrsmethods-of-underlying-model","title":"B.a Access Attrs/Methods of Underlying Model\u00b6","text":""},{"location":"demo/#bb-access-attrsmethods-of-meter-class","title":"B.b Access Attrs/Methods of Meter class\u00b6","text":""},{"location":"demo/#bc-access-attrsmethods-sharing-same-names","title":"B.c Access Attrs/Methods Sharing Same Names\u00b6","text":"<p>In this case, you can directly access the attrs/methods of the <code>Meter</code> instance by name. To access those of the underlying model, add the prefix <code>ORIGIN_</code> to the name.</p>"},{"location":"demo/#c-automatic-device-synchronization","title":"C. Automatic Device Synchronization\u00b6","text":"<ul> <li>No need to concern about the device mismatch between the model and input.</li> <li>Always get ready to perform a feed forward \ud83d\ude80</li> </ul>"},{"location":"demo/#d-model-structure-analysis","title":"D. Model Structure Analysis\u00b6","text":"<p>This feature will help you quickly understand the model architecture, especially when there are a large number of repetitive structures.</p>"},{"location":"demo/#da-enable-repeat-block-folding","title":"D.a Enable Repeat Block Folding\u00b6","text":""},{"location":"demo/#db-disable-repeat-block-folding","title":"D.b Disable Repeat Block Folding\u00b6","text":""},{"location":"demo/#e-full-stack-model-analytics","title":"E. Full-Stack Model Analytics\u00b6","text":"<p><code>TorchMeter</code> give you two ways to quantify your model performance:</p> <ol> <li>Overall Report: A quick summary of specific statistics.</li> <li>Layer-wise Profile: A detailed operation-wise tabular report of specific statistics.</li> </ol>"},{"location":"demo/#ea-model-state","title":"E.a Model State\u00b6","text":"<p>Provide an inspection of your model's basic information, including:</p> <ul> <li>Model type</li> <li>Device the model now on</li> <li>Feed-forward input</li> </ul>"},{"location":"demo/#eb-overall-report","title":"E.b Overall Report\u00b6","text":"<p>Provide a comprehensive report on the overall performance of the model, including all the statistics:</p> <ul> <li>Model state</li> <li>Parameters volumn</li> <li>Calculation burden</li> <li>Memory usage</li> <li>Inference time</li> <li>Throughput</li> </ul>"},{"location":"demo/#ec-layer-wise-profile","title":"E.c Layer-wise Profile\u00b6","text":"<p>Provide a layer-wise, rich-text, detailed tabular report concerning each statistics.</p>"},{"location":"demo/#ec1-parameter-analysis","title":"E.c.1 Parameter Analysis\u00b6","text":""},{"location":"demo/#ec2-computational-profiling","title":"E.c.2 Computational Profiling\u00b6","text":"<p>\u2757\u2757\u2757 You need to give at least one feed-forward before measuring the computational \u2757\u2757\u2757</p>"},{"location":"demo/#ec3-memory-diagnostics","title":"E.c.3 Memory Diagnostics\u00b6","text":"<p>\u2757\u2757\u2757 You need to give at least one feed-forward before measuring the memory usage \u2757\u2757\u2757</p>"},{"location":"demo/#ec4-performance-benchmarking","title":"E.c.4 Performance Benchmarking\u00b6","text":"<p>\u2757\u2757\u2757 You need to give at least one feed-forward before measuring the inference time / throughput \u2757\u2757\u2757</p>"},{"location":"demo/#f-fine-grained-customization","title":"F. Fine-Grained Customization\u00b6","text":"<p><code>TorchMeter</code> provides lots of customization options in following aspects, feel free to customize your style:</p> <ul> <li>Statistics Overview</li> <li>Rich-Text Operation Tree</li> <li>Tabular Report</li> </ul>"},{"location":"demo/#fa-customization-of-statistics-overview","title":"F.a Customization of Statistics Overview\u00b6","text":""},{"location":"demo/#fa1-pick-and-reorder-statistics","title":"F.a.1 Pick and Reorder Statistics\u00b6","text":""},{"location":"demo/#fa2-pure-output-without-warnings","title":"F.a.2 Pure Output without Warnings\u00b6","text":"<p><code>TorchMeter</code> is still in the development stage, and the support for some operations or layers is not yet perfect.</p> <p>Therefore, the current version of <code>TorchMeter</code> may not be able to measure <code>cal</code> (<code>param</code>, <code>mem</code>, and <code>ittp</code> will not be affected) for some operations, and a warning message will be display at this time.</p> <p>We offer an argument to disable this behavior, see below. You can compare the result with that in section <code>E.b</code>.</p>"},{"location":"demo/#fb-customization-of-rich-text-operation-tree","title":"F.b Customization of Rich-Text Operation Tree\u00b6","text":"<p>There are two types of customizations for hierarchical operation tree:</p> <ol> <li>Hierarchical display customization</li> <li>Repeat block customization<ul> <li>Customize the title of the repeat block</li> <li>Customize the overall style of the repeat block</li> <li>Customize the footnote of the repeat block</li> </ul> </li> </ol>"},{"location":"demo/#fb1-customize-the-hierarchical-display","title":"F.b.1 Customize the Hierarchical Display\u00b6","text":"<p>All customization fields can be found in the <code>Default Configuration</code> section in <code>Cheatsheet</code> tab.</p> <p>You can customize the display of a tree level by designating the configurations through the level index, which can be found here.</p>"},{"location":"demo/#fb2-customize-the-repeat-block","title":"F.b.2 Customize the Repeat Block\u00b6","text":""},{"location":"demo/#fb21-customize-the-title","title":"F.b.2.1 Customize the title\u00b6","text":""},{"location":"demo/#fb22-customize-the-style","title":"F.b.2.2 Customize the style\u00b6","text":"<p>All customization fields can be found in the <code>Customization</code> tab.</p>"},{"location":"demo/#fb23-customize-the-footer","title":"F.b.2.3 Customize the footer\u00b6","text":""},{"location":"demo/#fb231-fixed-text","title":"F.b.2.3.1 Fixed Text\u00b6","text":""},{"location":"demo/#fb232-dynamic-text-based-on-tree-node-attributes","title":"F.b.2.3.2 Dynamic Text based on Tree Node Attributes\u00b6","text":"<p>A tree node represents an operation in the model, the attributes of which can be found in <code>Tree Node Attributes</code> section in <code>Cheatsheet</code> tab.</p>"},{"location":"demo/#fb233-dynamic-text-based-on-function","title":"F.b.2.3.3 Dynamic Text based on Function\u00b6","text":""},{"location":"demo/#fc-customization-of-tabular-report","title":"F.c Customization of Tabular Report\u00b6","text":"<p>The customization of tabular report fucos on 3 aspects:</p> <ol> <li>Customize the column/overall style.</li> <li>Enable or not the operation tree.</li> <li>Customize the tabular report structure.</li> </ol>"},{"location":"demo/#fc1-customize-the-columnoverall-style","title":"F.c.1 Customize the Column/Overall Style\u00b6","text":"<p>All customization fields can be found in the <code>Default Configuration</code> section in <code>Cheatsheet</code> tab.</p>"},{"location":"demo/#fc2-enable-the-operation-tree-beside","title":"F.c.2 Enable the Operation Tree Beside\u00b6","text":"<p>\u2757\ufe0f\u2757\ufe0f\u2757\ufe0f When the terminal width is too small or the tree width is too big, \u2757\ufe0f\u2757\ufe0f\u2757\ufe0f the space of the table will be squeezed and reduce the visual experience.</p>"},{"location":"demo/#fc3-customize-tabular-report-structure","title":"F.c.3 Customize Tabular Report Structure\u00b6","text":""},{"location":"demo/#fc31-rename-columns","title":"F.c.3.1 Rename Columns\u00b6","text":""},{"location":"demo/#fc32-rerange-columns","title":"F.c.3.2 Rerange Columns\u00b6","text":"<p>\u2757\ufe0f\u2757\ufe0f\u2757\ufe0f The order of columns will only be changed in rendering, no in the underlying datasheet.</p>"},{"location":"demo/#fc33-delete-columns","title":"F.c.3.3 Delete Columns\u00b6","text":"<p><code>TorchMeter</code> offers 2 argument in method <code>torchmeter.Meter.profile()</code> to achieve this:</p> <ol> <li>Through <code>exclude_cols</code> argument: Specify the columns to be deleted to achieve a small amount of deletion</li> <li>Through <code>pick_cols</code> argument: Implement mass deletion by defining the retained columns.</li> </ol> <p>\u2757\ufe0f\u2757\ufe0f\u2757\ufe0f Note that this feature is only used to adjust the table display and does not actually delete columns, \u2757\ufe0f\u2757\ufe0f\u2757\ufe0f as data cannot be restored once deleted.</p>"},{"location":"demo/#fc34-add-a-new-column","title":"F.c.3.4 Add a New Column\u00b6","text":"<p>By defining the calculation logic for new column values, you can achieve online, real-time data analysis. In other words, the table report is programmable.</p> <p>\u2757\ufe0f\u2757\ufe0f\u2757\ufe0f You can control whether to actually add a new column to the underlying table with the <code>keep_new_col</code> argument.</p>"},{"location":"demo/#g-tabular-report-export","title":"G. Tabular Report Export\u00b6","text":""},{"location":"demo/#ga-instant-export","title":"G.a Instant Export\u00b6","text":"<p>Export the tabular report right after instant rendering. This is very useful in the following cases of immediate, non-permanent operations:</p> <ul> <li>Rename columns while setting <code>keep_custom_name = False</code></li> <li>Change the order of columns</li> <li>Delete columns</li> <li>Add columns while setting <code>keep_new_col = False</code></li> </ul>"},{"location":"demo/#gb-postponed-export","title":"G.b Postponed Export\u00b6","text":"<p>If you've measured a statistic, you can export the underlying datasheet whenever you want. But in this way, you can't customize the datasheet like reordering columns, renaming columns, etc.</p>"},{"location":"demo/#h-centralized-configuration-management","title":"H. Centralized Configuration Management\u00b6","text":""},{"location":"demo/#ha-list-current-configurations","title":"H.a List Current Configurations\u00b6","text":""},{"location":"demo/#hb-retrieve-specific-settings","title":"H.b Retrieve Specific Settings\u00b6","text":""},{"location":"demo/#hc-change-specific-settings","title":"H.c Change Specific Settings\u00b6","text":""},{"location":"demo/#hd-dump-to-disk","title":"H.d Dump to Disk\u00b6","text":"<p>You can dump all the configurations as a <code>yaml</code> file for sharing or reloading in a new session</p>"},{"location":"demo/#he-restore-configuration","title":"H.e Restore Configuration\u00b6","text":"<p>Mess up the configurations? Don't worry, we can restore them to the value in loaded file. If the config object is not created by loading a <code>yaml</code> file, will use the default value in <code>Default Configuration</code> we've prepared for you.</p>"},{"location":"demo/#hf-reload-and-overwrite","title":"H.f Reload and Overwrite\u00b6","text":"<p>With the <code>yaml</code> file exported in <code>H.d</code>, you can easily mirror a config in another session.</p> <p>Or course, you can overwrite the config in current session using the settings in the <code>yaml</code> file.</p>"},{"location":"demo/#i-others","title":"I. Others\u00b6","text":""},{"location":"demo/#i1-raw-data-mode","title":"I.1 Raw Data Mode\u00b6","text":"<p>When this mode is enabled, the statistic data will be represented in the unit at the time of statistics. For details, see <code>Unit Explanation</code>.</p>"},{"location":"demo/#i2-quickview-of-column-names","title":"I.2 Quickview of Column Names\u00b6","text":""},{"location":"demo/#i3-model-migration","title":"I.3 Model Migration\u00b6","text":""},{"location":"demo/#i4-submodule-explore","title":"I.4 Submodule Explore\u00b6","text":"<p>Sometimes, we want to explore a specific submodule of a model to evaluate its performance. In this case, we can use the <code>rebase</code> method in conjunction with the <code>subnodes</code> property to narrow down the model analysis scope to any submodule.</p>"},{"location":"api/core/","title":"Core","text":""},{"location":"api/core/#torchmeter.core.Meter","title":"torchmeter.core.Meter","text":"Python<pre><code>Meter(model: Module, device: Optional[Union[str, device]] = None)\n</code></pre> <p>A comprehensive instrumentation tool for PyTorch model performance analysis and visualization.</p> <p>The <code>Meter</code> class provides end-to-end measurement capabilities for neural networks, including parameter statistics, computational cost analysis, memory usage tracking, inference time and throughput analysis. It serves as a wrapper around <code>PyTorch</code> modules while maintaining full compatibility with native model operations.</p> <p>Key Features:</p> <ol> <li> <p>Zero-Intrusion Proxy</p> <ul> <li>acts as drop-in decorator without any changes of the underlying model</li> <li>Seamlessly integrates with PyTorch modules while preserving full compatibility (attributes and methods)</li> </ul> </li> <li> <p>Full-Stack Model Analytics: Holistic performance analytics across 5 dimensions:</p> <ul> <li>parameter distribution</li> <li>calculation cost: FLOPs/MACs</li> <li>memory access assessment</li> <li>inference latency</li> <li>throughput benchmarking</li> </ul> </li> <li> <p>Rich visualization</p> <ul> <li>Programmable tabular reports with real-time rendering</li> <li>Hierarchical operation tree with smart folding of repeated blocks for model structure insights</li> </ul> </li> <li> <p>Fine-Grained Customization</p> <ul> <li>Real-time hot-reload rendering: Dynamic adjustment of rendering configuration for operation trees,                                 report tables and their nested components</li> <li>Progressive update: Namespace assignment + dictionary batch update</li> </ul> </li> <li> <p>Config-Driven Runtime Management</p> <ul> <li>Centralized control: Singleton-managed global configuration for dynamic behavior adjustment</li> <li>Portable presets: Export/import YAML profiles for runtime behaviors, eliminating repetitive setup</li> </ul> </li> <li> <p>Portability and Practicality</p> <ul> <li>Decoupled pipeline: Separation of data collection and visualization</li> <li>Automatic device synchronization: Maintains production-ready status by keeping model and data co-located</li> <li>Dual-mode reporting with export flexibility:<ul> <li>Measurement units mode vs. raw data mode</li> <li>Multi-format export (<code>CSV</code>/<code>Excel</code>) for analysis integration</li> </ul> </li> </ul> </li> </ol> <p>Core Functionality:</p> <ol> <li> <p>Parameter Analysis</p> <ul> <li>Total/trainable parameter quantification</li> <li>Layer-wise parameter distribution analysis</li> <li>Gradient state tracking (requires_grad flags)</li> </ul> </li> <li> <p>Computational Profiling</p> <ul> <li>FLOPs/MACs precision calculation</li> <li>Operation-wise calculation distribution analysis</li> <li>Dynamic input/output detection (number, type, shape, ...)</li> </ul> </li> <li> <p>Memory Diagnostics</p> <ul> <li>Input/output tensor memory awareness</li> <li>Hierarchical memory consumption analysis</li> </ul> </li> <li> <p>Performance Benchmarking</p> <ul> <li>Auto warm-up phase execution (eliminates cold-start bias)</li> <li>Device-specific high-precision timing</li> <li>Inference latency  &amp; Throughput Benchmarking</li> </ul> </li> <li> <p>Visualization Engine</p> <ul> <li>Centralized configuration management</li> <li>Programmable tabular report<ol> <li>Style customization and real-time rendering</li> <li>Dynamic table structure adjustment</li> <li>Real-time data analysis in programmable way</li> <li>Multi-format data export</li> </ol> </li> <li>Rich-text hierarchical structure tree rendering<ol> <li>Style customization and real-time rendering</li> <li>Smart module folding based on structural equivalence detection</li> </ol> </li> </ul> </li> <li> <p>Cross-Platform Support</p> <ul> <li>Automatic model-data co-location</li> <li>Seamless device transition (CPU/CUDA)</li> </ul> </li> </ol> <p>Attributes:</p> Name Type Description <code>ipt</code> <code>Dict[str, Any]</code> <p>Input arguments for underlying model's <code>forward</code> method.</p> <code>device</code> <code>device</code> <p>Current computation device for model and tensor data in input .</p> <code>model</code> <code>Module</code> <p>The wrapped PyTorch model instance.</p> <code>optree</code> <code>OperationTree</code> <p>A backend hierarchical data structure of model operations.</p> <code>tree_renderer</code> <code>TreeRenderer</code> <p>A renderer for operation tree visualization.</p> <code>table_renderer</code> <code>TabularRenderer</code> <p>A renderer for programmable tabular reports.</p> <code>ittp_warmup</code> <code>int</code> <p>Number of warm-up(i.e., feed-forward inference) iterations before <code>ittp</code> measurement.</p> <code>ittp_benchmark_time</code> <code>int</code> <p>Number of benchmark iterations per operation in measuring <code>ittp</code>.</p> <code>tree_fold_repeat</code> <code>bool</code> <p>Whether to fold repeated blocks in the rendered tree structure.</p> <code>tree_levels_args</code> <code>FlagNameSpace</code> <p>Rendering configuration for various levels of rendered tree structure.</p> <code>tree_repeat_block_args</code> <code>FlagNameSpace</code> <p>Rendering configuration for repeated blocks of rendered tree structure.</p> <code>table_display_args</code> <code>FlagNameSpace</code> <p>Comprehensive rendering configuration for rendered tables.</p> <code>table_column_args</code> <code>FlagNameSpace</code> <p>Rendering configuration for all of the rendered tables' columns.</p> <code>structure</code> <code>Tree</code> <p>A stylized tree representation of the model's operation hierarchy.</p> <code>param</code> <code>ParamsMeter</code> <p>A ParamsMeter instance containing the measured parameter-related statistics.</p> <code>cal</code> <code>CalMeter</code> <p>A CalMeter instance containing the measured computational cost data.</p> <code>mem</code> <code>MemMeter</code> <p>A MemMeter instance containing the measured memory usage data.</p> <code>ittp</code> <code>IttpMeter</code> <p>A IttpMeter instance containing fresh inference time and throughput data.</p> <code>model_info</code> <code>Text</code> <p>A <code>rich.Text</code> object containing the formatted model information.</p> <code>subnodes</code> <code>List[str]</code> <p>A list of all nodes in the operation tree with their IDs and names.</p> <p>Methods:</p> Name Description <code>__call__</code> <p>Execute model inference while maintaining input and model device synchronization.</p> <code>__getattr__</code> <p>Transparently proxy attribute access to the underlying model when not found in Meter instance.</p> <code>__setattr__</code> <p>Prioritize setting attributes on Meter instance first, falling back to the underlying model.</p> <code>__delattr__</code> <p>Try to delete attributes from Meter instance first, fall back to underlying model if needed.</p> <code>to</code> <p>Move the model to the specified device while keeping input and model device synchronization.</p> <code>profile</code> <p>Render a tabular report of the specified statistics with rich visualization.</p> <code>table_cols</code> <p>Get all column names of the backend dataframe for the specified statistics.</p> <code>stat_info</code> <p>Generates a formatted summary of the specified statistics.</p> <code>overview</code> <p>Generates an overview of all statistics in a formatted layout.</p> <code>rebase</code> <p>Rebases the Meter instance to a specific node in the operation tree.</p> Note <ul> <li>Requires at least one forward pass before most measurements become available.</li> <li>Implements lazy evaluation and cache for most statistics (i.e. <code>param</code>, <code>cal</code>, <code>mem</code>).</li> </ul> Example Python<pre><code>import torch\nfrom rich import print\nfrom torchmeter import Meter, get_config\nfrom torchvision import models\n\n# prepare your torch model\nunderlying_model = models.resnet152()\n\n# wrap the model with Meter class\nmodel = Meter(underlying_model)\n\n# Basic usage\ninput = torch.randn(1, 3, 224, 224)\noutput = model(input)  # Standard model execution\n\n# Performance analysis\nprint(model.structure)  # Visualize model hierarchy\nprint(model.param)  # Show parameter statistics\nmodel.profile(\"cal\")  # Display computational cost table\n\n# Automatic device synchronization\nif torch.cuda.is_available():\n    model.to(\"cuda\")\n    model(input)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p><code>PyTorch</code> model to be instrumented for measurement</p> required <code>device</code> <code>Optional[Union[str, device]]</code> <p>Target device for model execution and measurement.                                          Accepts either device string (e.g., <code>cuda:0</code>) or                                          <code>torch.device</code> object. If <code>None</code>, automatically detects                                          model's current device via its parameters.</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If provided model is not a <code>nn.Module</code> instance</p> <code>UserWarning</code> <p>When device is not specified and model contains no parameters (fallback to <code>CPU</code>)</p> <p>Initialization performs following key operations:</p> <ol> <li> <p>Device configuration:</p> <ul> <li>Uses specified device or auto-detects via model parameters</li> <li>Moves model to target device</li> </ul> </li> <li> <p>Measurement infrastructure setup:</p> <ul> <li>Initializes input capture dictionary (<code>_ipt</code>)</li> <li>Builds operation tree (<code>optree</code>) for model structure analysis</li> <li>Prepares renderers for visualization (<code>tree_renderer</code>, <code>table_renderer</code>)</li> </ul> </li> <li> <p>Measurement state initialization:</p> <ul> <li>Resets measurement flags (<code>param</code>/<code>cal</code>/<code>mem</code>)</li> <li>Sets default benchmark parameters (<code>ittp_warmup</code>=50, <code>ittp_benchmark_time</code>=100)</li> <li>Initializes accuracy warning trackers (<code>_has_nocall_nodes</code>, <code>_has_not_support_nodes</code>)</li> </ul> </li> </ol> Example Python<pre><code>from torchmeter import Meter\nfrom torchvision import models\n\nunderlying_model = models.resnet18()\n\n# auto detect device\nmodel = Meter(underlying_model)\n\n# init a gpu model\nmodel = Meter(underlying_model, device=\"cuda\")\nmodel = Meter(underlying_model, device=\"cuda:1\")\n</code></pre> Source code in <code>torchmeter/core.py</code> Python<pre><code>def __init__(self, model: nn.Module, device: Optional[Union[str, tc_device]] = None) -&gt; None:\n    \"\"\"Initialize a Meter instance for model performance measurement and visualization.\n\n    Args:\n        model (nn.Module): `PyTorch` model to be instrumented for measurement\n        device (Optional[Union[str, torch.device]]): Target device for model execution and measurement.\n                                                     Accepts either device string (e.g., `cuda:0`) or\n                                                     `torch.device` object. If `None`, automatically detects\n                                                     model's current device via its parameters.\n\n    Raises:\n        TypeError: If provided model is not a `nn.Module` instance\n        UserWarning: When device is not specified and model contains no parameters (fallback to `CPU`)\n\n    Notes:\n\n    Initialization performs following key operations:\n\n    1. Device configuration:\n        - Uses specified device or auto-detects via model parameters\n        - Moves model to target device\n\n    2. Measurement infrastructure setup:\n        - Initializes input capture dictionary (`_ipt`)\n        - Builds operation tree (`optree`) for model structure analysis\n        - Prepares renderers for visualization (`tree_renderer`, `table_renderer`)\n\n    3. Measurement state initialization:\n        - Resets measurement flags (`param`/`cal`/`mem`)\n        - Sets default benchmark parameters (`ittp_warmup`=50, `ittp_benchmark_time`=100)\n        - Initializes accuracy warning trackers (`_has_nocall_nodes`, `_has_not_support_nodes`)\n\n    Example:\n        ```python\n        from torchmeter import Meter\n        from torchvision import models\n\n        underlying_model = models.resnet18()\n\n        # auto detect device\n        model = Meter(underlying_model)\n\n        # init a gpu model\n        model = Meter(underlying_model, device=\"cuda\")\n        model = Meter(underlying_model, device=\"cuda:1\")\n        ```\n    \"\"\"\n\n    from torchmeter.engine import OperationTree\n    from torchmeter.display import TreeRenderer, TabularRenderer\n\n    if not isinstance(model, nn.Module):\n        raise TypeError(f\"model must be a nn.Module, but got `{type(model).__name__}`.\")\n\n    device = device or self.__device_detect(model)\n    self.__device = tc_device(device) if isinstance(device, str) else device\n    self.model = model.to(self.__device)\n\n    self._ipt: IPT_TYPE = {\"args\": tuple(), \"kwargs\": dict()}  # TODO: self.ipt_infer()\n\n    self.optree = OperationTree(self.model)\n\n    self.tree_renderer = TreeRenderer(self.optree.root)\n    self.table_renderer = TabularRenderer(self.optree.root)\n\n    self.__measure_param = False\n    self.__measure_cal = False\n    self.__measure_mem = False\n    self.ittp_warmup = 50\n    self.ittp_benchmark_time = 100\n\n    self.__has_nocall_nodes: Optional[bool] = None\n    self.__has_not_support_nodes: Optional[bool] = None\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.cal","title":"cal  <code>property</code>","text":"Python<pre><code>cal: CalMeter\n</code></pre> <p>Measures the calculation cost of the model during inference.</p> <p>This property calculates the computational cost (i.e., <code>FLOPs</code> and <code>MACs</code>) for each node in the operation tree during a feed-forward inference pass.</p> <p>Returns:</p> Name Type Description <code>CalMeter</code> <code>CalMeter</code> <p>A CalMeter instance containing the measured computational cost data.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If no input data has been provided (i.e., <code>self._ipt</code> is empty).</p> Notes <ul> <li> <p>You must first invoke the Meter instance (via a forward pass) before accessing this property.</p> </li> <li> <p>The measurement is performed only once for each Meter instance. Subsequent accesses   will return the cached result.</p> </li> <li> <p>The measurement results depend on the model input, and different input tensor sizes   will lead to varying calculation costs, which is normal. For consistent and comparable   results, we recommend using a single sample for measuring all statistics including <code>cal</code>.   This can be achieved by providing a single-sample forward pass to the meter instance whenever   you want.</p> </li> </ul>"},{"location":"api/core/#torchmeter.core.Meter.device","title":"device  <code>property</code> <code>writable</code>","text":"Python<pre><code>device: device\n</code></pre> <p>The device where the model and all input tensors are currently located.</p> <p>Returns:</p> Type Description <code>device</code> <p>torch.device: Current device as a torch.device object.</p>"},{"location":"api/core/#torchmeter.core.Meter.ipt","title":"ipt  <code>property</code>","text":"Python<pre><code>ipt: IPT_TYPE\n</code></pre> <p>Captured underlying model input dictionary.</p> <p>Returns:</p> Type Description <code>IPT_TYPE</code> <p>Dict[str, Any]: A dictionary containing the captured model input.</p> Notes <ul> <li> <p>This property is read-only and cannot be directly modified</p> </li> <li> <p>Returned dictionary containing:</p> <ul> <li><code>args</code> (<code>tuple</code>): Positional arguments passed to the <code>forward()</code> of the underlying model.</li> <li><code>kwargs</code> (<code>dict</code>): Keyword arguments passed to the <code>forward()</code> of the underlying model</li> </ul> </li> <li> <p>Input can only be set/updated through <code>Meter</code> instance calls   (i.e., feed-forward inference of the origin model)</p> </li> <li> <p>If there exists tensor data, its dimensions might directly impact the measurement results   of multiple statistics (e.g. <code>cal</code>, <code>mem</code>, <code>ittp</code>). For consistent and comparable results,   we recommend using a single sample for measuring all statistics. This can be achieved   by providing a single-sample forward pass to the meter instance whenever you want.</p> </li> </ul>"},{"location":"api/core/#torchmeter.core.Meter.ittp","title":"ittp  <code>property</code>","text":"Python<pre><code>ittp: IttpMeter\n</code></pre> <p>Measures the inference time and throughput of the model.</p> <p>This property calculates the inference time and throughput for each node in the operation tree. It performs a warm-up phase followed by a benchmark phase to ensure accurate measurements. The results are returned as an <code>IttpMeter</code> object.</p> <p>Returns:</p> Name Type Description <code>IttpMeter</code> <code>IttpMeter</code> <p>A IttpMeter instance containing fresh inference time and throughput data.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If no input data has been provided (i.e., <code>self._ipt</code> is empty).</p> <code>TypeError</code> <p>If <code>self.ittp_warmup</code> is not an integer.</p> <code>ValueError</code> <p>If <code>self.ittp_warmup</code> is a negative integer.</p> Notes <ul> <li> <p>You must first invoke the Meter instance (via a forward pass) before accessing this property.</p> </li> <li> <p>The measurements are performed on the device specified by <code>meter_instance.device</code> !!!</p> </li> <li> <p>The unit <code>IPS</code> means Input Per Second, which is the number of inferences with given input   per second.</p> </li> <li> <p>Unlike other statistics, the measured result is not cached, so it will be   re-measured every time <code>ittp</code> attribute is accessed.</p> </li> <li> <p>The warm-up phase runs for <code>meter_instance.ittp_warmup</code> iterations to stabilize the measurements.</p> </li> <li> <p>The benchmark phase runs for <code>meter_instance.ittp_benchmark_time</code> iterations per operation.</p> </li> <li> <p>The measurement results depend on the model input, and different input tensor sizes will lead to   varying latencies and throughput, which is normal. For consistent and comparable results, we   recommend using a single sample for measuring all statistics including <code>ittp</code>. This can be   achieved by providing a single-sample forward pass to the meter instance whenever you want.</p> </li> </ul>"},{"location":"api/core/#torchmeter.core.Meter.mem","title":"mem  <code>property</code>","text":"Python<pre><code>mem: MemMeter\n</code></pre> <p>Measures the memory cost of the model during inference.</p> <p>This property calculates the memory usage for each node in the operation tree during a feed-forward inference pass.</p> <p>Returns:</p> Name Type Description <code>MemMeter</code> <code>MemMeter</code> <p>A MemMeter instance containing the measured memory usage data.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If no input data has been provided (i.e., <code>self._ipt</code> is empty).</p> Notes <ul> <li> <p>You must first invoke the Meter instance (via a forward pass) before accessing this property.</p> </li> <li> <p>The measurement is performed only once for each Meter instance. Subsequent accesses   will return the cached result.</p> </li> <li> <p>The measurement results depend on the model input, and different input tensor sizes   will lead to varying memory costs, which is normal. For consistent and comparable   results, we recommend using a single sample for measuring all statistics including   <code>mem</code>. This can be achieved by providing a single-sample forward pass to the meter instance   whenever you want.</p> </li> </ul>"},{"location":"api/core/#torchmeter.core.Meter.model_info","title":"model_info  <code>property</code>","text":"Python<pre><code>model_info: Text\n</code></pre> <p>Generates a formatted summary of the model's basic information.</p> <p>This property provides a detailed summary of the model, including its name, device, forward method signature, and structured input representation.</p> <p>Returns:</p> Name Type Description <code>Text</code> <code>Text</code> <p>A <code>rich.Text</code> object containing the formatted model information.</p> Notes <ul> <li> <p>If no input has been provided (i.e., <code>self._ipt</code> is empty), the input representation will indicate that it is not provided.</p> </li> <li> <p>Otherwise, all the values in <code>self._ipt</code> will correspond to the formal arguments of the <code>forward</code> method, and a structured input representation with type prompts will be generated through the <code>torchmeter.utils.data_repr</code> function.</p> </li> </ul>"},{"location":"api/core/#torchmeter.core.Meter.param","title":"param  <code>property</code>","text":"Python<pre><code>param: ParamsMeter\n</code></pre> <p>Measures the number of model parameters.</p> <p>This property calculates the parameter-related metrics (e.g., number of parameters, trainable parameters) for each node in the operation tree.</p> <p>Returns:</p> Name Type Description <code>ParamsMeter</code> <code>ParamsMeter</code> <p>A ParamsMeter instance containing the measured parameter-related statistics.</p> Notes <p>The measurement is performed only once for each Meter instance. Subsequent accesses will return the cached result.</p>"},{"location":"api/core/#torchmeter.core.Meter.structure","title":"structure  <code>property</code>","text":"Python<pre><code>structure: Tree\n</code></pre> <p>Generate a stylized tree representation of the model's operation hierarchy.</p> <p>This property renders the operation tree based on current configuration settings. The rendering strategy (folded/unfolded) and customization options are determined by the active configuration parameters. Caching is applied to optimize rendering performance when configuration remains unchanged.</p> <p>Returns:</p> Name Type Description <code>Tree</code> <code>Tree</code> <p>A <code>rich.tree.Tree</code> object representing the hierarchical structure of model operations.</p> Notes <ul> <li> <p>Configuration parameters influence rendering behavior, you can access them directly   by <code>metered_model.&lt;param_name&gt;</code></p> <ul> <li><code>tree_fold_repeat</code>: Controls whether a repeated block is rendered as a single block.                       Default to True.</li> <li><code>tree_levels_args</code>: Customizes rendering at different tree levels.</li> <li><code>tree_repeat_block_args</code>: Detailed parameters to control the rendering of the repeat blocks.</li> </ul> </li> <li> <p>Caching mechanism: Reuses cached render result if all configuration parameters remain   unchanged since last render.</p> </li> <li> <p>For information on repeated blocks identification and rendering, please refer to the   description of <code>Meter.tree_fold_repeat</code> property.</p> </li> </ul> Example Python<pre><code>from rich import print\nfrom torchmeter import Meter\nfrom torchvision import models\n\nunderlying_model = models.vit_b_16()\nmodel = Meter(underlying_model)\n\n# use the default configuration\nprint(model.structure)\n\n# reaccess the structure, will be quickly returned\nprint(model.structure)\n\n# use a custom configuration\nmodel.tree_fold_repeat = False\nmodel.tree_levels_args = {\"default\": {\"guide_style\": \"red\"}}\nprint(model.structure)\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.subnodes","title":"subnodes  <code>property</code>","text":"Python<pre><code>subnodes: List[str]\n</code></pre> <p>Retrieves a list of all nodes in the operation tree with their IDs and names.</p> <p>This property returns a formatted list of all nodes in the operation tree, where each node is represented by its ID and name. This is useful for identifying specific nodes when rebasing or inspecting the tree structure.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of strings, each formatted as <code>(node_id) node_name</code>, representing all nodes        in the operation tree.</p>"},{"location":"api/core/#torchmeter.core.Meter.table_column_args","title":"table_column_args  <code>property</code> <code>writable</code>","text":"Python<pre><code>table_column_args: FlagNameSpace\n</code></pre> <p>Gets column rendering configuration for rendered tables.</p> <p>This property directly binds to <code>torchmeter.display.TabularRenderer.col_args</code> to get column-level rendering configuration (e.g., style, justify) for tables generated via <code>Meter.profile()</code>. The configuration persists across all subsequent table renderings until explicitly modified.</p> <p>Returns:</p> Name Type Description <code>FlagNameSpace</code> <code>FlagNameSpace</code> <p>A namespace containing concrete configuration names.            Accessible keys match valid arguments of <code>rich.table.Column</code>.</p>"},{"location":"api/core/#torchmeter.core.Meter.table_display_args","title":"table_display_args  <code>property</code> <code>writable</code>","text":"Python<pre><code>table_display_args: FlagNameSpace\n</code></pre> <p>Gets comprehensive rendering configuration for rendered tables.</p> <p>This property directly binds to <code>torchmeter.display.TabularRenderer.tb_args</code> to get rendering configuration (e.g., style, highlight) for tables generated via <code>Meter.profile()</code>. The configuration persists across all subsequent table renderings until explicitly modified.</p> <p>Returns:</p> Name Type Description <code>FlagNameSpace</code> <code>FlagNameSpace</code> <p>A namespace containing concrete configuration names.            Accessible keys match valid arguments of <code>rich.table.Table</code>.</p>"},{"location":"api/core/#torchmeter.core.Meter.tree_fold_repeat","title":"tree_fold_repeat  <code>property</code> <code>writable</code>","text":"Python<pre><code>tree_fold_repeat: bool\n</code></pre> <p>Controls whether repeated tree blocks are rendered as collapsed panels.</p> <p>This property directly binds to the <code>tree_fold_repeat</code> property in the global configuration. When enabled, repeated operation blocks are collapsed into a single panel during tree rendering via <code>Meter.structure</code>.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True to collapse repeated blocks, False to expand them.</p> Note <ul> <li> <p>Repeated blocks are identified only when two operations exhibit structural equivalence in:</p> <ol> <li>Their own parameter signatures</li> <li>Their child operations' hierarchical parameters</li> <li>The execution order within the operation if it is a container.</li> </ol> </li> <li> <p>The folding feature activates exclusively for such validated repetitive patterns.   All other structures render sequentially following their topological order.</p> </li> <li> <p>If your model doesn't have the repeated blocks mentioned above (like <code>AlexNet</code>),   setting this property True or False won't affect the output.</p> </li> </ul>"},{"location":"api/core/#torchmeter.core.Meter.tree_levels_args","title":"tree_levels_args  <code>property</code> <code>writable</code>","text":"Python<pre><code>tree_levels_args: FlagNameSpace\n</code></pre> <p>Gets rendering configuration for various levels of rendered tree structure.</p> <p>This property directly binds to <code>torchmeter.display.TreeRenderer.tree_levels_args</code> to get rendering configuration (e.g., label, guide_style) for various levels of rendered tree structure generated via <code>Meter.structure</code> property. The configuration persists across all subsequent tree renderings until explicitly modified.</p> <p>Returns:</p> Name Type Description <code>FlagNameSpace</code> <code>FlagNameSpace</code> <p>A nested namespace where the outer-layer keys are the specific tree levels,            and the values are the configuration namespaces for the corresponding levels.            In each configuration namespace, the keys contain the specific configuration names,            which match the valid parameters of <code>rich.tree.Tree</code>.</p>"},{"location":"api/core/#torchmeter.core.Meter.tree_repeat_block_args","title":"tree_repeat_block_args  <code>property</code> <code>writable</code>","text":"Python<pre><code>tree_repeat_block_args: FlagNameSpace\n</code></pre> <p>Gets rendering configuration for repeated blocks of rendered tree structure.</p> <p>This property directly binds to <code>torchmeter.display.TreeRenderer.repeat_block_args</code> to get rendering configuration (e.g., <code>style</code>, <code>highlight</code>) for repeated blocks of rendered tree structure generated via <code>Meter.structure</code> property. The configuration persists across all subsequent tree renderings until explicitly modified.</p> <p>Returns:</p> Name Type Description <code>FlagNameSpace</code> <code>FlagNameSpace</code> <p>A namespace containing concrete configuration names.            Accessible keys match valid arguments of <code>rich.panel.Panel</code>.</p>"},{"location":"api/core/#torchmeter.core.Meter.__call__","title":"__call__","text":"Python<pre><code>__call__(*args, **kwargs) -&gt; Any\n</code></pre> <p>Execute model inference while maintaining input and model device synchronization.</p> <p>This method performs three key operations in order:</p> <ol> <li>Captures input arguments of underlying model's <code>forward</code> method for measurement purposes</li> <li>Align the device where the input tensor is located with the device where the model on.</li> <li>Executes the underlying model's feed-forward inference</li> </ol> <p>Parameters:</p> Name Type Description Default <code>*args</code> <p>Positional arguments of the underlying model's <code>forward</code> method</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments of the underlying model's <code>forward</code> method</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Output from the underlying model's feed-forward inference</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If input data is needed but not provided.           (triggered by <code>_ipt2device()</code> method).</p> Notes <ul> <li> <p>From a macroscopic perspective, this is equivalent to direct model invocation:     <code>meter_instance(input)</code> == <code>model(input)</code></p> </li> <li> <p>You can safely input tensors from different devices; automatic synchronization is handled:</p> <ul> <li>Moves all tensors in the input to current device via <code>_ipt2device()</code></li> <li>Ensures model is on current device before execution</li> </ul> </li> <li> <p>Subsequent calls perform two key operations:</p> <ol> <li>Overwrite captured inputs, enabling <code>ipt</code> updates through normal model invocation</li> <li>Clear cached measurements when input differs (determined by <code>Meter.__is_ipt_changed()</code> rules)</li> </ol> </li> <li> <p>If there exists tensor data, its dimensions might directly impact the measurement results   of multiple statistics (e.g. <code>cal</code>, <code>mem</code>, <code>ittp</code>). For consistent and comparable results,   we recommend using a single sample for measuring all statistics. This can be achieved   by passing in a single batch of sample data whenever you want.</p> </li> </ul> Example Python<pre><code>import torch\nimport torch.nn as nn\nfrom torchmeter import Meter\n\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.conv = nn.Conv2d(3, 10, 3)\n\n    def forward(self, x, y=1):\n        return self.conv(x) + y\n\n\nunderlying_model = MyModel()\nmodel = Meter(underlying_model, device=\"cuda:0\")\n\n# Standard invocation\noutput = model(torch.randn(1, 3, 224, 224))\n\n# Mixed argument types\noutput = model(torch.randn(1, 3, 224, 224), y=2)\n</code></pre> Source code in <code>torchmeter/core.py</code> Python<pre><code>def __call__(self, *args, **kwargs) -&gt; Any:\n    \"\"\"Execute model inference while maintaining input and model device synchronization.\n\n    This method performs three key operations in order:\n\n    1. Captures input arguments of underlying model's `forward` method for measurement purposes\n    2. Align the device where the input tensor is located with the device where the model on.\n    3. Executes the underlying model's feed-forward inference\n\n    Args:\n        *args: Positional arguments of the underlying model's `forward` method\n        **kwargs: Keyword arguments of the underlying model's `forward` method\n\n    Returns:\n        Any: Output from the underlying model's feed-forward inference\n\n    Raises:\n        RuntimeError: If input data is needed but not provided.\n                      (triggered by `_ipt2device()` method).\n\n    Notes:\n        - From a macroscopic perspective, this is equivalent to direct model invocation:\n            `meter_instance(input)` == `model(input)`\n\n        - You can safely input tensors from different devices; automatic synchronization is handled:\n            - Moves all tensors in the input to current device via `_ipt2device()`\n            - Ensures model is on current device before execution\n\n        - Subsequent calls perform two key operations:\n            1. Overwrite captured inputs, enabling `ipt` updates through normal model invocation\n            2. Clear cached measurements when input differs (determined by `Meter.__is_ipt_changed()` rules)\n\n        - If there exists tensor data, its dimensions might directly impact the measurement results\n          of multiple statistics (e.g. `cal`, `mem`, `ittp`). For consistent and comparable results,\n          we recommend using **a single sample** for measuring all statistics. This can be achieved\n          by passing in a single batch of sample data whenever you want.\n\n    Example:\n        ```python\n        import torch\n        import torch.nn as nn\n        from torchmeter import Meter\n\n\n        class MyModel(nn.Module):\n            def __init__(self):\n                super(MyModel, self).__init__()\n                self.conv = nn.Conv2d(3, 10, 3)\n\n            def forward(self, x, y=1):\n                return self.conv(x) + y\n\n\n        underlying_model = MyModel()\n        model = Meter(underlying_model, device=\"cuda:0\")\n\n        # Standard invocation\n        output = model(torch.randn(1, 3, 224, 224))\n\n        # Mixed argument types\n        output = model(torch.randn(1, 3, 224, 224), y=2)\n        ```\n    \"\"\"\n\n    new_ipt: IPT_TYPE = {\"args\": args, \"kwargs\": kwargs}\n    if self.__is_ipt_changed(new_ipt):\n        self.__measure_param = False\n        self.__measure_cal = False\n        self.__measure_mem = False\n\n    self._ipt = new_ipt\n    self._ipt2device()\n    self.model.to(self.device)\n    return self.model(*self._ipt[\"args\"], **self._ipt[\"kwargs\"])\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.__delattr__","title":"__delattr__","text":"Python<pre><code>__delattr__(name: str) -&gt; None\n</code></pre> <p>Try to delete attributes from Meter instance first, fall back to underlying model if needed.</p> <p>This method ensures:</p> <ol> <li>Class attributes defined in <code>Meter</code> cannot be deleted</li> <li>Instance attributes are deleted along with corresponding model attributes (if exists)</li> <li>Attributes prefixed with \"ORIGIN_\" will delete the actual model attribute after removing prefix</li> </ol> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the attribute to delete</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <ul> <li>When trying to delete Meter's class attributes</li> <li>When attempting to delete non-existent attributes</li> <li>When failed to delete attribute from both Meter instance and the underlying model</li> </ul> Notes <ul> <li> <p>When encountering conflicting attribute names between Meter instance and the model:     The Meter instance's attribute will be prioritized for deletion by default.     To delete the underlying model's attribute with same name, prepend \"ORIGIN_\" prefix.     Example: <code>del meter_instance.ORIGIN_param</code> will delete model's <code>param</code> attribute</p> </li> <li> <p>This implementation ensures the Meter instance can be seamlessly used as a drop-in replacement   for the underlying model without requiring code modifications</p> </li> </ul> Source code in <code>torchmeter/core.py</code> Python<pre><code>def __delattr__(self, name: str) -&gt; None:\n    \"\"\"Try to delete attributes from Meter instance first, fall back to underlying model if needed.\n\n    This method ensures:\n\n    1. Class attributes defined in `Meter` cannot be deleted\n    2. Instance attributes are deleted along with corresponding model attributes (if exists)\n    3. Attributes prefixed with \"ORIGIN_\" will delete the actual model attribute after removing prefix\n\n    Args:\n        name (str): Name of the attribute to delete\n\n    Raises:\n        AttributeError:\n            - When trying to delete Meter's class attributes\n            - When attempting to delete non-existent attributes\n            - When failed to delete attribute from both Meter instance and the underlying model\n\n    Notes:\n        - When encountering conflicting attribute names between Meter instance and the model:\n            The Meter instance's attribute will be prioritized for deletion by default.\n            To delete the underlying model's attribute with same name, prepend \"ORIGIN_\" prefix.\n            Example: `del meter_instance.ORIGIN_param` will delete model's `param` attribute\n\n        - This implementation ensures the Meter instance can be seamlessly used as a drop-in replacement\n          for the underlying model without requiring code modifications\n    \"\"\"\n\n    cls_attrs: Dict[str, bool] = self.__get_clsattr_with_settable_flag()\n\n    if name in cls_attrs:\n        raise AttributeError(f\"`{name}` could never be deleted.\")\n\n    try:\n        # delete the property with same name defined in Meter from origin model\n        if name.startswith(\"ORIGIN_\"):\n            name = name[7:]\n            raise AttributeError\n\n        super().__delattr__(name)\n\n    except AttributeError:\n        delattr(self.model, name)\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.__device_detect","title":"__device_detect","text":"Python<pre><code>__device_detect(model: Module) -&gt; Union[str, tc_device]\n</code></pre> <p>Detects the device where the model are located via model's parameters.</p> <p>This method detects the model's device by checking its parameters' location. If no parameters are found, it will raise a warning and move the model to CPU by default.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model whose device is to be detected.</p> required <p>Returns:</p> Type Description <code>Union[str, device]</code> <p>Union[str, torch.device]: The device where the model's parameters are located. If no parameters are found,</p> <code>Union[str, device]</code> <p>returns 'cpu' as the default device.</p> <p>Raises:</p> Type Description <code>UserWarning</code> <p>If the model has no parameters, a warning is issued indicating that the model will be moved          to CPU for subsequent analysis.</p> Source code in <code>torchmeter/core.py</code> Python<pre><code>def __device_detect(self, model: nn.Module) -&gt; Union[str, tc_device]:\n    \"\"\"Detects the device where the model are located via model's parameters.\n\n    This method detects the model's device by checking its parameters' location.\n    If no parameters are found, it will raise a warning and move the model to CPU by default.\n\n    Args:\n        model (nn.Module): The model whose device is to be detected.\n\n    Returns:\n        Union[str, torch.device]: The device where the model's parameters are located. If no parameters are found,\n        returns 'cpu' as the default device.\n\n    Raises:\n        UserWarning: If the model has no parameters, a warning is issued indicating that the model will be moved\n                     to CPU for subsequent analysis.\n    \"\"\"\n\n    import warnings\n\n    try:\n        model_first_param = next(model.parameters())\n        return model_first_param.device\n\n    except StopIteration:\n        warnings.warn(\n            category=UserWarning,\n            message=\"We can't detect the device where your model is located because no parameter was found \"\n            + \"in your model. We'll move your model to CPU and do all subsequent analysis based on this CPU \"\n            + \"version. If this isn't what you want, change the device with `to` method, \"\n            + \"e.g. `metered_model.to('cuda')`.\",\n        )\n\n        return \"cpu\"\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.__get_clsattr_with_settable_flag","title":"__get_clsattr_with_settable_flag  <code>classmethod</code>","text":"Python<pre><code>__get_clsattr_with_settable_flag() -&gt; Dict[str, bool]\n</code></pre> <p>Determines which class attributes have setter methods defined.</p> <p>This method iterates over all properties of the class and checks if a setter method is defined for each property. It returns a dictionary mapping attribute names to a boolean indicating whether the attribute is settable.</p> <p>Returns:</p> Type Description <code>Dict[str, bool]</code> <p>Dict[str, bool]: A dictionary where keys are attribute names and values indicate</p> <code>Dict[str, bool]</code> <p>whether the attribute has a setter method (True if settable, False otherwise).</p> Source code in <code>torchmeter/core.py</code> Python<pre><code>@classmethod\ndef __get_clsattr_with_settable_flag(cls) -&gt; Dict[str, bool]:\n    \"\"\"Determines which class attributes have setter methods defined.\n\n    This method iterates over all properties of the class and checks if a setter method\n    is defined for each property. It returns a dictionary mapping attribute names to a\n    boolean indicating whether the attribute is settable.\n\n    Returns:\n        Dict[str, bool]: A dictionary where keys are attribute names and values indicate\n        whether the attribute has a setter method (True if settable, False otherwise).\n    \"\"\"\n\n    return {k: v.fset is not None for k, v in cls.__dict__.items() \n            if isinstance(v, property)}  # fmt: skip\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.__getattr__","title":"__getattr__","text":"Python<pre><code>__getattr__(name: str) -&gt; Any\n</code></pre> <p>Transparently proxy attribute access to the underlying model when not found in Meter instance</p> <p>This method enables seamless attribute access to the wrapped model while maintaining Meter's own attributes. It follows these resolution rules:</p> <ol> <li>Directly returns Meter's own attributes if they exist</li> <li>For attributes prefixed with \"ORIGIN_\", returns the underlying model's attribute with the prefix removed</li> <li>Otherwise, returns the corresponding attribute from the wrapped model</li> </ol> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the attribute to retrieve</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The value of the requested attribute from either Meter instance or underlying model</p> <p>Raises:</p> Type Description <code>AttributeError</code> <ul> <li>When the attribute does not exist in both Meter instance and underlying model</li> <li>When using \"ORIGIN_\" prefix with non-existent attribute in underlying model</li> </ul> Notes <ul> <li> <p>Attribute resolution priority:     Meter's own attributes &gt; underlying model's attributes (unless \"ORIGIN_\" prefix is used)</p> </li> <li> <p>To bypass Meter's attributes and directly access model's attributes with same name:     Use \"ORIGIN_\" prefix (e.g., <code>meter.ORIGIN_param</code> maps to <code>model.param</code>)</p> </li> <li> <p>This implementation ensures the Meter instance can be seamlessly used as a drop-in replacement   for the underlying model without requiring code modifications</p> </li> </ul> Source code in <code>torchmeter/core.py</code> Python<pre><code>def __getattr__(self, name: str) -&gt; Any:\n    \"\"\"Transparently proxy attribute access to the underlying model when not found in Meter instance\n\n    This method enables seamless attribute access to the wrapped model while maintaining Meter's\n    own attributes. It follows these resolution rules:\n\n    1. Directly returns Meter's own attributes if they exist\n    2. For attributes prefixed with \"ORIGIN_\", returns the underlying model's attribute with the prefix removed\n    3. Otherwise, returns the corresponding attribute from the wrapped model\n\n    Args:\n        name (str): Name of the attribute to retrieve\n\n    Returns:\n        Any: The value of the requested attribute from either Meter instance or underlying model\n\n    Raises:\n        AttributeError:\n            - When the attribute does not exist in both Meter instance and underlying model\n            - When using \"ORIGIN_\" prefix with non-existent attribute in underlying model\n\n    Notes:\n        - Attribute resolution priority:\n            Meter's own attributes &gt; underlying model's attributes (unless \"ORIGIN_\" prefix is used)\n\n        - To bypass Meter's attributes and directly access model's attributes with same name:\n            Use \"ORIGIN_\" prefix (e.g., `meter.ORIGIN_param` maps to `model.param`)\n\n        - This implementation ensures the Meter instance can be seamlessly used as a drop-in replacement\n          for the underlying model without requiring code modifications\n    \"\"\"\n\n    try:\n        # get the property with same name defined in Meter from origin model\n        if name.startswith(\"ORIGIN_\"):\n            name = name[7:]\n            raise AttributeError\n        return super().__getattribute__(name)\n\n    except AttributeError:\n        return getattr(self.model, name)\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.__is_ipt_changed","title":"__is_ipt_changed","text":"Python<pre><code>__is_ipt_changed(new_ipt: IPT_TYPE) -&gt; bool\n</code></pre> <p>Determines if the new input differs from the current captured input.</p> <p>Compares both positional arguments (args) and keyword arguments (kwargs) between current and new input:</p> <ul> <li>For Tensor arguments: Checks shape and dtype equivalence</li> <li>For non-Tensor arguments: Performs value equality check</li> <li>Verifies argument structure consistency (same length for args, same keys for kwargs)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>new_ipt</code> <code>IPT_TYPE</code> <p>New input arguments to compare against currently stored input.      It is a dictionary with two keys:         - <code>args</code>: A tuple containing all positional arguments.         - <code>kwargs</code>: A dictionary containing all keyword arguments.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if any of following conditions met:</p> <ol> <li>Current input is empty (first-time input)</li> <li>Positional arguments differ in length/value type/shape (for Tensors)</li> <li>Keyword arguments have different keys or values</li> <li>Any argument value differs (non-Tensor) or tensor properties differ (Tensor)</li> </ol> Source code in <code>torchmeter/core.py</code> Python<pre><code>def __is_ipt_changed(self, new_ipt: IPT_TYPE) -&gt; bool:  # noqa: C901\n    \"\"\"Determines if the new input differs from the current captured input.\n\n    Compares both positional arguments (args) and keyword arguments (kwargs) between current and new input:\n\n    - For Tensor arguments: Checks shape and dtype equivalence\n    - For non-Tensor arguments: Performs value equality check\n    - Verifies argument structure consistency (same length for args, same keys for kwargs)\n\n    Args:\n        new_ipt: New input arguments to compare against currently stored input.\n                 It is a dictionary with two keys:\n                    - `args`: A tuple containing all positional arguments.\n                    - `kwargs`: A dictionary containing all keyword arguments.\n\n    Returns:\n        bool: `True` if any of following conditions met:\n\n            1. Current input is empty (first-time input)\n            2. Positional arguments differ in length/value type/shape (for Tensors)\n            3. Keyword arguments have different keys or values\n            4. Any argument value differs (non-Tensor) or tensor properties differ (Tensor)\n    \"\"\"\n\n    if self._is_ipt_empty():\n        return True\n\n    is_changed = False\n\n    # check anonymous arguments\n    if len(self._ipt[\"args\"]) != len(new_ipt[\"args\"]):\n        return True\n\n    for origin, new in zip(self._ipt[\"args\"], new_ipt[\"args\"]):\n        if type(origin) is not type(new):\n            is_changed = True\n        elif isinstance(origin, Tensor):\n            is_changed = origin.shape != new.shape or origin.dtype != new.dtype\n        else:\n            is_changed = origin != new\n\n        if is_changed:\n            return True\n\n    # check named arguments\n    if set(self._ipt[\"kwargs\"].keys()) != set(new_ipt[\"kwargs\"].keys()):\n        return True\n\n    for k, origin in self._ipt[\"kwargs\"].items():\n        new = new_ipt[\"kwargs\"][k]\n\n        if type(origin) is not type(new):\n            is_changed = True\n        elif isinstance(origin, Tensor):\n            is_changed = origin.shape != new.shape or origin.dtype != new.dtype\n        else:\n            is_changed = origin != new\n\n        if is_changed:\n            return True\n\n    return False\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.__setattr__","title":"__setattr__","text":"Python<pre><code>__setattr__(name: str, value: Any) -&gt; None\n</code></pre> <p>Prioritize setting attributes on Meter instance first, falling back to the underlying model.</p> <p>This method ensures: 1. Class attributes defined in <code>Meter</code> that cannot be modified are blocked 2. Instance attributes are set first, falling back to model attributes if not present 3. Attributes prefixed with \"ORIGIN_\" will set the underlying model attribute after removing prefix</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the attribute to assign</p> required <code>value</code> <code>Any</code> <p>Value to be assigned to the attribute</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <ul> <li>When attempting to set non-modifiable Meter class attributes.</li> <li>When attribute assignment fails for both <code>Meter</code> instance and the underlying model</li> </ul> Notes <ul> <li> <p>When encountering conflicting attribute names between Meter instance and the model:     The Meter instance's attribute will be prioritized for assignment by default.     To assign the underlying model's attribute with same name, prepend \"ORIGIN_\" prefix.     Example: <code>meter_instance.ORIGIN_param = 1</code> will set model's <code>param</code> attribute to 1</p> </li> <li> <p>This implementation ensures the Meter instance can be seamlessly used as a drop-in replacement   for the underlying model without requiring code modifications</p> </li> <li> <p>Non-modifiable Meter class attributes are attributes defined by <code>@property</code> but without a setter.   include:</p> <ol> <li><code>ipt</code></li> <li><code>structure</code></li> <li><code>param</code></li> <li><code>cal</code></li> <li><code>mem</code></li> <li><code>ittp</code></li> <li><code>model_info</code></li> <li><code>subnodes</code></li> </ol> </li> </ul> Source code in <code>torchmeter/core.py</code> Python<pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Prioritize setting attributes on Meter instance first, falling back to the underlying model.\n\n    This method ensures:\n    1. Class attributes defined in `Meter` that cannot be modified are blocked\n    2. Instance attributes are set first, falling back to model attributes if not present\n    3. Attributes prefixed with \"ORIGIN_\" will set the underlying model attribute after removing prefix\n\n    Args:\n        name (str): Name of the attribute to assign\n        value (Any): Value to be assigned to the attribute\n\n    Raises:\n        AttributeError:\n            - When attempting to set non-modifiable Meter class attributes.\n            - When attribute assignment fails for both `Meter` instance and the underlying model\n\n    Notes:\n        - When encountering conflicting attribute names between Meter instance and the model:\n            The Meter instance's attribute will be prioritized for assignment by default.\n            To assign the underlying model's attribute with same name, prepend \"ORIGIN_\" prefix.\n            Example: `meter_instance.ORIGIN_param = 1` will set model's `param` attribute to 1\n\n        - This implementation ensures the Meter instance can be seamlessly used as a drop-in replacement\n          for the underlying model without requiring code modifications\n\n        - Non-modifiable Meter class attributes are attributes defined by `@property` but without a setter.\n          include:\n            1. `ipt`\n            2. `structure`\n            3. `param`\n            4. `cal`\n            5. `mem`\n            6. `ittp`\n            7. `model_info`\n            8. `subnodes`\n    \"\"\"\n\n    cls_attrs: Dict[str, bool] = self.__get_clsattr_with_settable_flag()\n    notchange_cls_attrs = [k for k, v in cls_attrs.items() if not v]\n\n    if name in notchange_cls_attrs:\n        raise AttributeError(f\"`{name}` could never be set.\")\n\n    try:\n        # set the property with same name defined in Meter from origin model\n        if name.startswith(\"ORIGIN_\"):\n            name = name[7:]\n            raise AttributeError\n\n        super().__setattr__(name, value)\n\n    except AttributeError:\n        setattr(self.model, name, value)\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.overview","title":"overview","text":"Python<pre><code>overview(*order: str, show_warning: bool = True) -&gt; Columns\n</code></pre> <p>Generates an overview of all statistics in a formatted layout.</p> <p>This method creates a visual overview of model statistics, including basic model information and core data of each specified statistic. You can customize the statistics contained in the rendering results and their order by passing in the statistics you want in the order you prefer.</p> <p>Parameters:</p> Name Type Description Default <code>*order</code> <code>str</code> <p>The names of the statistics to include in the overview. If not provided,         all available statistics are included.</p> <code>()</code> <code>show_warning</code> <code>bool</code> <p>Whether to display warnings for potentially inaccurate results.                 Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>Columns</code> <code>Columns</code> <p>A <code>rich.Columns</code> object containing the formatted overview.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any of the provided statistics names are invalid.</p> Example Python<pre><code>from torch import randn\nfrom torchmeter import Meter\nfrom torchvision import models\n\nunderlying_model = models.resnet18()\nmodel = Meter(underlying_model)\nmodel(randn(1, 3, 224, 224))\n\n# overview all statistics (i.e. param, cal, mem, ittp)\nmodel.overview()\n\n# only overview `cal` and `param`\n# and the order is `cal` then `param`\nmodel.overview(\"cal\", \"param\")\n</code></pre> Source code in <code>torchmeter/core.py</code> Python<pre><code>def overview(self, *order: str, show_warning: bool = True) -&gt; Columns:\n    \"\"\"Generates an overview of all statistics in a formatted layout.\n\n    This method creates a visual overview of model statistics, including basic model\n    information and core data of each specified statistic. You can customize the statistics\n    contained in the rendering results and their order by passing in the statistics you want\n    in the order you prefer.\n\n    Args:\n        *order (str): The names of the statistics to include in the overview. If not provided,\n                    all available statistics are included.\n        show_warning (bool): Whether to display warnings for potentially inaccurate results.\n                            Defaults to True.\n\n    Returns:\n        Columns: A `rich.Columns` object containing the formatted overview.\n\n    Raises:\n        ValueError: If any of the provided statistics names are invalid.\n\n    Example:\n        ```python\n        from torch import randn\n        from torchmeter import Meter\n        from torchvision import models\n\n        underlying_model = models.resnet18()\n        model = Meter(underlying_model)\n        model(randn(1, 3, 224, 224))\n\n        # overview all statistics (i.e. param, cal, mem, ittp)\n        model.overview()\n\n        # only overview `cal` and `param`\n        # and the order is `cal` then `param`\n        model.overview(\"cal\", \"param\")\n        ```\n    \"\"\"\n\n    from functools import partial\n\n    from rich.box import HORIZONTALS\n    from rich.panel import Panel\n\n    order = order or self.optree.root.statistics\n\n    invalid_stat = tuple(filter(lambda x: x not in self.optree.root.statistics, order))\n    if len(invalid_stat) &gt; 0:\n        raise ValueError(f\"Invalid statistics: {invalid_stat}\")\n\n    container = Columns(expand=True, align=\"center\")\n    format_cell = partial(Panel, safe_box=True, expand=False, highlight=True, box=HORIZONTALS)\n\n    container.add_renderable(format_cell(self.model_info, title=\"[b]Model INFO[/]\", border_style=\"orange1\"))\n    container.renderables.extend([\n        format_cell(\n            self.stat_info(stat_name, show_warning=show_warning),\n            title=f\"[b]{stat_name.capitalize()} INFO[/]\",\n            border_style=\"cyan\",\n        )\n        for stat_name in order\n    ])\n\n    return container\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.profile","title":"profile","text":"Python<pre><code>profile(stat_name: str, show: bool = True, no_tree: bool = False, **tb_kwargs) -&gt; Tuple[Table, DataFrame]\n</code></pre> <p>Render a tabular report of the specified statistics with rich visualization.</p> <p>This method generates an interactive table visualization for the given statistical data, optionally combined with the model's operation tree structure. The rendering supports real-time customization through keyword arguments and can export data to multiple formats.</p> <p>Parameters:</p> Name Type Description Default <code>stat_name</code> <code>str</code> <p>Name of the statistics to profile (i.e., 'param', 'cal', 'mem', 'ittp').</p> required <code>show</code> <code>bool</code> <p>Whether to immediately render the visualization and display in terminal.                    Defaults to True.</p> <code>True</code> <code>no_tree</code> <code>bool</code> <p>Not to display the rendered tree when set to True. Defaults to False.</p> <code>False</code> <code>**tb_kwargs</code> <p>Additional table customization options:</p> <ul> <li>raw_data (<code>bool</code>): Use raw numerical data instead of formatted values with unit.                      Defaults to <code>False</code>.</li> <li>pick_cols (<code>Sequence[str]</code>): Whitelist of columns to display. Defaults to <code>[]</code>.</li> <li>exclude_cols (<code>Sequence[str]</code>): Blacklist of columns to hide. Defaults to <code>[]</code>.</li> <li>custom_cols (<code>Dict[str, str]</code>): Column rename mappings (original: new). Defaults to <code>{}</code>.</li> <li>keep_custom_name (<code>bool</code>): Whether to keep custom names after this call. Defaults to <code>False</code>.</li> <li>newcol_name (<code>str</code>): Name for new computed column. Defaults to <code>''</code>.</li> <li>newcol_func (<code>Callable[[DataFrame], ArrayLike]</code>): Function to compute new column values.                                                     Defaults to <code>lambda df: [None]*len(df)</code>.</li> <li>newcol_type (<code>Optional[PolarsDataType]</code>): Explicit data type for new column. Defaults to <code>None</code>.</li> <li>newcol_idx (<code>int</code>): Insertion position for new column (-1=append). Defaults to <code>-1</code>.</li> <li>keep_new_col (<code>bool</code>): Retain new columns in backend dataframe and subsequent renders.                          Defaults to <code>False</code>.</li> <li>save_to (<code>Optional[str]</code>): File path for data export, not None to trigger export. Defaults to <code>None</code>.</li> <li>save_format (<code>Optional[str]</code>): Export format, <code>None</code> to use the value in <code>save_to</code>.                                  Now we only support <code>csv</code> or <code>xlsx</code> file. Defaults to <code>None</code>.</li> </ul> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Table, DataFrame]</code> <p>The rendered <code>rich.table.Table</code> object and underlying polars DataFrame.</p> <p>Raises:</p> Type Description <code>RuntimeWarning</code> <p>If your model has some modules defined but not explicitly called.</p> <code>AttributeError</code> <p>If <code>stat_name</code> is not a valid statistics name.</p> <code>ValueError</code> <ul> <li>If horizontal gap defined in global config is negative when disable <code>no_tree</code>.</li> <li>If you specify any not existing column name to <code>pick_cols</code> when enable <code>show</code> and <code>pick_cols</code>.</li> <li>If you pass in a directory path as <code>save_to</code> but not specify <code>save_format</code>.</li> <li>If you pass in a non csv or xlsx file path as <code>save_to</code>.</li> <li>If you pass in a non-supported export format as <code>save_format</code>.</li> <li>If <code>newcol_name</code> already exists in the backend dataframe.</li> </ul> <code>RuntimeError</code> <ul> <li>If terminal width is insufficient for display when enable <code>show</code>.</li> <li>If no input data has been provided (i.e., <code>ipt</code> property is empty) and <code>stat_name</code> is   one of <code>cal</code>, <code>mem</code>, or <code>ittp</code>.</li> <li>If no module is called (e.g. the underlying model's <code>forward</code> method is not empty).</li> <li>If the whole model is empty and has no sublayers.</li> <li>If using a single layer as a model</li> <li>If <code>newcol_func</code> returns values with length mismatch to the underlying dataframe's row count</li> </ul> <code>TypeError</code> <ul> <li>If <code>stat_name</code> is not a string</li> <li>If <code>pick_cols</code> is not a list, tuple or set.</li> <li>If <code>exclude_cols</code> is not a list, tuple or set.</li> <li>If <code>custom_cols</code> is not a dict.</li> <li>If <code>newcol_name</code> is not a string.</li> <li>If <code>newcol_func</code> is uncallable</li> <li>If <code>newcol_func</code> doesn't have exactly 1 formal parameter</li> <li>If return value of <code>newcol_func</code> is not array-like</li> <li>If <code>newcol_idx</code> is not an integer.</li> <li>If <code>newcol_type</code> is not a valid Polars data type.</li> <li>If <code>save_to</code> is not a string, neither None.</li> <li>If <code>save_format</code> is not a string, neither None.</li> </ul> Notes <ol> <li> <p>Ensure at least one forward pass has been executed before accessing <code>cal</code>/<code>mem</code>/<code>ittp</code> statistics to    guarantee valid input capture.</p> </li> <li> <p>Table and tree rendering styles can be preconfigured through the properties:</p> <ul> <li><code>table_display_args</code></li> <li><code>table_column_args</code></li> <li><code>tree_fold_args</code></li> <li><code>tree_levels_args</code></li> <li><code>tree_repeat_block_args</code></li> </ul> </li> <li> <p>The rendering result will be progressively displayed line-by-line with a time interval.    You can configure this interval through the following steps (must be non-negative):     Python<pre><code>from torchmeter import get_config\n\ncfg = get_config()\ncfg.render_interval = 0.5  # unit second, should be non-negative\n</code></pre></p> </li> <li> <p>Disable rendering (<code>show=False</code>) when only exporting data to reduce computational overhead.</p> </li> <li> <p>Enable <code>no_tree</code> to:</p> <ul> <li>Enable focused data analysis</li> <li>Hide the operation tree for narrow terminals</li> <li>Default layout shows tree left + table right (may enforce row separators if space constrained)</li> </ul> </li> <li> <p>Horizontal spacing between tree and table is controlled by <code>combine.horizon_gap</code> in global config.    You should promise the value is non-negative.</p> </li> <li> <p>When <code>raw_data=True</code> displays unformatted values:</p> <ul> <li><code>param</code>: Parameter counts</li> <li><code>cal</code>: FLOPs/MACs counts</li> <li><code>mem</code>: Bytes consumed</li> <li><code>ittp</code>: Median inference time (seconds) and inferences per second per module</li> </ul> </li> <li> <p>Column management:</p> <ul> <li>Use <code>pick_cols</code> to reorder columns (validate column names via   <code>metered_instance.table_cols(stat_name)</code>)</li> <li>Processing order: <code>pick_cols</code> -&gt; <code>exclude_cols</code> -&gt; <code>custom_cols</code> -&gt; <code>newcol</code></li> <li>Conflicts:<ul> <li>picked columns override custom/newcol names</li> <li>exclusions override picks</li> </ul> </li> </ul> </li> <li> <p>About <code>newcol_func</code>:</p> <ul> <li>must have exactly 1 formal parameter (name irrelevant) that will receive the   underlying <code>polars.DataFrame</code> of specified statistics.</li> <li>Implement logic using the incoming dataframe to return new column values (must be 1D array-like data   such as <code>Series</code>, <code>lists</code>, <code>ndarrays</code>, etc.). Note that you can use <code>val</code> property to access the   raw data for all statistics (for <code>ittp</code>, the return will be a tuple made up of the median and iqr of   the measurement data sequence).</li> <li>The example below demonstrates adding a percentage column of the <code>cal</code> statistics. Refer to   https://docs.pola.rs/api/python/stable/reference/dataframe/index.html for using <code>polars.Dataframe</code>.</li> </ul> </li> <li> <p>The <code>newcol_idx</code> parameter mostly follows Python list insertion semantics:</p> <ul> <li>Negative values count backward from end (<code>-1</code>=<code>append</code>)</li> <li><code>0</code> inserts at beginning</li> <li>Values exceeding column count clamp to nearest valid position:</li> <li>Negative abs values &gt; column count \u2192 insert at start</li> <li>Positive values &gt; column count \u2192 append at end</li> </ul> </li> <li> <p>Session persistence:</p> <ul> <li><code>keep_new_col</code> retains created columns</li> <li><code>keep_custom_name</code> preserves renamed columns</li> </ul> </li> <li> <p>Export paths:</p> <ul> <li>Directory paths require explicit <code>save_format</code></li> <li>File paths auto-detect format from extension unless <code>save_format</code> overrides</li> </ul> </li> </ol> Example Python<pre><code>import torch\nfrom torchmeter import Meter\nfrom torchvision import models\n\n# wrap your model with Meter\nunderlying_model = models.alexnet()\nmodel = Meter(underlying_model)\n\n# execute a forward inference (necessary, to provide input data)\ninput = torch.randn(1, 3, 224, 224)\nmodel(input)\n\n# check column names of cal tabel\nprint(model.table_cols(\"cal\"))\n# ('Operation_Id', 'Operation_Name', 'Operation_Type', 'Kernel_Size', 'Bias',\n# 'Input', 'Output', 'MACs', 'FLOPs')\n\n\ndef newcol_logic(df):\n    flops_col = df[\"FLOPs\"]\n    return flops_col.map_elements(lambda x: f\"{100 * x / metered_model.cal.Flops:.4f} %\")\n\n\n# Customized profile with column operations\nmodel.profile(\n    \"cal\",\n    # render and display immediately\n    show=True,\n    no_tree=True,\n    raw_data=False,\n    # columns management\n    exclude_cols=[\"Kernel_Size\", \"Bias\"],\n    custom_cols={\"Operation_Id\": \"ID\", \"Operation_Name\": \"Module Name\", \"Operation_Type\": \"Module Type\"},\n    newcol_name=\"Percentage\",\n    newcol_func=newcol_logic,\n    newcol_type=str,\n    newcol_idx=-1,\n    # export\n    save_to=\"./cal_profile.xlsx\",\n    save_format=\"xlsx\",\n)\n</code></pre> Source code in <code>torchmeter/core.py</code> Python<pre><code>def profile(self, stat_name: str, show: bool = True, no_tree: bool = False, **tb_kwargs) -&gt; Tuple[Table, DataFrame]:\n    \"\"\"Render a tabular report of the specified statistics with rich visualization.\n\n    This method generates an interactive table visualization for the given statistical data,\n    optionally combined with the model's operation tree structure. The rendering supports\n    real-time customization through keyword arguments and can export data to multiple formats.\n\n    Args:\n        stat_name (str): Name of the statistics to profile (i.e., 'param', 'cal', 'mem', 'ittp').\n\n        show (bool, optional): Whether to immediately render the visualization and display in terminal.\n                               Defaults to True.\n\n        no_tree (bool, optional): Not to display the rendered tree when set to True. Defaults to False.\n\n        **tb_kwargs: Additional table customization options:\n\n            - raw_data (`bool`): Use raw numerical data instead of formatted values with unit.\n                                 Defaults to `False`.\n            - pick_cols (`Sequence[str]`): Whitelist of columns to display. Defaults to `[]`.\n            - exclude_cols (`Sequence[str]`): Blacklist of columns to hide. Defaults to `[]`.\n            - custom_cols (`Dict[str, str]`): Column rename mappings (original: new). Defaults to `{}`.\n            - keep_custom_name (`bool`): Whether to keep custom names after this call. Defaults to `False`.\n            - newcol_name (`str`): Name for new computed column. Defaults to `''`.\n            - newcol_func (`Callable[[DataFrame], ArrayLike]`): Function to compute new column values.\n                                                                Defaults to `lambda df: [None]*len(df)`.\n            - newcol_type (`Optional[PolarsDataType]`): Explicit data type for new column. Defaults to `None`.\n            - newcol_idx (`int`): Insertion position for new column (-1=append). Defaults to `-1`.\n            - keep_new_col (`bool`): Retain new columns in backend dataframe and subsequent renders.\n                                     Defaults to `False`.\n            - save_to (`Optional[str]`): File path for data export, not None to trigger export. Defaults to `None`.\n            - save_format (`Optional[str]`): Export format, `None` to use the value in `save_to`.\n                                             Now we only support `csv` or `xlsx` file. Defaults to `None`.\n\n    Returns:\n        The rendered `rich.table.Table` object and underlying polars DataFrame.\n\n    Raises:\n        RuntimeWarning: If your model has some modules defined but not explicitly called.\n\n        AttributeError: If `stat_name` is not a valid statistics name.\n\n        ValueError:\n            - If horizontal gap defined in global config is negative when disable `no_tree`.\n            - If you specify any not existing column name to `pick_cols` when enable `show` and `pick_cols`.\n            - If you pass in a directory path as `save_to` but not specify `save_format`.\n            - If you pass in a non csv or xlsx file path as `save_to`.\n            - If you pass in a non-supported export format as `save_format`.\n            - If `newcol_name` already exists in the backend dataframe.\n\n        RuntimeError:\n            - If terminal width is insufficient for display when enable `show`.\n            - If no input data has been provided (i.e., `ipt` property is empty) and `stat_name` is\n              one of `cal`, `mem`, or `ittp`.\n            - If no module is called (e.g. the underlying model's `forward` method is not empty).\n            - If the whole model is empty and has no sublayers.\n            - If using a single layer as a model\n            - If `newcol_func` returns values with length mismatch to the underlying dataframe's row count\n\n        TypeError:\n            - If `stat_name` is not a string\n            - If `pick_cols` is not a list, tuple or set.\n            - If `exclude_cols` is not a list, tuple or set.\n            - If `custom_cols` is not a dict.\n            - If `newcol_name` is not a string.\n            - If `newcol_func` is uncallable\n            - If `newcol_func` doesn't have exactly **1** formal parameter\n            - If return value of `newcol_func` is not array-like\n            - If `newcol_idx` is not an integer.\n            - If `newcol_type` is not a valid Polars data type.\n            - If `save_to` is not a string, neither None.\n            - If `save_format` is not a string, neither None.\n\n    Notes:\n        1. Ensure at least one forward pass has been executed before accessing `cal`/`mem`/`ittp` statistics to\n           guarantee valid input capture.\n\n        2. Table and tree rendering styles can be preconfigured through the properties:\n            - `table_display_args`\n            - `table_column_args`\n            - `tree_fold_args`\n            - `tree_levels_args`\n            - `tree_repeat_block_args`\n\n        3. The rendering result will be progressively displayed line-by-line with a time interval.\n           You can configure this interval through the following steps (must be non-negative):\n            ```python\n            from torchmeter import get_config\n\n            cfg = get_config()\n            cfg.render_interval = 0.5  # unit second, should be non-negative\n            ```\n\n        4. Disable rendering (`show=False`) when only exporting data to reduce computational overhead.\n\n        5. Enable `no_tree` to:\n            - Enable focused data analysis\n            - Hide the operation tree for narrow terminals\n            - Default layout shows tree left + table right (may enforce row separators if space constrained)\n\n        6. Horizontal spacing between tree and table is controlled by `combine.horizon_gap` in global config.\n           You should promise the value is non-negative.\n\n        7. When `raw_data=True` displays unformatted values:\n            - `param`: Parameter counts\n            - `cal`: FLOPs/MACs counts\n            - `mem`: Bytes consumed\n            - `ittp`: Median inference time (seconds) and inferences per second per module\n\n        8. Column management:\n            - Use `pick_cols` to reorder columns (validate column names via\n              `metered_instance.table_cols(stat_name)`)\n            - Processing order: `pick_cols` -&gt; `exclude_cols` -&gt; `custom_cols` -&gt; `newcol`\n            - Conflicts:\n                - picked columns override custom/newcol names\n                - exclusions override picks\n\n        9. About `newcol_func`:\n            - must have exactly **1** formal parameter (name irrelevant) that will receive the\n              underlying `polars.DataFrame` of specified statistics.\n            - Implement logic using the incoming dataframe to return new column values (must be 1D array-like data\n              such as `Series`, `lists`, `ndarrays`, etc.). Note that you can use `val` property to access the\n              raw data for all statistics (for `ittp`, the return will be a tuple made up of the median and iqr of\n              the measurement data sequence).\n            - The example below demonstrates adding a percentage column of the `cal` statistics. Refer to\n              https://docs.pola.rs/api/python/stable/reference/dataframe/index.html for using `polars.Dataframe`.\n\n        10. The `newcol_idx` parameter mostly follows Python list insertion semantics:\n            - Negative values count backward from end (`-1`=`append`)\n            - `0` inserts at beginning\n            - Values exceeding column count clamp to nearest valid position:\n              * Negative abs values &gt; column count \u2192 insert at start\n              * Positive values &gt; column count \u2192 append at end\n\n        12. Session persistence:\n            - `keep_new_col` retains created columns\n            - `keep_custom_name` preserves renamed columns\n\n        13. Export paths:\n            - Directory paths require explicit `save_format`\n            - File paths auto-detect format from extension unless `save_format` overrides\n\n    Example:\n        ```python\n        import torch\n        from torchmeter import Meter\n        from torchvision import models\n\n        # wrap your model with Meter\n        underlying_model = models.alexnet()\n        model = Meter(underlying_model)\n\n        # execute a forward inference (necessary, to provide input data)\n        input = torch.randn(1, 3, 224, 224)\n        model(input)\n\n        # check column names of cal tabel\n        print(model.table_cols(\"cal\"))\n        # ('Operation_Id', 'Operation_Name', 'Operation_Type', 'Kernel_Size', 'Bias',\n        # 'Input', 'Output', 'MACs', 'FLOPs')\n\n\n        def newcol_logic(df):\n            flops_col = df[\"FLOPs\"]\n            return flops_col.map_elements(lambda x: f\"{100 * x / metered_model.cal.Flops:.4f} %\")\n\n\n        # Customized profile with column operations\n        model.profile(\n            \"cal\",\n            # render and display immediately\n            show=True,\n            no_tree=True,\n            raw_data=False,\n            # columns management\n            exclude_cols=[\"Kernel_Size\", \"Bias\"],\n            custom_cols={\"Operation_Id\": \"ID\", \"Operation_Name\": \"Module Name\", \"Operation_Type\": \"Module Type\"},\n            newcol_name=\"Percentage\",\n            newcol_func=newcol_logic,\n            newcol_type=str,\n            newcol_idx=-1,\n            # export\n            save_to=\"./cal_profile.xlsx\",\n            save_format=\"xlsx\",\n        )\n        ```\n    \"\"\"\n\n    from rich.rule import Rule\n    from rich.layout import Layout\n\n    # the horizontal gap between tree and table\n    TREE_TABLE_GAP = __cfg__.combine.horizon_gap\n\n    if not isinstance(stat_name, str):\n        raise TypeError(f\"stat_name must be a string, but got `{type(stat_name).__name__}`.\")\n\n    if TREE_TABLE_GAP &lt; 0:\n        raise ValueError(\n            \"The gap between the rendered tree and the rendered table should be non-negative, \"\n            + f\"but got `{TREE_TABLE_GAP}`.\"\n        )\n\n    stat = getattr(self, stat_name)\n    tb, data = self.table_renderer(stat_name=stat_name, **tb_kwargs)\n\n    if not show:\n        return tb, data\n\n    tree = None if no_tree else self.structure\n\n    console = get_console()\n    tree_width = console.measure(tree).maximum if not no_tree else 0  # type: ignore\n    desirable_tb_width = console.measure(tb).maximum\n    actual_tb_width = min(desirable_tb_width, console.width - tree_width - TREE_TABLE_GAP)\n\n    if actual_tb_width &lt;= 5:  # 5 is the minimum width of table\n        raise RuntimeError(\n            \"The width of the terminal is too small, try to maximize the window or \"\n            + \"set a smaller `horizon_gap` value in config and try again.\"\n        )\n\n    # when some cells in the table is overflown, we need to show a line between rows\n    if actual_tb_width &lt; desirable_tb_width:\n        tb.show_lines = True\n\n    # get main content(i.e. tree &amp; statistics table)\n    if no_tree:\n        main_content: Union[Table, Layout] = tb\n        tree_height = 0\n    else:\n        main_content = Layout()\n        main_content.split_row(\n            Layout(tree, name=\"left\", size=tree_width + TREE_TABLE_GAP),\n            Layout(tb, name=\"right\", size=actual_tb_width),\n        )\n        tree_height = len(console.render_lines(tree))  # type: ignore\n\n    temp_options = console.options.update_width(actual_tb_width)\n    tb_height = len(console.render_lines(tb, options=temp_options))\n    main_content_height = max(tree_height, tb_height)\n    main_content_width = tree_width + actual_tb_width + (0 if no_tree else TREE_TABLE_GAP)\n\n    # get footer content\n    footer = Columns(\n        title=Rule(\"[gray54]s u m m a r y[/]\", characters=\"-\", style=\"gray54\"),  # type: ignore\n        padding=(1, 1),\n        equal=True,\n        expand=True,\n    )\n\n    model_info = self.model_info\n    stat_info = self.stat_info(stat_or_statname=stat, show_warning=False)\n    model_info.style = \"dim\"\n    stat_info.style = \"dim\"\n    footer.add_renderable(model_info)\n    footer.add_renderable(stat_info)\n\n    temp_options = console.options.update_width(main_content_width)\n    footer_height = len(console.render_lines(footer, options=temp_options))\n\n    # render profile\n    canvas = Layout()\n    canvas.split_column(\n        Layout(main_content, name=\"top\", size=main_content_height), Layout(footer, name=\"down\", size=footer_height)\n    )\n\n    origin_width = console.width\n    origin_height = console.height\n    console.width = main_content_width\n    console.height = main_content_height + footer_height\n\n    try:\n        render_perline(renderable=canvas)\n    finally:\n        # if user interupts the rendering when render_interval &gt; 0\n        # still restore the console size\n        console.width = origin_width\n        console.height = origin_height\n\n    return tb, data\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.rebase","title":"rebase","text":"Python<pre><code>rebase(node_id: str) -&gt; Meter\n</code></pre> <p>Rebases the Meter instance to a specific node in the operation tree.</p> <p>This method allows the Meter instance to focus on a specific node in the operation tree, effectively treating that node as the new root of a new Meter instance. If the provided node ID is \"0\", the original Meter instance is returned unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>str</code> <p>The ID of the node to rebase to. Must be a valid node ID in the operation tree.</p> required <p>Returns:</p> Name Type Description <code>Meter</code> <code>Meter</code> <p>A new Meter instance with the specified node as the root.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>node_id</code> is not a string.</p> <code>ValueError</code> <p>If <code>node_id</code> does not exist in the operation tree.</p> Notes <ul> <li>Use <code>Meter(your_model).subnodes</code> to retrieve a list of valid node IDs.</li> <li>If <code>node_id</code> is \"0\", the original Meter instance is returned without modification.</li> </ul> Example Python<pre><code>from torchmeter import Meter\nfrom torchvision import models\n\nunderlying_model = models.resnet18()\nmodel = Meter(underlying_model)\nrebased_model = metered_model.rebase(\"5\")\n\nprint(model)  # Meter(model=0 ResNet: ResNet, device=cpu)\nprint(rebased_model)  # Meter(model=0 Sequential: Sequential, device=cpu)\n</code></pre> Source code in <code>torchmeter/core.py</code> Python<pre><code>def rebase(self, node_id: str) -&gt; Meter:\n    \"\"\"Rebases the Meter instance to a specific node in the operation tree.\n\n    This method allows the Meter instance to focus on a specific node in the operation tree,\n    effectively treating that node as the new root of a new Meter instance. If the provided\n    node ID is \"0\", the original Meter instance is returned unchanged.\n\n    Args:\n        node_id (str): The ID of the node to rebase to. Must be a valid node ID in the operation tree.\n\n    Returns:\n        Meter: A new Meter instance with the specified node as the root.\n\n    Raises:\n        TypeError: If `node_id` is not a string.\n        ValueError: If `node_id` does not exist in the operation tree.\n\n    Notes:\n        - Use `Meter(your_model).subnodes` to retrieve a list of valid node IDs.\n        - If `node_id` is \"0\", the original Meter instance is returned without modification.\n\n    Example:\n        ```python\n        from torchmeter import Meter\n        from torchvision import models\n\n        underlying_model = models.resnet18()\n        model = Meter(underlying_model)\n        rebased_model = metered_model.rebase(\"5\")\n\n        print(model)  # Meter(model=0 ResNet: ResNet, device=cpu)\n        print(rebased_model)  # Meter(model=0 Sequential: Sequential, device=cpu)\n        ```\n    \"\"\"\n\n    if not isinstance(node_id, str):\n        raise TypeError(f\"node_id must be a string, but got `{type(node_id).__name__}`.\")\n\n    if node_id == \"0\":\n        return self\n\n    id_generator = ((node_idx, node.node_id) for node_idx, node in enumerate(self.optree.all_nodes))\n\n    for idx, valid_id in id_generator:\n        if node_id == valid_id:\n            new_base = self.optree.all_nodes[idx]\n            return self.__class__(new_base.operation, device=self.device)\n    else:\n        raise ValueError(f\"Invalid node_id: {node_id}. Use `Meter(your_model).subnodes` to check valid ones.\")\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.stat_info","title":"stat_info","text":"Python<pre><code>stat_info(stat_or_statname: Union[str, Statistics], *, show_warning: bool = True) -&gt; Text\n</code></pre> <p>Generates a formatted summary of the specified statistics.</p> <p>This method provides a summary of the given statistics, including its name and the crucial data about this statistics. However, sometimes there may exist some modules which is defined but not explicitly called, or some modules that its calculation measurement logic is not defined in this version. To prevent confusing user, we will show inaccuracies warnings in the summary. If you don't want to see these warnings, you can set <code>show_warning</code> to <code>False</code> manually.</p> <p>Parameters:</p> Name Type Description Default <code>stat_or_statname</code> <code>Union[str, Statistics]</code> <p>The name of the statistics or the statistics object itself.</p> required <code>show_warning</code> <code>bool</code> <p>Whether to display warnings about potential inaccuracies. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>Text</code> <code>Text</code> <p>A <code>rich.Text</code> object containing the formatted summary.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>stat_or_statname</code> is neither a string nor a <code>Statistics</code> object.</p> Notes <ul> <li> <p>The main content will be obtained from the <code>crucial_data</code> property of the statistics object, which is   defined in the corresponding statistics class.</p> </li> <li> <p>For <code>ittp</code>, the number of repeated measurements, namely <code>Benchmark Times</code>, will be additionally   displayed. This value can be accessed or modified through the `ittp_benchmark_time' attribute.</p> </li> <li> <p><code>show_warning</code> option is keyword-only argument, so you should use it through its keyword name.</p> </li> <li> <p>Warnings are only shown for the following two statistics: calculation (<code>cal</code>) and memory (<code>mem</code>). Because   only these two statistics are affected by the no called modules or the not supported mudules.</p> </li> </ul> Example Python<pre><code>from torch import randn\nfrom torchmeter import Meter\nfrom torchvision import models\n\nfrom rich import print\n\nunderlying_model = models.vit_b_16()\nmodel = Meter(underlying_model)\n_ = model(randn(1, 3, 224, 224))\n\n# using statistics name\nprint(model.stat_info(\"param\"))\n\n# using statistics object\ncal = model.cal\nprint(model.stat_info(cal))\n\n# not show warnings\nprint(model.stat_info(\"mem\", show_warning=False))\n</code></pre> Source code in <code>torchmeter/core.py</code> Python<pre><code>def stat_info(self, stat_or_statname: Union[str, Statistics], *, show_warning: bool = True) -&gt; Text:  # noqa: C901\n    \"\"\"Generates a formatted summary of the specified statistics.\n\n    This method provides a summary of the given statistics, including its name and the crucial data\n    about this statistics. However, sometimes there may exist some modules which is defined but not\n    explicitly called, or some modules that its calculation measurement logic is not defined in this\n    version. To prevent confusing user, we will show inaccuracies warnings in the summary. If you don't\n    want to see these warnings, you can set `show_warning` to `False` manually.\n\n    Args:\n        stat_or_statname (Union[str, Statistics]): The name of the statistics or the statistics object itself.\n        show_warning (bool): Whether to display warnings about potential inaccuracies. Defaults to True.\n\n    Returns:\n        Text: A `rich.Text` object containing the formatted summary.\n\n    Raises:\n        TypeError: If `stat_or_statname` is neither a string nor a `Statistics` object.\n\n    Notes:\n        - The main content will be obtained from the `crucial_data` property of the statistics object, which is\n          defined in the corresponding statistics class.\n\n        - For `ittp`, the number of repeated measurements, namely `Benchmark Times`, will be additionally\n          displayed. This value can be accessed or modified through the `ittp_benchmark_time' attribute.\n\n        - `show_warning` option is keyword-only argument, so you should use it through its keyword name.\n\n        - Warnings are only shown for the following two statistics: calculation (`cal`) and memory (`mem`). Because\n          only these two statistics are affected by the no called modules or the not supported mudules.\n\n    Example:\n        ```python\n        from torch import randn\n        from torchmeter import Meter\n        from torchvision import models\n\n        from rich import print\n\n        underlying_model = models.vit_b_16()\n        model = Meter(underlying_model)\n        _ = model(randn(1, 3, 224, 224))\n\n        # using statistics name\n        print(model.stat_info(\"param\"))\n\n        # using statistics object\n        cal = model.cal\n        print(model.stat_info(cal))\n\n        # not show warnings\n        print(model.stat_info(\"mem\", show_warning=False))\n        ```\n    \"\"\"\n\n    if isinstance(stat_or_statname, str):\n        stat = getattr(self, stat_or_statname)\n    elif isinstance(stat_or_statname, Statistics):\n        stat = stat_or_statname\n    else:\n        raise TypeError(\n            f\"Invalid type for stat_or_statname: `{type(stat_or_statname).__name__}`. \"\n            + \"Please pass in the statistics name or the statistics object itself.\"\n        )\n\n    stat_name = stat.name\n    infos_ls: List[str] = [f\"\u2022 [b]Statistics:[/b] {stat_name}\"]\n\n    if stat_name == \"ittp\":\n        infos_ls.append(f\"\u2022 [b]Benchmark Times:[/b] {self.ittp_benchmark_time}\")\n\n    infos_ls.extend([f\"\u2022 [b]{k}:[/b] {v}\" for k, v in stat.crucial_data.items()])\n\n    # warning field, only works when stat is \"cal\" or \"mem\"\n    if show_warning and stat_name in (\"cal\", \"mem\"):\n        # cache for __has_nocall_nodes\n        if self.__has_nocall_nodes is None:\n            from operator import attrgetter\n\n            crucial_data_getter = attrgetter(f\"{stat_name}.crucial_data\")\n            try:\n                list(map(crucial_data_getter, self.optree.all_nodes))\n                self.__has_nocall_nodes = False\n            except RuntimeError:\n                self.__has_nocall_nodes = True\n\n        # cache for __has_not_support_nodes\n        if stat_name == \"cal\" and self.__has_not_support_nodes is None:\n            self.__has_not_support_nodes = any(n.cal.is_not_supported for n in self.optree.all_nodes)\n\n        warns_ls = []\n        if self.__has_nocall_nodes:\n            warns_ls.append(\n                \" \" * 2 + \"[dim yellow]:arrow_forward:  \" + \"Some nodes are defined but not called explicitly.[/]\"\n            )\n\n        if stat_name == \"cal\" and self.__has_not_support_nodes:\n            warns_ls.append(\n                \" \" * 2\n                + \"[dim yellow]:arrow_forward:  \"\n                + \"Some modules don't support calculation measurement yet.[/]\"\n            )\n\n        if warns_ls:\n            warns_ls.insert(0, \"[dim yellow]:warning:  Warning: the result may be inaccurate, cause:[/]\")\n            warns_ls.append(\n                \" \" * 2\n                + \"[dim cyan]:ballot_box_with_check:  \"\n                + f\"use `Meter(your_model).profile('{stat_name}')` to see more.[/]\"\n            )\n\n        infos_ls.extend(warns_ls)\n\n    infos = \"\\n\".join(infos_ls)\n\n    console = get_console()\n    return console.render_str(infos)\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.table_cols","title":"table_cols","text":"Python<pre><code>table_cols(stat_name: str) -&gt; Tuple[str, ...]\n</code></pre> <p>Get all column names of the backend dataframe for the specified statistics.</p> <p>This method returns the column names of the backend dataframe associated with the given statistics. If the dataframe is empty(i.e. the <code>profile</code> is not called yet), it falls back to the values of the <code>tb_fields</code> property of corresponding statistics class.</p> <p>Parameters:</p> Name Type Description Default <code>stat_name</code> <code>str</code> <p>The name of the statistics for which to retrieve the columns.</p> required <p>Returns:</p> Type Description <code>Tuple[str, ...]</code> <p>A tuple of column names for the specified statistics backend dataframe.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>stat_name</code> is not a string.</p> <code>KeyError</code> <p>If <code>stat_name</code> is not found in the available statistics (i.e. <code>param</code>, <code>cal</code>, <code>mem</code>, <code>ittp</code>).</p> Text Only<pre><code>default column names for each statistics:\n    - param: (\"Operation_Id\", \"Operation_Name\", \"Operation_Type\",\n              \"Param_Name\", \"Requires_Grad\", \"Numeric_Num\")\n\n    - cal: (\"Operation_Id\", \"Operation_Name\", \"Operation_Type\",\n            \"Kernel_Size\", \"Bias\", \"Input\", \"Output\", \"MACs\", \"FLOPs\")\n\n    - mem: (\"Operation_Id\", \"Operation_Name\", \"Operation_Type\",\n            \"Param_Cost\", \"Buffer_Cost\", \"Output_Cost\", \"Total\")\n\n    - ittp: (\"Operation_Id\", \"Operation_Name\", \"Operation_Type\",\n             \"Infer_Time\", \"Throughput\")\n</code></pre> Example Python<pre><code>from torchmeter import Meter\nfrom torchvision import models\n\nunderlying_model = models.resnet18()\nmodel = Meter(underlying_model)\n\nmodel.table_cols(\"param\")\n# ('Operation_Id',\n#  'Operation_Name',\n#  'Operation_Type',\n#  'Param_Name',\n#  'Requires_Grad',\n#  'Numeric_Num')\n\nmodel.table_cols(\"cal\")\n# ('Operation_Id',\n#  'Operation_Name',\n#  'Operation_Type',\n#  'Kernel_Size',\n#  'Bias',\n#  'Input',\n#  'Output',\n#  'MACs',\n#  'FLOPs')\n</code></pre> Source code in <code>torchmeter/core.py</code> Python<pre><code>def table_cols(self, stat_name: str) -&gt; Tuple[str, ...]:\n    \"\"\"Get all column names of the backend dataframe for the specified statistics.\n\n    This method returns the column names of the backend dataframe associated with the given statistics.\n    If the dataframe is empty(i.e. the `profile` is not called yet), it falls back to the values of the\n    `tb_fields` property of corresponding statistics class.\n\n    Args:\n        stat_name (str): The name of the statistics for which to retrieve the columns.\n\n    Returns:\n        A tuple of column names for the specified statistics backend dataframe.\n\n    Raises:\n        TypeError: If `stat_name` is not a string.\n        KeyError: If `stat_name` is not found in the available statistics (i.e. `param`, `cal`, `mem`, `ittp`).\n\n    Notes:\n\n        default column names for each statistics:\n            - param: (\"Operation_Id\", \"Operation_Name\", \"Operation_Type\",\n                      \"Param_Name\", \"Requires_Grad\", \"Numeric_Num\")\n\n            - cal: (\"Operation_Id\", \"Operation_Name\", \"Operation_Type\",\n                    \"Kernel_Size\", \"Bias\", \"Input\", \"Output\", \"MACs\", \"FLOPs\")\n\n            - mem: (\"Operation_Id\", \"Operation_Name\", \"Operation_Type\",\n                    \"Param_Cost\", \"Buffer_Cost\", \"Output_Cost\", \"Total\")\n\n            - ittp: (\"Operation_Id\", \"Operation_Name\", \"Operation_Type\",\n                     \"Infer_Time\", \"Throughput\")\n\n    Example:\n        ```python\n        from torchmeter import Meter\n        from torchvision import models\n\n        underlying_model = models.resnet18()\n        model = Meter(underlying_model)\n\n        model.table_cols(\"param\")\n        # ('Operation_Id',\n        #  'Operation_Name',\n        #  'Operation_Type',\n        #  'Param_Name',\n        #  'Requires_Grad',\n        #  'Numeric_Num')\n\n        model.table_cols(\"cal\")\n        # ('Operation_Id',\n        #  'Operation_Name',\n        #  'Operation_Type',\n        #  'Kernel_Size',\n        #  'Bias',\n        #  'Input',\n        #  'Output',\n        #  'MACs',\n        #  'FLOPs')\n        ```\n    \"\"\"\n\n    if not isinstance(stat_name, str):\n        raise TypeError(f\"stat_name must be a string, but got `{type(stat_name).__name__}`.\")\n\n    stats_data_dict: Dict[str, DataFrame] = self.table_renderer.stats_data\n\n    if stat_name not in stats_data_dict:\n        raise KeyError(f\"Statistics `{stat_name}` not in {tuple(stats_data_dict.keys())}.\")\n\n    stat_data: DataFrame = stats_data_dict[stat_name]\n\n    if stat_data.is_empty():\n        cols: Tuple[str, ...] = getattr(self.optree.root, stat_name).tb_fields\n    else:\n        cols = tuple(stat_data.columns)\n\n    return cols\n</code></pre>"},{"location":"api/core/#torchmeter.core.Meter.to","title":"to","text":"Python<pre><code>to(new_device: Union[str, device]) -&gt; None\n</code></pre> <p>Move the model to the specified device while keeping input and model device synchronization.</p> <p>Simulate the <code>to</code> method of pytorch model and use it to move model and all tensor data in <code>self._ipt</code> to the specified device.</p> <p>Parameters:</p> Name Type Description Default <code>new_device</code> <code>Union[str, device]</code> <p>Target device name or its corresponding torch.device object.</p> required Example Python<pre><code>import torch\nfrom torchmeter import Meter\nfrom torchvision import models\n\nunderlying_model = models.resnet18()\nmodel = Meter(underlying_model)\n\n# move to cuda:0\nmodel.to(\"cuda:0\")\n\n# move to cpu\nmodel.to(torch.device(\"cpu\"))\n</code></pre> Source code in <code>torchmeter/core.py</code> Python<pre><code>def to(self, new_device: Union[str, tc_device]) -&gt; None:\n    \"\"\"Move the model to the specified device while keeping input and model device synchronization.\n\n    Simulate the `to` method of pytorch model and use it to move model and all tensor data in\n    `self._ipt` to the specified device.\n\n    Args:\n        new_device (Union[str, torch.device]): Target device name or its corresponding torch.device object.\n\n    Example:\n        ```python\n        import torch\n        from torchmeter import Meter\n        from torchvision import models\n\n        underlying_model = models.resnet18()\n        model = Meter(underlying_model)\n\n        # move to cuda:0\n        model.to(\"cuda:0\")\n\n        # move to cpu\n        model.to(torch.device(\"cpu\"))\n        ```\n    \"\"\"\n    self.device = new_device  # type: ignore\n</code></pre>"},{"location":"contribute/conventions/","title":"Conventions \u2014 Let's Make it Easy and Standardize","text":"<p>Hi, contributors:</p> <p>We highly appreciate your patience in following these guidelines to help us keep <code>torchmeter</code> organized and maintainable.</p> <p>Thank you ! \ud83c\udf1f</p>"},{"location":"contribute/conventions/#Branch-Name","title":"Branch Name","text":""},{"location":"contribute/conventions/#Why-this-matters","title":"Why this matters?","text":"<p>Consistent naming rule helps us:  </p> <ul> <li>\ud83e\uddd0 Quickly evaluate contributions  </li> <li>\ud83d\udcaa Maintain codebase health  </li> <li>\ud83e\udd1d Improve collaborative efficiency  </li> </ul>"},{"location":"contribute/conventions/#Structure","title":"Structure","text":"<pre><code>[category]/[optional-issue-number]-[short-description]\n</code></pre> Key Principles <ol> <li>Descriptive &amp; Concise: Balance clarity with brevity for quick scanning</li> <li>Semantic Structure: Use meaningful prefixes and descriptive suffixes</li> <li>Traceability: Link branches to specific development contexts</li> </ol> Category Prefixes Prefix Purpose When to Use Example <code>feat</code> New functionality Adding new capabilities <code>feature/#86-optimize-cache</code> <code>bugfix</code> Bug corrections Fixing unexpected behavior <code>bugfix/div-zero-error</code> <code>docs</code> Documentation updates Improving guides/comments <code>docs/add-install-notes</code> <code>test</code> Testing improvements Enhancing test coverage <code>test/add-edge-cases</code> <code>refactor</code> Code restructuring Improving code structure <code>refactor/metrics-handler</code> <code>hotfix</code> Critical fixes Urgent production fixes <code>hotfix/memory-leak-patch</code> <code>chore</code> Project maintenance Updating dependencies/builds <code>chore/update-requirements</code>"},{"location":"contribute/conventions/#Best-Practices","title":"Best Practices","text":"Reference issues (when applicable) <pre><code>bugfix/#123-fix-tensor-shape\n</code></pre>  Keep it concise (3-5 key words) <pre><code># \ud83d\udc4d Clear and scoped\nfeat/nocall-modules-handling\n\n# \ud83d\udc4e Too vague\nfeat/new-stuff\n</code></pre>  Use lowercase with hyphens <pre><code># \ud83d\udc4d Consistent formatting\ndocs/update-contrib-guide\n\n# \ud83d\udc4e Mixed formatting\nDocs/Update_contrib_guide\n</code></pre>  Avoid unclear abbreviations <pre><code># \ud83d\udc4d Full description\nbugfix/fix-memory-leak\n\n# \ud83d\udc4e Use abbreviations without prior agreement\nbugfix/fx-mem\n</code></pre>  Avoid version numbers <pre><code># \ud83d\udc4d Feature description\nfeat/new-tree-renderer\n\n# \ud83d\udc4e Include version numbers\nfeat/v2.1.0\n</code></pre>"},{"location":"contribute/conventions/#Commit-Message","title":"Commit Message","text":""},{"location":"contribute/conventions/#Why-this-matters_1","title":"Why this matters?","text":"<p>Clear commit message helps us:</p> <ul> <li>\ud83d\udd0d Track down specific changes</li> <li>\ud83d\udcd6 Understand change context quickly</li> <li>\ud83e\udd1d Improve collaborative efficiency</li> </ul>"},{"location":"contribute/conventions/#Structure_1","title":"Structure","text":"<pre><code>&lt;type&gt;[optional scope]: &lt;subject&gt;\n\n[optional body]\n\n[optional footer]\n</code></pre> Type Prefixes Prefix Change Type Example <code>feat</code> New feature <code>feat(render): implement custom display of statistic</code> <code>fix</code> Bug fix <code>fix(memory): resolve CUDA memory leak in measuring mem</code> <code>docs</code> Documentation <code>docs: update API reference</code> <code>test</code> Test-related <code>test(metrics): add edge cases for xxx</code> <code>ci</code> Workflow-related <code>ci(badge-update): revise the content to be updated</code> <code>refactor</code> Code refactoring <code>refactor: simplify module registration</code> <code>perf</code> Performance <code>perf: optimize tree rendering</code> <code>chore</code> Repo maintemance <code>chore: update issue template</code> <code>build</code> Distribution packages building <code>build: update package introduction in setup.cfg</code> Scope <p>A scope is to identify the specific area of the codebase being modified</p> Scope Name Notes Example <code>infra</code> For DevOps/Infra changes <code>chore(infra): update CI config</code> <code>[module-name]</code> Match directory/module names <code>fix(core): add input validation for profile()</code> <code>[feature-area]</code> See below <code>perf(render): speed up tree rendering</code> <code>[document-section]</code> Specific doc section <code>docs(install): add method to install from source</code> <code>[workflow-funtion]</code> See below <code>ci(badge-update): revise the content to be updated</code> <code>unit</code> / <code>integrate</code> Test category <code>test(unit): add edge cases</code> Feature-Area Feature-Area Notes <code>render</code> Changes related to rendering and terminal output <code>measure</code> Changes related to the measurement of statistics <code>config</code> Changes related to global configuration <code>model-scan</code> Changes related to model structure exploration <code>api</code> Changes related to code logic, interface changes, performance improvements, etc. Workflow-Funtion Workflow-Funtion Notes <code>PR-title-lint</code> corresponding step: <code>pr_autolabel.yml::labeler::Check PR Title</code> <code>PR-auto-label</code> corresponding step: <code>pr_autolabel.yml::labeler::Label PR</code> <code>badge-update</code> corresponding job: <code>badge_updater.yml::Coverage-Badge</code> <code>lint-format</code> corresponding job: <code>*_test.yml::Lint-Format</code> <code>compatibility-test</code> corresponding job: <code>compatibility_test.yml::Compatibility-Test</code> <code>mini-test</code> corresponding job: <code>minimal_test.yml::Minimal-Test</code> <code>build</code> corresponding job: <code>publish_release.yml::Build-Distribution-Packages</code> <code>publish</code> corresponding job: <code>publish_release.yml::Publish-(Test)PyPI</code> <code>draft-release</code> corresponding job: <code>publish_release.yml::Publish-Release</code> <code>email-notify</code> corresponding step: <code>publish_release.yml::Publish-Release/Cleanup-Tag::Email Notification</code> Subject Line <ul> <li>Keep under 72 characters</li> <li>Use imperative mood: \"Add\" not \"Added\" or \"Adds\"</li> </ul> <pre><code># \ud83d\udc4d Good\nfeat: implement metric registry\n\n# \ud83d\udc4e Avoid\nImplemented metric registry\n</code></pre> Body (when needed) <ul> <li>Wrap text at 80 characters</li> <li>Reference issues using <code>closes #123</code> or <code>refs: #123</code></li> <li>Explain what and why rather than how</li> <li>Use ordered or unordered lists in <code>markdown</code> syntax to organize content</li> </ul> Footer (when needed) <ul> <li>Link pull requests: <code>refs: #45</code></li> <li>For breaking changes: <code>BREAKING CHANGE: &lt;description&gt;</code></li> </ul>"},{"location":"contribute/conventions/#Best-Practices_1","title":"Best Practices","text":"Feature Implementation <pre><code># \ud83d\udc4d Clear scope and imperative mood\nfeat(metrics): add precision-recall curve support\n\n- Implement curve plotting for binary classification tasks\n- Integrate with existing visualization toolkit\ncloses #88\n\n# ----------------------------------------------------------\n\n# \ud83d\udc4e Vague description\nAdded some metrics stuff\n</code></pre>  Documentation Update <pre><code># \ud83d\udc4d Specific document section reference\ndocs(tutorial): add distributed training example\n\n- Demonstrate multi-GPU usage with DDP\n- Add benchmark results table\nrefs: #102\n\n# ----------------------------------------------------------\n\n# \ud83d\udc4e Vague description\ndocs: update docs\n</code></pre>  Test Enhancement <pre><code># \ud83d\udc4d Clear test category and edge case\ntest(integrate): add fp16 precision validation\n\n- Verify tensor dtype conversion in mixed precision mode\n- Add tolerance thresholds for different hardware\n\n# ----------------------------------------------------------\n\n# \ud83d\udc4e Unclear test scope\ntest: fix some tests\n</code></pre>  Code Refactoring <pre><code># \ud83d\udc4d Modular improvement explanation\nrefactor(core): decouple metric calculation from IO\n\n- Separate computation logic from result saving\n- Create new ResultHandler class\n- BREAKING CHANGE: Remove save_to_csv() method\n\n# ----------------------------------------------------------\n\n# \ud83d\udc4e No scope/benefit explanation\nrefactor: change some code\n</code></pre>  Performance Optimization <pre><code># \ud83d\udc4d Quantifiable improvement\nperf(render): reduce tree visualization latency by 40%\n\n- Implement lazy loading for large model structures\n- Add caching mechanism for common architectures\n\n# ----------------------------------------------------------\n\n# \ud83d\udc4e Generic claim\nperf: make it faster\n</code></pre>  Maintenance Task <pre><code># \ud83d\udc4d Clear infra context\nchore(infra): migrate CI from Travis to GitHub Actions\n\n- Add workflow for automated PyTorch version matrix testing\n- Remove .travis.yml configuration\n\n# ----------------------------------------------------------\n\n# \ud83d\udc4e Ambiguous maintenance\nchore: update files\n</code></pre>"},{"location":"contribute/conventions/#Pull-Request-Title","title":"Pull Request Title","text":""},{"location":"contribute/conventions/#Why-this-matters_2","title":"Why this matters?","text":"<ul> <li>\ud83c\udff7\ufe0f Facilitates PR categorization and management.</li> <li>\u2705 Required for merging \u2013 Valid titles are enforced by automated checks in our workflow .</li> <li>\ud83e\udd16 Enables automated changelog generation for releases \u2013 <code>torchmeter</code> use release-drafter  to generate release notes based on PR labels.</li> </ul>"},{"location":"contribute/conventions/#Structure_2","title":"Structure","text":"<pre><code>&lt;type&gt;[optional scope][optional !]: &lt;subject&gt;\n</code></pre> Type Prefixes <p>Most are the same as Commit Message Type Prefixes , cause the PR will finally be merged as a commit.</p> <p>Limitations</p> <p>Type prefix must be one in the following table, otherwise the PR will be rejected!</p> PR Type When to Use Example <code>feat</code> New features <code>feat: add FP16 support</code> <code>fix</code> Bug fixes <code>fix(core): memory leak</code> <code>perf</code> Performance improvements <code>perf: optimize rendering</code> <code>depr</code> Deprecations <code>depr: remove old API</code> <code>docs</code> Documentation updates <code>docs: add API examples</code> <code>test</code> Test-related changes <code>test: add edge cases</code> <code>ci</code> CI/CD improvements <code>ci: add GPU testing</code> <code>build</code> Changes related to building <code>build: update setup.cfg</code> <code>refactor</code> Code restructuring <code>refactor: clean utils</code> <code>revert</code> Reverted changes <code>revert: #123 change</code> <code>chore</code> Maintenance tasks <code>chore: update deps</code> Scope (Optional) <p>Totally same as Commit Message Scope .</p> <ul> <li>If you don't plan to add a scope, please don't leave parentheses in the PR title.</li> <li>Scope must not be empty or start with a space.</li> </ul> <pre><code># \ud83d\udc4d Good\nfix(core): Memory leak\n\n# \ud83d\udc4e Avoid\nfix(): Memory leak\n</code></pre> <pre><code># \ud83d\udc4d Good\nfix(core): Memory leak\n\n# \ud83d\udc4e Avoid\nfix( ): Memory leak\nfix( core): memory leak\n</code></pre> Exclamation Mark (<code>!</code>, Optional) <p>A <code>!</code> indicates a breaking change, which means that the PR will bring a major version bump. Therefore, please use it with caution. The PRs denoted by <code>!</code> will undergo a more rigorous review procedure.</p> Subject <p>Mostly same as Commit Message Subject </p> <ul> <li>Keep under 72 characters</li> <li>Use imperative mood: <code>Add</code> not <code>Added</code></li> <li>Capitalize the initial letter.</li> <li>Avoid ending with punctuation</li> <li>Not to reference issues/PR/discussion at beginning</li> </ul> <pre><code># \ud83d\udc4d Good\nfix: memory leak described in #456\n\n# \ud83d\udc4e Avoid\nfix: #456 memory leak\n</code></pre>"},{"location":"contribute/conventions/#Best-Practices_2","title":"Best Practices","text":"<p>Quick Validation</p> <p>You can validate your PR title with: <code>bash misc/validate_pr_title.sh '&lt;your-PR-title&gt;'</code></p>  Valid type usage <pre><code># \ud83d\udc4d Proper type\nfeat: Add histogram visualization\n\n# \ud83d\udc4e Invalid type\nfeats: Add histogram visualization\n</code></pre>  Valid Scope Usage <pre><code># \ud83d\udc4d Proper scoping\nfeat(metrics): Add histogram visualization\n\n# \ud83d\udc4e Empty parentheses\nfeat(): Add new feature\n\n# \ud83d\udc4e Space in scrpe beginning\nfeat( ): Add new feature\nfeat( core): Add new feature\n</code></pre>  Space before Subject <pre><code># \ud83d\udc4d Only one space before subject line\nrefactor: Remove deprecated methods\n\n# \ud83d\udc4e no/more than one space\nrefactor:Remove deprecated methods\nrefactor:  Remove deprecated methods\n</code></pre>  Capitalize the Beginning of Subject <pre><code># \ud83d\udc4d Capitalized.\nrefactor: Remove deprecated methods\n\n# \ud83d\udc4e Not been capitalized\nrefactor: remove deprecated methods\n</code></pre>  Imperative Mood <pre><code># \ud83d\udc4d Correct imperative form\nfix(core): Resolve memory leak\n\n# \ud83d\udc4e Past tense usage\nfix(core): Memory leak resolved\n</code></pre>  Reference Placement <pre><code># \ud83d\udc4d Proper reference position\ndocs: Update installation guide (closes #123)\n\n# \ud83d\udc4e Error position\ndocs(#123): Update installation guide\ndocs: #123 Update installation guide\n</code></pre>  Length Control <pre><code># \ud83d\udc4d Concise title (68 chars)\nperf(render): Optimize tree rendering latency using lazy-load\n\n# \ud83d\udc4e Overly long title (89 chars)\nperf(render): Implement multiple optimization techniques including lazy-load and caching for tree rendering\n</code></pre>  Punctuation Rules <pre><code># \ud83d\udc4d Clean ending\nchore(ci): Migrate to GitHub Actions\n\n# \ud83d\udc4e Trailing punctuation\nchore(ci): Update CI configuration.\n</code></pre>"},{"location":"contribute/discussions/","title":"Discussions \u2014 Let's Collaborate &amp; Innovate!","text":"Note <p> Access to <code>Discussions</code> </p> <ul> <li>Discussions section is for non-urgent questions, seeking help, sharing ideas, or general chatting.  </li> <li>Further reading: Github Docs of Discussions </li> </ul>"},{"location":"contribute/discussions/#Scenarios-of-Using-Discussions","title":"Scenarios of Using Discussions","text":"<ul> <li> Share use cases </li> <li> Ask \"how-to\" questions </li> <li> Brainstorm new features</li> <li> Discuss performance optimization strategies </li> <li> Propose major refactorings or breaking changes </li> <li> Bug Reporting \u2192 Use Issues </li> <li> Feature Requests \u2192 Use Issues </li> </ul>"},{"location":"contribute/discussions/#How-to-participate-in-a-Discussion","title":"How to participate in a Discussion","text":"<ul> <li> <p>Starting a discussion </p> </li> <li> <p>Starting a poll </p> </li> </ul>"},{"location":"contribute/discussions/#Suggestions","title":"Suggestions","text":"<ol> <li> <p>Search First \ud83d\udd0d</p> <ul> <li>Search for similar topics first</li> <li>Join existing discussions when possible</li> <li>Create new thread only for distinct topics</li> </ul> </li> <li> <p>Hook 'em with a great title \u270d\ufe0f</p> <ul> <li>\u2705 Clear example: <code>\"How to show raw data in the tabular report?\"</code> </li> <li>\u274c Avoid vague titles: <code>\"Help pls\"</code> </li> </ul> </li> <li> <p>Structure Your Post \ud83d\udccb</p> <ul> <li>Organize content with special markdown syntax, such as header, code blocks, quotes, details blocks, etc. Check markdown syntax on Github  for more details.</li> <li>Link the discussion to relevant issues or PRs if applicable. Use <code>#issue-number</code>/<code>#pr-number</code> syntax to link to issues or PRs. </li> </ul> </li> <li> <p>Engage Effectively \ud83d\ude4b\u200d\u2642\ufe0f</p> <ul> <li>Be respectful &amp; constructive  </li> <li>Stay on-topic: Keep replies focused on the topic. </li> <li>Acknowledge Contributors: Always general to mark someone\u2019s comment as answer  if it helps resolve your problem, their contributions deserve recognition!</li> </ul> </li> </ol>"},{"location":"contribute/issues/","title":"Issues \u2014 Let's Report &amp; Enhance!","text":"Note <p> Access to <code>Issues</code> </p> <ul> <li>Issues section is for reporting urgent bugs or feature requests </li> <li>Further reading: Github Docs of Issues </li> </ul>"},{"location":"contribute/issues/#Scenarios-of-Filing-Issues","title":"Scenarios of Filing Issues","text":"<ul> <li> Bugs reports</li> <li> Feature proposals</li> <li> Documentation errors reports</li> <li> Non-Urgent Questions \u2192 Use Discussions </li> <li> Help with Usage \u2192 Use Discussions </li> </ul>"},{"location":"contribute/issues/#Submission-Guide","title":"Submission Guide","text":"<ol> <li> <p>Search First \ud83d\udd0d: </p> <ul> <li>Check existing issues (open/closed)</li> <li>If there are relevant issues, comment if you have more details. If the issue is addressed, give a \ud83d\udc4d reaction to show support, it motivates everyone involved!</li> <li>Otherwise, create a new issue following the steps below.</li> </ul> </li> <li> <p>File an Issue \ud83d\uddf3 </p> <ul> <li>Navigate to the <code>Issues</code> tab  and click <code>New issue</code>.  </li> <li>Select the template matching your scenario (bug report, feature request, etc.).  </li> <li>Fill out all fields (asterisks <code>*</code> denote required information).  </li> <li>Click <code>Create</code> to submit.  </li> </ul> </li> </ol> Tips Illustration of filing an issue <p></p> <ul> <li>Further reading: How maintainers manage issues </li> </ul>"},{"location":"contribute/issues/#Suggestions","title":"Suggestions","text":"<ol> <li> <p>Ensure a Clear Title \u270d\ufe0f  </p> <ul> <li>\u2705 Good example: <code>\"Export data error: target file not found\"</code></li> <li>\u274c Avoid vague titles: <code>\"Something's wrong!\"</code></li> </ul> </li> <li> <p>Link Related Content \ud83d\udd17  </p> <ul> <li>If this issue relates to other issues, discussions, or PRs, use <code>#corresponding-number</code> to reference them.</li> </ul> </li> <li> <p>Tell the Full Story </p> <ul> <li>If create an issue from a template: Fill out all requested fields for complete information.  </li> <li>If participate in existing issues: Use the simplified template below to share your additional details.</li> </ul> </li> </ol> Issue comment template for supplementing details<pre><code>## If my situation differs from the issue author's\n\n- [ ] No\n- [ ] Yes\n\n&lt;!-- If choose yes, describe your case --&gt;\nIn my case, I found that...\n\n## Steps to Reproduce\n\n&lt;details&gt;\n&lt;summary&gt;Steps&lt;/summary&gt;\n\n1. \n2. \n3. \n\n&lt;/details&gt;\n\n## Environment\n\n- `OS`: Ubuntu 22.04\n- `Python`: 3.10\n- `torchmeter`: 0.4.2\n\n## Additional context\n\n&lt;!-- \nAny addition information helping to resolve this issue is welcome. \\\nYou can include code snippets, error traces, screenshots/GIFs, or other relevant materials here. \n--&gt;\n\n&lt;details&gt;\n&lt;summary&gt;Details&lt;/summary&gt;\n\n1. \n2. \n3. \n\n&lt;/details&gt;\n</code></pre>"},{"location":"contribute/prs/","title":"Pull Requests \u2014 Let's Squash Bugs &amp; Build Features!","text":"Note <p> Access to <code>Pull Requests(PRs)</code> </p> <ul> <li>Pull Requests (PRs) are for code contributions</li> <li>Further reading: Github Docs of Pull Requests </li> </ul>"},{"location":"contribute/prs/#Scenarios-of-Submitting-a-PR","title":"Scenarios of Submitting a PR","text":"<ul> <li> Fix bugs </li> <li> Add new feature </li> <li> Update documentation </li> <li> Performance optimizations </li> <li> Test coverage enhancements </li> <li> CI/CD pipeline improvements</li> <li> Code improvements / refactoring </li> </ul>"},{"location":"contribute/prs/#Step-by-Step-Guide","title":"Step-by-Step Guide","text":"Prerequisite Knowledge <ol> <li> <p><code>torchmeter</code> is hosted on GitHub , so you\u2019ll need a GitHub Account  to begin contributing.</p> </li> <li> <p><code>torchmeter</code> uses Git  for version control. If you're unfamiliar with <code>Git basics</code> or <code>GitHub PR workflows</code>, we recommend these resources: </p> <ul> <li>Git Tutorial  </li> <li>GitHub's Guide to Contributing via PR </li> </ul> </li> <li> <p>Our contribution process draw inspiration from projects like <code>numpy</code>, <code>pandas</code>, <code>polars</code>, and <code>rich</code>. For reference:</p> </li> </ol> <ul> <li> Numpy's contributing guide </li> <li> Pandas' contributing guide </li> <li> Polars' contributing guide </li> <li> Rich's contributing guide </li> </ul>"},{"location":"contribute/prs/#A-Claim-Your-Mission","title":"A. Claim Your Mission","text":"Section Overview <p>This section will guide you through:</p> <ul> <li>Discovering beginner-friendly start points</li> <li>Properly claiming unassigned issues</li> <li>Collaborating on existing development efforts</li> </ul> <p>By following these protocols, you'll establish clear ownership while respecting community norms. We're excited to help you find meaningful work that aligns with project needs and your interests!</p> <ol> <li> <p>Finding Beginner-Friendly Issues: New to <code>torchmeter</code> or open-source? We recommend:</p> <ul> <li> <p>Start by searching for <code>good-first-issue</code> labeled issues on the Issues page . These are specially marked for beginners and often have clear scopes.</p> </li> <li> <p>Look for issues without existing assignees to avoid duplication of effort.</p> </li> </ul> </li> <li> <p>Claiming an Issue</p> <p>To take ownership of an unassigned issue: Leave a polite comment like: <code>\"I\u2019d try to work on this!\"</code> or just a single <code>\"take\"</code>. This signals your intent and allows maintainers to assign it to you.</p> Responsibility Note <p>Claiming an issue means you\u2019ll be responsible for following up and resolving it. If circumstances prevent you from continuing, please update the thread promptly so others can help.</p> </li> <li> <p>Joining Existing Efforts</p> <ul> <li> <p>Politely ask current assignee via comment: For example, <code>\"Hi @username, may I collaborate on this?\"</code></p> </li> <li> <p>Wait patiently: If the current contributor hasn\u2019t updated the issue for 7+ days, you may gently ask if they need help or if you can take over.</p> </li> </ul> </li> </ol>"},{"location":"contribute/prs/#B-Environment-Setup","title":"B. Environment Setup","text":"Section Overview <p>This section will help you configure a development environment for <code>torchmeter</code>. We'll walk through essential steps including:</p> <ul> <li><code>Git</code> configuration for version control</li> <li><code>Python</code> environment setup with required dependencies</li> <li>Local repository initialization and remote tracking</li> </ul> <p>By completing these steps, you'll have a fully functional setup to make contribution efficiently. Let's begin now!</p>"},{"location":"contribute/prs/#Ba-Download--Install-Git","title":"B.a Download &amp; Install Git","text":"<ol> <li> <p>Download <code>Git</code> through its download page \u2192 https://git-scm.com/downloads</p> </li> <li> <p>Verify Installation: Open your terminal and run the following command.</p> </li> </ol> Bash<pre><code>git --version\n</code></pre> <p>A successful installation will display the <code>Git</code> version (e.g., <code>git version 2.49.0</code>).</p>"},{"location":"contribute/prs/#Bb-Create-a-Fork-Repository","title":"B.b Create a Fork Repository","text":"What is a fork repository? <ul> <li>A fork repo is a copy of the original repository, allowing you to make changes without affecting the original project. </li> <li>Learn more: GitHub Forking Guide </li> </ul> <ol> <li> <p>Go to the official <code>torchmeter</code> repository page \u2192 https://github.com/TorchMeter/torchmeter</p> </li> <li> <p>Click the <code>Fork</code> button in the top-right corner</p> </li> <li> <p>Configure your fork:</p> <ul> <li>Select your <code>GitHub Account</code> as the owner</li> <li>Keep the default repository name unless you want to customize it</li> <li>(Optional) Uncheck <code>Copy the master branch only</code> to include all branches</li> </ul> </li> <li> <p>Click <code>Create fork</code>. You'll now have a personal sandbox repository at <code>https://github.com/&lt;your-username&gt;/torchmeter</code> if you have not changed the default repository name.</p> </li> </ol> Illustration of forking torchmeter <p></p>"},{"location":"contribute/prs/#Bc-Clone-Your-Fork-to-Local-Machine","title":"B.c Clone Your Fork to Local Machine","text":"<ol> <li> <p>Go to your GitHub account's Repositories page  and navigate to your newly created fork of <code>torchmeter</code>.</p> </li> <li> <p>Copy the repository URL:</p> <ul> <li>Click the green <code>Code</code> button on your fork's page</li> <li>Select the <code>Local-HTTPS</code> tab and copy the URL (i.e., <code>https://github.com/&lt;your-username&gt;/torchmeter.git</code> if you kept the default repository name)</li> </ul> </li> <li> <p>Clone to your local system</p> Bash<pre><code>cd path/to/store/your/project\n\ngit clone &lt;paste-the-url-copied-in-last-step-here&gt; torchmeter-yourname  # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>torchmeter-yourname</code> with any string you want. This will be the directory name for the local copy of your fork repository.</li> </ol> </li> <li> <p>Verify: A new directory <code>torchmeter-yourname</code> will be created containing:</p> <ul> <li>Working directory: Your local copy of the project files</li> <li>Local repository: The <code>.git</code> folder managing version control (contains commit history, branches, etc.)</li> </ul> </li> </ol> What is the difference between the working directory (aka workspace) and the local repository? Working DirectoryLocal Repository <ul> <li>What: Your project folder (i.e., <code>torchmeter-yourname</code> in the last step) where you edit files directly.</li> <li>Contains: Live files (e.g., modified <code>python</code> scripts).</li> <li>Actions: <code>manual edits</code>, <code>git add</code></li> </ul> <ul> <li>What: The <code>.git</code> folder (hidden) in the project root.</li> <li>Contains: Full <code>Git</code> history (commits, branches).</li> <li>Actions: <code>git commit</code>, <code>git log</code></li> </ul> <ul> <li>Further reading: What is the difference between the working directory (aka workspace) and the repository? </li> </ul>"},{"location":"contribute/prs/#Bd-Link-to-Official-Repository-Upstream","title":"B.d Link to Official Repository (Upstream)","text":"<ol> <li> <p>Set up upstream tracking to sync with the latest changes:</p> Bash<pre><code># pwd: path/to/store/your/project\n\ncd torchmeter-yourname # (1)\n\n# Add the official repository as upstream\ngit remote add upstream https://github.com/TorchMeter/torchmeter.git\n\n# Fetch the latest updates\ngit fetch upstream\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>torchmeter-yourname</code> with the directory name you set in step B.c.3.</li> </ol> </li> <li> <p>Verify remote &amp; upstream tracking:</p> Bash<pre><code># pwd: path/to/your/working/directory\n\ngit branch -a\n</code></pre> <p>Ensure the output contains the highlighted lines below. If you uncheck \"Copy the master branch only\" (1) when forking, you might see info of additional branches like <code>v0.1.x</code> (2) - these can be safely ignored as we ultimately create PRs against the master branch.</p> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f refer to step B.b.3.</li> <li>\ud83d\ude4b\u200d\u2642\ufe0f lines 7-8</li> </ol> <p>Expected output<pre><code>* master\nremotes/origin/HEAD -&gt; origin/master\nremotes/origin/master\nremotes/upstream/HEAD -&gt; upstream/master\nremotes/upstream/master\n\nremotes/origin/v0.1.x\nremotes/upstream/v0.1.x \n</code></pre> </p> Why we do this? <p>After this step, your local repository now has two remote references, both are critical to the contribution process:</p> remotes/originremotes/upstream <ul> <li>The repo it points to: Your fork on GitHub, i.e., <code>https://github.com/&lt;your-username&gt;/torchmeter</code> if you kept the default repository name in forking.</li> <li>Purpose: To receive local changes for future PR submissions to the official repository</li> </ul> <ul> <li>The repo it points to: The official <code>torchmeter</code> repository, i.e., <code>https://github.com/TorchMeter/torchmeter</code></li> <li>Purpose: To keep your local repository synchronized with the official repository's updates to avoid merge conflicts when submitting PRs</li> </ul> <p>If you're unfamiliar with these concepts or the open-source contribution process, don't worry! We'll walk you through the entire workflow step-by-step in the following sections.</p>"},{"location":"contribute/prs/#Be-Configure-Python-Environment","title":"B.e Configure Python Environment","text":"About Python Environment <ul> <li>We highly recommend creating a dedicated <code>Python</code> virtual environment for <code>torchmeter</code> development. </li> <li>You can use virtual environment management tools like <code>venv</code>, <code>uv</code>, <code>poetry</code>, or <code>conda</code>, etc.</li> <li>Here we'll use <code>conda</code> as an example; other tools can be configured via their official documentation.</li> </ul> <ol> <li> <p>Install <code>Miniconda</code>:</p> <ul> <li> <p>Official guide: Miniconda Installation </p> </li> <li> <p>Verify installation:</p> </li> </ul> Bash<pre><code># pwd: anywhere\nconda --version  \n</code></pre> <p>Expected output: conda version (e.g., <code>conda 24.1.2</code>)</p> </li> <li> <p>Create virtual environment with <code>Python 3.8</code> (minimum required version):</p> Bash<pre><code># pwd: anywhere\n\nconda create -n torchmeter-dev python=3.8 # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f <code>torchmeter-dev</code> is customizable, is the virtual environment name</li> </ol> </li> <li> <p>Install <code>torchmeter</code> as well as its dependencies in editable mode:</p> Bash<pre><code># pwd: path/to/your/working/directory\n\nconda activate torchmeter-dev # (1)\npip install -e \".[test]\" # (2)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>torchmeter-dev</code> with your virtual environment name.</li> <li>\ud83d\ude4b\u200d\u2642\ufe0f The <code>-e</code> flag is required to enable coverage tracking in testing. Omitting it may cause coverage calculation errors.</li> </ol> </li> </ol> For Windows Users with NVIDIA GPUs <p>On Windows systems, <code>pip</code> may default to installing the <code>CPU</code> version of <code>PyTorch</code>, which prevents leveraging <code>GPU</code> acceleration. Please follow these steps to manually verify and install the <code>GPU-enabled PyTorch</code> version:</p> <ol> <li> <p>Verify <code>Pytorch</code>'s <code>CUDA</code> compatibility:</p> PowerShell<pre><code># pwd: anywhere\n\nconda activate torchmeter-dev  # (1)\n\npython -c \"import torch; print(torch.cuda.is_available())\"  \n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>torchmeter-dev</code> with your virtual environment name</li> </ol> <p>If you have installed the <code>CUDA-enabled Pytorch</code> version, the output of the command should be <code>True</code>. </p> <p>If it is, you can skip this part and proceed to section C.</p> </li> <li> <p>If the command return <code>False</code>, manually install <code>GPU-enabled Pytorch</code>:</p> <ol> <li> <p>Determine <code>CUDA</code> version:</p> PowerShell<pre><code># pwd: anywhere\n\nnvidia-smi | findstr \"CUDA Version\"  # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Check the version number, e.g. <code>CUDA Version: 12.4</code></li> </ol> </li> <li> <p>Download appropriate <code>Pytorch</code> wheel:</p> <ul> <li><code>Pytorch</code> binaries \u2192 https://download.pytorch.org/whl/torch. Note that <code>torchmeter</code> supports <code>Pytorch</code> versions \u2265 <code>1.7.0</code>.</li> <li>Match <code>Python</code> version (e.g., <code>cp38</code> for <code>Python 3.8</code>), <code>CUDA</code> version (e.g., <code>cu124</code>), and <code>OS</code>. Example: <code>torch-2.4.1+cu124-cp38-cp38-win_amd64.whl</code></li> </ul> </li> <li> <p>Install <code>torch</code> by <code>whl</code> file:</p> PowerShell<pre><code># pwd: anywhere\n\nconda activate torchmeter-dev # (1)\n\npip install path/to/downloaded/torch.whl\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>torchmeter-dev</code> with your virtual environment name</li> </ol> </li> </ol> </li> <li> <p>Validate <code>GPU</code> support: re-execute the command in <code>step 1</code> to confirm <code>GPU</code> support.</p> </li> </ol>"},{"location":"contribute/prs/#C-Making-Code-Changes","title":"C. Making Code Changes","text":"Section Overview <p>This section will guide you through:</p> <ul> <li>Understanding code architecture and implementing changes</li> <li>Maintaining code quality through type-checking, linting and testing</li> <li>Following proper version control practices for local/remote submissions</li> </ul> <p>By completing these steps, your code will not only adhere to project standards and remain robust and maintainable, but also be properly prepared for official review.</p>"},{"location":"contribute/prs/#Ca-Understanding-Code--Getting-started","title":"C.a Understanding Code &amp; Getting started","text":"Recommended Tools for this Step Debugger: <code>pdb</code>Interactive Development: <code>IPython</code> <ul> <li>Purpose: For code debugging</li> <li>Quickstart Guide: PDB Tutorial </li> <li>Documentation: Python PDB Docs </li> </ul> <ul> <li>Purpose: For rapid logic validation (powerful REPL)</li> <li>Documentation: IPython Official Site </li> </ul> <ol> <li> <p>Fetch Latest Code of <code>torchmeter</code> </p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit checkout master\ngit pull upstream master --ff-only\n</code></pre> </li> <li> <p>Create Your Development Branch</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\n# Replace `&lt;your-branch-name&gt;` with your branch name\ngit checkout -b &lt;your-branch-name&gt; upstream/master # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>&lt;your-branch-name&gt;</code> with your branch name. When naming a branch, please follow our branch naming conventions .</li> </ol> <p>Branch Name conventions</p> <p>When naming a branch, please follow our branch naming conventions .</p> </li> <li> <p>Dive into the code</p> <ol> <li> <p>You can start by reviewing the annotated project tree  for a quick understanding of the project layout.</p> </li> <li> <p>Based on your insights, locate the specific files/classes/functions to modify. You can make it via the <code>IDE</code>'s file tree, text searching or <code>IDE</code> navigation (<code>Ctrl/Cmd+Click</code> to jump to definitions).</p> </li> <li> <p>If you successfully find the parts you need to modify, you can start reading the source code in combination with the annotation document to figure out its logic and working principle.</p> </li> <li> <p>If you\u2019re stuck, there are 2 ways to move on:</p> <ul> <li> <p>Use <code>pdb</code> breakpoints: insert <code>import pdb; pdb.set_trace()</code> at the problematic part of the code, then run the code and it will stop at the breakpoint and allow you to inspect the variables.</p> </li> <li> <p>For persistent confusion, kindly start a Discussion  to seek assistance.</p> </li> </ul> </li> </ol> </li> <li> <p>Start implementing your modifications after fully grasping the existing logic. Note that it's highly recommended to focus your changes on one issue or feature. This will make the review process easier.</p> </li> <li> <p>You can verify your modifications through debugging or custom scripts, but we recommend using <code>IPython</code> for rapid testing:</p> <ol> <li> <p>Install <code>Ipython</code>:</p> Bash<pre><code># Replace `torchmeter-dev` with your virtual environment name\nconda activate torchmeter-dev\n\npip install ipython\n</code></pre> </li> <li> <p>Open the terminal and type <code>ipython</code> to start the interactive    environment. You can then import and test your modified code directly. For example, if you added a new function <code>new_func()</code> in <code>torchmeter.core</code>: </p> Python<pre><code>from torchmeter.core import new_func\n\n# Test your implementation\nnew_func(args1, args2)\n</code></pre> </li> </ol> </li> <li> <p>Finally, update contributors list: </p> <ol> <li>Open <code>CONTRIBUTORS.md</code>  in the project root directory</li> <li> <p>Add your information at the end following the format below:</p> Markdown<pre><code>- [Your-Name/Github-ID](GitHub-profile/your-home-page)\n</code></pre> </li> </ol> </li> </ol>"},{"location":"contribute/prs/#Cb-Lint-Format-and-Test-your-Code","title":"C.b Lint, Format and Test your Code","text":"Recommended Tools for this Step <p>For <code>VSCode</code> users, we recommend installing these extensions:</p> <code>Ruff</code><code>Mypy Type Checker</code> <ul> <li>Plugin page  </li> <li>Highlight: This plugin uses underlines to highlight code snippets that do not conform to the predefined rules and allows you to automatically fix some common errors.</li> </ul> <ul> <li>Plugin page </li> <li>Highlight: This plugin also works with underlines to highlight code snippets that has wrong type annotations or lacks required ones.</li> </ul> <p>To ensure your code meets <code>torchmeter</code>'s standards, please complete these 3 critical steps in order.</p> <ol> <li> <p>Type Checking</p> <ul> <li> <p><code>torchmeter</code> uses <code>mypy</code> for static type checking (already installed in step B.e.3).</p> </li> <li> <p>You'll need to add type annotations to your changes. Please refer to <code>mypy</code> documentation  for best practices.</p> </li> <li> <p>After completing the type annotations, make sure to pass the following type checking commands:</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\nconda activate torchmeter-dev # (1)\n\nmypy ./torchmeter\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>torchmeter-dev</code> with your virtual environment name.</li> </ol> </li> </ul> <p>You should promise output is something like <code>Success: no issues found in &lt;number-of-files&gt; source files</code></p> </li> <li> <p>Linting and Formatting</p> <ul> <li> <p><code>torchmeter</code> uses ruff  for linting and formatting (already installed in step B.e.3).</p> </li> <li> <p>Our style rules are defined in <code>ruff.toml</code>  at project root. Please respect these configurations, if you find any rules unreasonable, please start a Discussions .</p> </li> <li> <p>Ensure the code format of your changes meets the project requirements by running the following formating commands:</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\nconda activate torchmeter-dev # (1)\n\nruff format \\\n--preview \\\n--target-version=py38 \n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>torchmeter-dev</code> with your virtual environment name.</li> </ol> <p>You should promise the command ends successfully</p> </li> <li> <p>After that, ensure your changes comply with the project's code style with the following commands:</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\nconda activate torchmeter-dev # (1)\n\nruff check \\\n--fix \\\n--unsafe-fixes \\\n--preview \\\n--target-version=py38\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>torchmeter-dev</code> with your virtual environment name.</li> </ol> <p>You should promise output is <code>All checks passed!</code> and no errors are reported.</p> </li> <li> <p>If any step fails, please modify the code according to the terminal output and re-execute the above steps until all steps are successful.</p> </li> </ul> One command method <p>If you have a way to run the <code>shell</code> script (on <code>Unix</code>-like systems or <code>cygwin</code> on <code>windows</code>), then: </p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/  \n\nbash misc/lint_format.sh  \n</code></pre> <p>This runs all linting and formatting in one command.</p> </li> <li> <p>Testing</p> <ul> <li> <p><code>torchmeter</code> uses <code>pytest</code> for testing code. Yes, <code>pytest</code> and the related plugins have also been installed in step B.e.3.</p> </li> <li> <p><code>torchmeter</code> has written the <code>pytest</code> running configuration in <code>pytest.ini</code> file at project root. This file defines how the tests are run, including the test directory, test filters, test configuration, etc. Specifically, <code>pytest</code> will only discover tests in the <code>tests</code> directory at project root, and requires a test coverage rate of &gt; 90%. </p> </li> <li> <p>Therefore, if you add new functions or classes, please ensure that corresponding test cases are added. Regarding the writing of test cases, you can refer to the official documentation  of <code>pytest</code> or quickly get started through the project <code>python_testing_tutorial</code> . During the process of writing test cases, we recommend using <code>fixture</code> and <code>parametrize</code> for parameterized testing, so as to reduce duplicate code.</p> </li> <li> <p>After you've completed the above steps (i.e. <code>type annotation</code>, <code>linting and formatting</code>), please make sure to run the following commands to ensure the logical correctness and stability of the code. </p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\nconda activate torchmeter-dev # (1)\n\npytest -q\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>torchmeter-dev</code> with your virtual environment name</li> </ol> </li> </ul> <p>You should promise there is no error reported in the output. If all tests passed, you will see the coverage report in the terminal.</p> </li> </ol>"},{"location":"contribute/prs/#Cc-Add-Documentation-for-Your-Code","title":"C.c Add Documentation for Your Code","text":"Why should I do this? Your expertise <p>Your first-hand knowledge makes your documentation the most authoritative and comprehensive source.  </p> Enhance readability <p>Clear documentation helps maintainers quickly grasp your code's logic and intent during PR reviews.  </p> Faster iteration Consistent documentation practices reduce redundant efforts for maintainers, allowing <code>torchmeter</code> to evolve more efficiently.   How torchmeter builds docs <ul> <li> <p>The documentation of <code>torchmeter</code> is built based on <code>mkdocs</code> . For the <code>API Reference</code> section , <code>mkdocstrings[python]</code>  is used to extract multi-level annotations of modules, classes, functions, etc. and generate the relevant docs content automatically. </p> </li> <li> <p>To identify the structure in the extracted annotation text, <code>mkdocstrings[python]</code>  requires a clear annotation format. In <code>torchmeter</code>, we follow Google's Python docstring style guide  to write annotation documents.</p> </li> <li> <p>Put simply, you just need to write <code>google</code>-style docstrings for your modifications, the automated documentation build process will take care of the rest! You can refer to the existing work as a reference, see <code>API Reference</code> section  for examples.</p> </li> </ul> Recommended Tools for this Step <p>For <code>VSCode</code> users, we recommend installing the <code>autDocstring</code> extension:</p> <ul> <li>Plugin page .  </li> <li>Configure format: Open <code>VSCode</code> settings ( Ctrl+, / Cmd+, ) \u2192 search for <code>autodocstring.docstringFormat</code> \u2192 select <code>google</code>.  </li> </ul> <ol> <li> <p>For new/modified functions or class methods</p> <ul> <li> <p>Add function-level documentation following Google\u2019s function-level guidelines .</p> </li> <li> <p>Example:  </p> Python<pre><code>def example_function(arg1: int, arg2: str) -&gt; bool:\n    \"\"\"Short description of the function's purpose.\n\n    Args:\n        arg1 (int): Description of argument 1.\n        arg2 (str): Description of argument 2.\n\n    Raises:\n        ValueError: If `arg1` is not an integer, or `arg2` is not a string.\n\n    Returns:\n        bool: Description of return value.\n    \"\"\"\n\n    if not isinstance(arg1, int):\n        raise ValueError(\"arg1 must be an integer\")\n\n    if not isinstance(arg2, str):\n        raise ValueError(\"arg2 must be a string\")\n\n    # Your implementation here\n\n    return True if arg1 &gt; 0 and args.startswith('a') else False\n</code></pre> </li> </ul> </li> <li> <p>For new/modified classes:  </p> <ul> <li> <p>Add class-level documentation following the Google class guidelines.</p> </li> <li> <p>If you add a brand new class, you need to add both class-level documentation for the class and function-level documentation for each method.</p> </li> <li> <p>Example:</p> Python<pre><code>class ExampleClass:\n    \"\"\"Class description and purpose.\n\n    Attributes:\n        attr1 (int): Description of class attribute.\n\n    Methods:\n        method1: Method description and purpose.\n    \"\"\"\n\n    attr1 : int = 0\n\n    def method1(self, arg1: int) -&gt; bool:\n        \"\"\"Method description and purpose.\n\n        Args:\n            arg1 (int): Description of argument 1.\n\n        Raises:\n            ValueError: If `arg1` is not an integer.\n\n        Returns:\n            bool: Description of return value.\n        \"\"\"\n        if not isinstance(arg1, int):\n            raise ValueError(\"arg1 must be an integer\")\n\n        # Your implementation here\n\n        return True if arg1 &gt; 0 else False\n\n    # other methods here\n</code></pre> </li> </ul> </li> </ol> <p>Acknowledgement</p> <p>Document writing can be rather dull and requires clear expression skills.    We sincerely appreciate every contributor who is willing to add to the documentation!    Thank you \ud83d\ude4f</p>"},{"location":"contribute/prs/#Cd-Commit-Changes-to-Local-Repository","title":"C.d Commit Changes to Local Repository","text":"Recommended Tools for this Step <p>For <code>VSCode</code> users, we recommend installing the <code>Git Graph</code> extension:</p> <ul> <li>Plugin page .  </li> <li>Highlight: Visualize commit history and repository state through an interactive interface.</li> </ul> <p>Once you feel that your changes have made phased progress, you can incorporate them into version management by committing the changes to the local repository. Please follow these steps:</p> <ol> <li> <p>Make sure you are on your development branch</p> <ol> <li> <p>Check your current branch</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit branch --show-current\n</code></pre> </li> <li> <p>You should ensure that the branch output by the above command is consistent with the branch set in step C.a.2. Otherwise, use the following command to switch branches:</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit checkout &lt;branch_name&gt; # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Replace <code>&lt;branch_name&gt;</code> with your development branch name set in step C.a.2.</li> </ol> </li> </ol> </li> <li> <p>Review Your Changes</p> <ol> <li> <p>List modified files</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit status\n</code></pre> <p>You may see something like this</p> <pre><code>On branch &lt;your-development-branch-name&gt;\nChanged but not updated:\n    (use \"git add &lt;file&gt;...\" to update what will be committed)\n    (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   xxx.py\n\nUntracked files:\n    (use \"git add &lt;file&gt;...\" to include in what will be committed)\n\n    zzz.py\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n</code></pre> </li> <li> <p>Please ensure that all your changes appear in the output of the above command. If there are unexpected changes, you can execute the following command to view it:</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit diff path/to/unexpected_changed_file\n</code></pre> </li> <li> <p>If there are any changes you don't want, you can use the following command to undo them. Otherwise, you can skip this step.</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\n# \u26a0\ufe0f be careful, this command will discard all changes in the target file and it is irreversible\ngit restore path/to/modified_files\n</code></pre> </li> </ol> </li> <li> <p>When all changes have been confirmed, you can optionally commit them to the staging area<sup>1</sup>.</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\n# You can execute \"git add\" multiple times to ensure that all the changes you wish to commit have been added to the staging area\ngit add path/to/modified_files/you/want/to/commit\n</code></pre> </li> <li> <p>When all the changes you desire have been staged, you can use the following command to commit the staged changes to the local repository:</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\n# Double-check staged files\ngit status\n\ngit commit\n</code></pre> </li> <li> <p>The above command will open a text editor in the terminal (it will be opened with <code>vim</code> or <code>nano</code>), and you need to fill in the commit message in it.</p> <ul> <li>We recommend describing what and why of the changes in the simplest possible way. If this commit is related to an <code>issue</code> or <code>PR</code>, please ensure that you have associated this commit with them by using <code>closes #&lt;issue-number&gt;</code>, <code>fixes #&lt;issue-number&gt;</code> or <code>refs: &lt;PR-number&gt;</code>etc. </li> <li>Refer to our commit message conventions  for specific requirements.</li> </ul> </li> <li> <p>After editing, save and close the editor. Then the changes in the staging area will be committed to the local repository. You can use the following command to view your commit history. If you are a <code>VSCode</code> user, you can use the <code>Git Graph</code> extension  to view the commit history more conveniently and intuitively.</p> Bash<pre><code>git log --pretty=format:'%h %ad | %an | %s%d' --graph --date=short\n</code></pre> </li> </ol> <p>While multiple commits are acceptable before pushing to the remote repository (i.e. your fork repository), it is highly recommended to keep your commit history concise (e.g., 3\u20136 commits). </p> <p>That is because large batches of changes may complicate review processes. For extensive refactors, consider splitting work into separate PRs addressing individual features/fixes.</p>"},{"location":"contribute/prs/#Ce-Push-Changes-to-Your-Fork-Repository","title":"C.e Push Changes to Your Fork Repository","text":"Enable GitHub Actions in your fork repository <ol> <li> <p>What is GitHub Actions in forks? </p> <ul> <li><code>GitHub Actions</code>  is GitHub's CI/CD service that automates workflows through <code>YAML</code> configurations.   </li> <li><code>torchmeter</code> uses predefined workflows for compatibility testing, automated releases, PR management, and README updates, etc. See all our workflow files  </li> </ul> </li> <li> <p>Why enable it? </p> <ul> <li>Your fork inherits the original repo's workflows but defaults to disabled for security<sup>2</sup>.    </li> <li>Enabling it allows you to simulate the CI process triggered when a PR is submitted to the official repo, which helps you find problems as early as possible.   </li> <li>In <code>torchmeter</code>, compatibility testing is mandatory for PR merging. Therefore, it is necessary to enable it for simulating the CI process.</li> </ul> </li> <li> <p>How to enable: Go to your fork's <code>Actions</code> tab \u2192 click the <code>I understand my workflows, go ahead and enable them</code> button.</p> </li> </ol> <ol> <li> <p>When you believe you've completed all your changes or need to save your progress temporarily, you can push the current commit history of your local repository to the remote repository (i.e., your <code>fork</code> repository). Execute the following commands.</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit push -u origin &lt;your-branch-name&gt;:&lt;remote-branch-name&gt; # (1) (2)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f You need to replace <code>&lt;your-branch-name&gt;</code> with the branch name created in step C.a.2. You also need to replace <code>&lt;remote-branch-name&gt;</code> with one that will receive the changes in remote repository. Generally, we keep it the same as <code>&lt;your-branch-name&gt;</code>.</li> <li>\ud83d\ude4b\u200d\u2642\ufe0f The <code>-u</code> parameter indicates that the <code>&lt;your-branch-name&gt;</code> branch in local repository will track the <code>&lt;remote-branch-name&gt;</code> branch in remote repository. Thus, when you make new commits on <code>&lt;your-branch-name&gt;</code> in local repository, you can easily push them to the <code>&lt;remote-branch-name&gt;</code> branch in remote repository with a simple <code>git push</code> command, no need to re-type the remote repository's target branch name. </li> </ol> </li> <li> <p>If you have enabled the <code>Github Actions</code> for your <code>fork</code> repository, you can submit a PR to the <code>master</code> branch of the remote repository (i.e., your <code>fork</code> repository) to automatically trigger the compatibility test we've prepared for you:</p> <ol> <li>Open the page of your fork repository. Shortly after pushing your changes, you'll find a prominent <code>Compare &amp; pull request</code> button. (1)(Illustration) </li> <li>Click this button. In the pop-up page, select the <code>base</code> branch as the <code>master</code> branch of your fork repository, and select the <code>head</code> branch as the <code>&lt;remote-branch-name&gt;</code> branch you just pushed. Please double-check that the <code>base</code> branch is the <code>master</code> branch of your <code>fork</code> repository, not the <code>master</code> branch of the official <code>torchmeter</code> repository.</li> <li>Fill in the PR title. See PR Title Convention .</li> <li>Fill in the PR description. Since you are just testing, the description can be brief, no need to fill it in according to the predefined template. </li> <li>Click the <code>Create Pull Request</code> button below, and you have created a PR targeting the <code>master</code> branch in your fork repository.</li> <li>Click on the <code>Actions</code> tab. You will see a task named <code>\u2705 Compatibility Test \u274c</code> is running. It is the compatibility test workflow of the <code>torchmeter</code> project.</li> <li>Wait for the task to finish running. If the task fails, check the error, modify the code locally, and then re-commit to the remote repository. This will update the commit history of the PR and trigger the minimal test <code>\u2705 Minimal Test \u274c</code>.</li> <li>If the minimum test is passed, click on the <code>Actions</code> tab, select <code>\u2705 Compatibility Test \u274c</code>, click <code>Run workflow</code>, choose your branch and run. This will re-trigger the compatibility test, do it until it is passed.</li> </ol> </li> </ol>"},{"location":"contribute/prs/#D-Contribute-to-Official-Repository","title":"D. Contribute to Official Repository","text":"Section Overview <p>Now, your code has been pushed to <code>GitHub</code> but is not yet part of the official <code>torchmeter</code> repository. In this section, we'll guide you through the final steps to complete your contribution journey:</p> <ul> <li>Submit your PR to the official <code>torchmeter</code> repository  </li> <li>Collaborate positively with reviewers  </li> <li>Celebrate your successful contribution</li> </ul> <p>By following these steps, your code will officially merge into <code>torchmeter</code>'s <code>master</code> branch and become part of the next release to benefit all users. We're thrilled to guide you through this final phase!</p>"},{"location":"contribute/prs/#Da-Avoiding-Protential-Merge-Conflicts","title":"D.a Avoiding Protential Merge Conflicts","text":"What is this for? What is a merge conflict? <p>When two branches make conflicting changes to the same part of a file, <code>Git</code> cannot automatically decide which should be kept. This creates a blocking state where your PR cannot be merged until resolved. </p> When a conflict happens? As all contributors work on the <code>master</code> base branch, new commits may be added while you develop. Then when you try to merge your PR, your changes may clash with these updates. Learn more <p>Understanding merge conflicts   |  Step-by-step conflict resolution guide </p> <ol> <li> <p>Check for upstream changes: </p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit fetch upstream\n\ngit rev-list --count &lt;your-branch-name&gt;..upstream/master # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f You need to replace <code>&lt;your-branch-name&gt;</code> with the branch name created in step C.a.2.</li> </ol> </li> <li> <p>If output is <code>0</code>, it indicates that there are no leading commits in <code>upstream/master</code>. In this case, proceed to step D.b.</p> </li> <li> <p>If output <code>&gt; 0</code>, it indicates that there are ahead commits in <code>upstream/master</code>. In this case, you need to resolve the merge conflicts through <code>rebase</code> :</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit checkout &lt;your-branch-name&gt;\ngit branch &lt;your-branch-name&gt;-bak &lt;your-branch-name&gt; # (1)\n\ngit rebase upstream/master # (2)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Back up the new branch, you need to replace <code>&lt;your-branch-name&gt;</code> with the branch name created in step C.a.2.</li> <li>\ud83d\ude4b\u200d\u2642\ufe0f Rebase the new branch onto the latest commit of the target branch in <code>torchmeter</code> official repo.</li> </ol> </li> <li> <p>The above command will attempt to rebase your branch <code>&lt;your-branch-name&gt;</code> onto the latest commit of the <code>master</code> branch of official <code>torchmeter</code> repo (i.e. the <code>upstream/master</code> in your local repo). Two scenarios may occur:</p> <ul> <li> <p>Your changes do not conflict with the latest commit of the target branch. The rebase was successful, and you will see the following output. In this case, you're ready to proceed to step <code>9</code> below to delete the backup branch.</p> <pre><code>Successfully rebased and updated refs/heads/&lt;your-branch-name&gt;.\n</code></pre> </li> <li> <p>There is a conflict between your changes and the latest commit of the target branch, and the rebase has failed. You will see output similar to the following, which indicates the commit where the conflict occurred and the file(s) involved.</p> <pre><code>Auto-merging test.py\nCONFLICT (content): Merge conflict in test.py\nerror: could not apply 5d3f9e2... Add new feature logic\n\nhint: Resolve all conflicts manually, mark them as resolved with\nhint: \"git add/rm &lt;conflicted_files&gt;\", then run \"git rebase --continue\".\nhint: You can instead skip this commit with \"git rebase --skip\".\nhint: To abort and get back to the state before \"git rebase\", run \"git rebase --abort\".\n\nCould not apply 5d3f9e2... Add new feature logic\n</code></pre> <p>If the rebase fails, you will find conflict markers such as <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code>, <code>=======</code>, <code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;</code> in the conflicted files. The conflict content of two branches is divided by <code>=======</code>, as shown below.</p> <pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nprint(\"Original content from master branch\")\n=======\nprint(\"New feature implementation\")\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; 5d3f9e2... Add new feature logic\n</code></pre> </li> </ul> </li> <li> <p>If there are conflicts, you need to resolve them manually. Discard the old changes and remove all conflict markers<sup>3</sup>. It should be noted that during the conflict resolution process, you are actually in an interrupted state of the previous <code>rebase</code> command. Therefore, you can use the following commands to revert the changes or completely cancel the whole <code>rebase</code> operation:</p> <ul> <li>Discard the existing changes\uff1a<code>git reset --hard &lt;your-branch-name&gt;</code></li> <li>Cancel rebase: <code>git rebase --abort</code></li> </ul> </li> <li> <p>Once you have resolved all the conflicts, you need to execute the following commands to continue the <code>rebase</code> operation:</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit status\ngit add path/to/conflict/file\ngit rebase --continue\n</code></pre> </li> <li> <p>Repeat step 6 until the rebase is successful. After that, commit the changes to the local repository with a formatted commit message. Refer to our commit message conventions   for specific requirements. </p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit commit # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f This will open an editor to edit the commit message. Please follow our commit message conventions  to format your writting. Thank you !</li> </ol> </li> <li> <p>Execute the following commands to synchronize the changes to your fork repository<sup>4</sup>.</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit checkout &lt;your-branch-name&gt; # (1)\ngit push \n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f You need to replace <code>&lt;your-branch-name&gt;</code> with the branch name created in step C.a.2.</li> </ol> </li> <li> <p>Finally, delete the backup branch.</p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit branch -D &lt;your-branch-name&gt;-bak # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f you need to replace <code>&lt;your-branch-name&gt;</code> with the branch name created in step C.a.2.</li> </ol> </li> </ol>"},{"location":"contribute/prs/#Db-Create-a-Pull-Request-to-torchmeter","title":"D.b Create a Pull Request to torchmeter","text":"Prerequisites of Creating PRs <p>Before creating a PR, kindly ensure the following prerequisites are met:  </p> <ol> <li> <p>Test coverage: If your changes introduce new functionality or logic, please add corresponding tests (see step C.b.3).  </p> </li> <li> <p>Documentation: We highly appreciate contributors who add/update docstrings for their changes (see step C.c).  </p> </li> <li> <p>Branch hygiene:  </p> <ul> <li>Your local changes are not on the master branch (<code>upstream/master</code> or <code>origin/master</code>). </li> <li>The name of the branch to host your change follows our branch naming conventions . If not, rename it via: </li> </ul> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit checkout &lt;your-branch-name&gt;  # (1)\ngit branch -m &lt;new-branch-name&gt;\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f You need to replace <code>&lt;your-branch-name&gt;</code> with the branch name created in step C.a.2.</li> </ol> </li> <li> <p>Sync status:  </p> <ul> <li>Your branch has been rebased onto the latest <code>upstream/master</code> (see step D.a)  </li> <li>All changes have been pushed to your fork repository. If workflows are enabled, ensure the <code>\u2705 Compatibility Test \u274c</code> completes successfully (see step C.e.2).</li> </ul> </li> </ol> <p>Once the requirements above are met, create your PR as follows:</p> <ol> <li> <p>Open your fork repository \u2192 Click <code>Pull requests</code> tab \u2192 <code>New pull request</code></p> </li> <li> <p>Configure the PR source/destination:  </p> <ul> <li>base repository: <code>TorchMeter/torchmeter</code> </li> <li>base: <code>master</code> </li> <li>head repository: <code>your-github-id/your-fork-repo</code> </li> <li>compare: <code>&lt;your-branch-name&gt;</code> </li> </ul> </li> <li> <p>Pay attention to the status prompt. If it shows <code>Can't automatically merge</code> (example), there are merge conflicts. In this case, please exit the PR creation page, resolve them following the steps in D.a and retry.</p> </li> <li> <p>Review your changes down the page, so as to ensure complete/correct file modifications.</p> </li> <li> <p>Click the green <code>Create pull request</code> button, and complete PR details:</p> <ul> <li>Title: Follow our PR title conventions .</li> <li>Description: You can see that your \"Add a description\" field is not empty. That's because we've prepared a content template for you to guide your filling. You just need to use <code>markdown</code> syntax  to fill it out as completely as possible according to the requirements in the comments. That's all what you need to do. Finally, you can click <code>Preview</code> above the input box to preview the rendered content you've filled in.</li> </ul> </li> <li> <p>If everything looks good, please check the option <code>Allow edits and access to secrets by maintainers</code>. This permission is required to auto-update the <code>README.md</code> coverage badge before your PR is merged<sup>5</sup>.</p> </li> <li> <p>Submit your PR</p> <ul> <li>For complete implementations (e.g., bug fixes/new features), click <code>Create pull request</code> for immediate review.  </li> <li>For in-progress work or consultation requests, choose <code>Create draft pull request</code> from the dropdown. Draft PRs  won't trigger formal review processes until you mark it Ready for review.  </li> </ul> </li> </ol>"},{"location":"contribute/prs/#Dc-Update-your-PR","title":"D.c Update your PR","text":"<p>Once your PR is created (whether draft or final), <code>torchmeter</code> uses automated workflows to ensure quality and facilitate efficient review/merge processes. If these checks fail, please actively collaborate to update the PR accordingly.</p> PR Title Linting and Formatting <p>Once a PR is created, a workflow  named <code>\ud83e\udd16 PR Auto-Labeler \u26f3</code> will be automatically triggered. It will determine whether the PR title complies with our PR title conventions .</p> <ul> <li> <p>If non-compliant:  </p> <ol> <li>A red <code>PR-title-needs-formatting</code> label will be added  </li> <li>You'll need to modify the PR title using the <code>Edit</code> button next to it  </li> </ol> </li> <li> <p>For compliant titles:  </p> <ol> <li>Category labels are automatically assigned based on title prefixes  </li> <li>These labels help organize PRs and inform our changelog generation when releasing a new version. </li> </ol> </li> </ul> Code Linting, Formatting and Compatibility Testing <p>Once a PR is created, a workflow  named <code>\u2705 Compatibility Test \u274c</code> will be automatically triggered. It will check whether the code in the PR meets the style and format requirements defined in <code>ruff.toml</code>. </p> <p>If both pass, compatibility tests will be conducted across platforms (<code>windows</code>, <code>macOs</code>, <code>linux</code>) and across versions (<code>python 3.8</code> to <code>python 3.13</code>). If any step fails, <code>torchmeter</code> will provide an error report on the workflow run page. Please download it, review it, and try to fix the problem. </p> <p>You can try to solve the problem by creating a new commit for the fix in your local repository and pushing it to the remote repository. The commit history of the PR will be automatically synchronized with the history of the <code>head</code> branch. </p> <p>It should be noted that every time PR is updated like this, an automated test workflow  named <code>\u2705 Minimal Test \u274c</code> will be triggered, which will execute the test in a randomly selected system and <code>python 3.8</code>. Without consuming a lot of time and resources like compatibility testing, this is beneficial for you to find new problems that may be introduced by new submission as soon as possible.</p>"},{"location":"contribute/prs/#Dd-Waiting-for-Review--Active-Collaboration","title":"D.d Waiting for Review &amp; Active Collaboration","text":"PR Closure <p>Kindly note that your pull request (PR) may be manually closed under these circumstances:  </p> <ol> <li>Incorrect target branch: Ensure the <code>base</code> branch is set to <code>master</code> </li> <li>Duplicate contributions: Existing PRs already address the same problem  </li> <li>CI failures with prolonged inactivity: PRs failing CI checks without updates for <code>30+</code> days  </li> <li>Outdated scope: When the code area involved in the PR has been refactored or cancelled</li> </ol> <ol> <li> <p>After passing compatibility tests, your PR enters formal review . Typical first review occurs within 5-7 business days (may vary with maintainer availability).</p> </li> <li> <p>During the review process, reviewers may leave comments. If any questions arise, please respond patiently and courteously to clarify your implementation rationale:</p> <ul> <li>Kindly respond to review comments as soon as possible  </li> <li>Use <code>Resolve conversation</code> button  when fixes are applied.  </li> <li>For unclear requests, ask clarifying questions like: <code>\"Could you please elaborate on [...]?\"</code> </li> </ul> </li> <li> <p>Provided everything checks out, maintainers will: </p> <ul> <li>Manually trigger compatibility tests to verify code standards, correctness, robustness, and cross-environment compatibility again.</li> <li>Manually execute the <code>\ud83e\udd16 Update README Badge \ud83d\udd30</code> workflow (as mentioned in step D.b.6) to update the coverage badge in <code>README.md</code></li> </ul> </li> <li> <p>If everything goes well\uff0cyour PR will be merged into the <code>master</code> branch in <code>Squash</code> or <code>Merge</code> way. Your contribution will be officially released and acknowledged in the next version announcement.</p> </li> </ol>"},{"location":"contribute/prs/#De-Celebrate-Your-Successful-Contribution-","title":"D.e Celebrate Your Successful Contribution \ud83c\udf89","text":"<ol> <li> <p>Once your PR is merged, you'll receive a notification email from <code>GitHub</code> with a message similar to: <code>Merged #&lt;PR-number&gt; into master.</code></p> </li> <li> <p>Congratulations\ud83c\udf8a\ud83c\udf8a\ud83c\udf8a Your contribution is now part of <code>torchmeter</code>. We'll announce your changes in our next official release and express our gratitude again on the release page .</p> </li> <li> <p>This marks the completion of your contribution journey! Take a well-deserved break, share the achievement with your peers, or celebrate in any way that brings you joy. We sincerely appreciate your time and effort!  </p> </li> </ol> Checkout Your Contribution Locally <p>The merged changes will be visible on the <code>master</code> branch. To update locally:  </p> Bash<pre><code># pwd: path/to/your/local/copy/of/your/fork/\n\ngit checkout master\ngit pull\n</code></pre> <p>This ensures your local environment reflects the latest project state including your contribution.</p> <ol> <li> <p>The staging area is a temporary storage area that holds the changes you'll add to your next commit. It's like the shopping cart you use before paying at the supermarket, where the items in the cart are your changes here. It should be noted that when you need to stage an empty folder, please create an empty file named <code>.gitkeep</code> in it.\u00a0\u21a9</p> </li> <li> <p>You can enable <code>Github Actions</code> for your fork repo without worry as we've added repository validation for sensitive operations (like package publishing), so you can rest assured to enable it.\u00a0\u21a9</p> </li> <li> <p>Currently, IDEs have mature support for resolving merge conflicts. For example, you can refer to Resolve conflicts in VsCode  and Resolve conflicts in PyCharm .\u00a0\u21a9</p> </li> <li> <p>If you have created a PR to the <code>master</code> branch of your fork repo in  step C.e, you will see that the commit history of PR will be updated synchronously and the minimum test workflow will be automatically triggered to verify the correctness and robustness of your changes.\u00a0\u21a9</p> </li> <li> <p>The workflow named <code>\ud83c\udf1f Update README Badge \ud83d\udd30</code> is responsible for updating the coverage badge in <code>README.md</code> and committing the changes to PR history. If you're worried about the security issues brought by enabling this option, you can review the content of this workflow . <code>torchmeter</code> ensures that only modifications related to the coverage badge in <code>README.md</code> will be made. No other code or sensitive information will be involved. Moreover, all changes will be publicly recorded, and you can review them at any time. Thanks for your trust ! \u21a9</p> </li> </ol>"},{"location":"contribute/thanks_contributors/","title":"\ud83e\udd1d Acknowledgement","text":"<p>We extend our heartfelt gratitude to every contributor who has helped shape <code>torchmeter</code> into a better tool!</p> <p>Your efforts, whether through code contributions, bug reports, or thoughtful discussions, are the lifeblood of this open-source project.</p> <p>Thank you so much for your time and effort !</p>"},{"location":"contribute/welcome_contributors/","title":"\u2728 Welcome to TorchMeter Contributors' Hub!","text":"<p>Thank you for wanting to make <code>torchmeter</code> even better!</p> <p>Whether you're:</p> <ul> <li> Asking questions </li> <li> Reporting bugs </li> <li> Contributing code </li> </ul> <p>Your input is pretty valuable to our community! </p> <p>Before jumping in, let's ensure smooth collaboration by reviewing these guidelines first.  They'll help us keep things organized and make your contribution process as efficient as possible! </p>"},{"location":"others/architecture/","title":"Project Architecture","text":"<p>This document outlines the architecture of <code>torchmeter</code>'s codebase, detailing each module's purpose and functionality. </p> <p>Hoping this helps you quickly understand the structure of <code>torchmeter</code> and boosts your contribution efficiency.</p>"},{"location":"others/architecture/#Structure-Overview","title":"Structure Overview","text":"<pre><code>torchmeter\n\u251c\u2500\u2500 __init__.py         # Package initialization &amp; metadata  \n\u251c\u2500\u2500 __cli__.py          # CLI tool implementation (not implemented) \n\u251c\u2500\u2500 py.typed            # PEP-561 type hinting marker\n\u251c\u2500\u2500 _stat_numeric.py    # Numeric data structures for metric tracking  \n\u251c\u2500\u2500 unit.py             # Unit systems and automatic unit conversion  \n\u251c\u2500\u2500 utils.py            # Utility functions/classes for common tasks  \n\u251c\u2500\u2500 core.py             # Central analytics engine for PyTorch model analysis  \n\u251c\u2500\u2500 config.py           # Configuration management with YAML and singleton patterns  \n\u251c\u2500\u2500 engine.py           # Hierarchical operation trees for model structure analysis \n\u251c\u2500\u2500 display.py          # Visualization components for model architecture and metrics  \n\u2514\u2500\u2500 statistic.py        # Modular meters for model parameter/computation/memory/inference-time/thoughput analysis   \n</code></pre>"},{"location":"others/architecture/#Detailed-Introduction","title":"Detailed Introduction","text":""},{"location":"others/architecture/#1-__init__py","title":"1. <code>__init__.py</code>","text":"Purpose <p>Implements package initialization, defining metadata, versioning, and public API declarations.  </p> Global Variables <ul> <li><code>__version__</code>: Package version identifier.  </li> <li><code>__all__</code>: Explicitly declares public API exports.  </li> </ul> Functions <p>None </p> Classes <p>None </p>"},{"location":"others/architecture/#2-__cli__py","title":"2. <code>__cli__.py</code>","text":"<p>Not implemented yet  </p> Purpose <p>Implements command-line interface (CLI) tool logic.  </p> Global Variables <p>None </p> Functions <ul> <li><code>main</code>: Main entry point for CLI tool.</li> </ul> Classes <p>None </p>"},{"location":"others/architecture/#3-pytyped","title":"3. <code>py.typed</code>","text":"Purpose <p>Serves as a <code>PEP 561</code> type hinting marker for static type checking.  </p>"},{"location":"others/architecture/#4-_stat_numericpy","title":"4. <code>_stat_numeric.py</code>","text":"Purpose <p>Implements numeric data structures for metric tracking and statistical aggregation </p> Global Variables <p>None</p> Functions <p>None</p> Classes <ul> <li><code>NumericData</code> (<code>ABC</code>) An abstract class for numeric data operations  </li> <li><code>UpperLinkData</code>: Implement hierarchical metric tracking with parent-child relationships  </li> <li><code>MetricsData</code>: Implement batch metric collection and statistical analysis  </li> </ul>"},{"location":"others/architecture/#5-unitpy","title":"5. <code>unit.py</code>","text":"Purpose <p>Implements unit systems and automatic unit conversion for numeric values  </p> Global Variables <ul> <li><code>__all__</code>: Public API exports (<code>CountUnit</code>, <code>BinaryUnit</code>, <code>TimeUnit</code>, <code>SpeedUnit</code>, <code>auto_unit</code>)  </li> </ul> Functions <ul> <li><code>auto_unit</code>: Automatically selects appropriate unit based on value magnitude and formats as string  </li> </ul> Classes <ul> <li><code>CountUnit</code> (<code>Enum</code>): Decimal-based unit system (K/M/G/T for 1e3/1e6/1e9/1e12)  </li> <li><code>BinaryUnit</code> (<code>IntFlag</code>): Binary-based unit system (KiB/MiB/GiB/TiB for 2^10/20/30/40)  </li> <li><code>TimeUnit</code> (<code>Enum</code>): Time unit system (h/min/s/ms/us/ns)  </li> <li><code>SpeedUnit</code> (<code>Enum</code>): Operational speed unit system (Input Per Second, IPS/KIPS/MIPS/GIPS/TIPS)  </li> </ul>"},{"location":"others/architecture/#6-utilspy","title":"6. <code>utils.py</code>","text":"Purpose <p>Provides utility functions or classes for common tasks such as file io, string formatting etc.</p> Global Variables <ul> <li><code>__all__</code>: Public API exports (<code>dfs_task</code>, <code>data_repr</code>, <code>Timer</code>)  </li> </ul> Functions <ul> <li><code>resolve_savepath</code>: Decouples save path into dir and filename, and allows customizable filenames, validates file extensions. </li> <li><code>hasargs</code>: Validates required arguments exist in a function signature  </li> <li><code>dfs_task</code>: Executes depth-first search tasks on hierarchical data structures  </li> <li><code>indent_str</code>: Formats text with customizable indentation and guidelines  </li> <li><code>data_repr</code>: Generates rich-formatted string representations for data structures  </li> <li><code>match_polars_type</code>: Infers Polars data types from Python/Numpy objects  </li> </ul> Classes <ul> <li><code>Timer</code> (<code>rich.status.Status</code>): Context manager for tracking and displaying execution time  </li> </ul>"},{"location":"others/architecture/#7-corepy","title":"7. <code>core.py</code>","text":"Purpose <p>Provides a central analytics engine for <code>PyTorch</code> model performance analysis and visualization.  </p> Global Variables <ul> <li><code>__all__</code>: Public API exports (<code>Meter</code>)  </li> <li><code>__cfg__</code>: Global configuration  </li> </ul> Functions <p>None </p> Classes <ul> <li><code>Meter</code>: Provides end-to-end measurement capabilities for neural networks, including  parameter statistics, computational cost analysis, memory usage tracking, inference time and  throughput analysis. It serves as a wrapper around <code>PyTorch</code> modules while maintaining full compatibility  with native model operations.</li> </ul>"},{"location":"others/architecture/#8-configpy","title":"8. <code>config.py</code>","text":"Purpose <p>Provides centralized configuration management for visualization parameters and layout presets through <code>YAML</code> parsing, singleton pattern enforcement, and reactive change tracking. </p> Global Variables <ul> <li><code>__all__</code>: Public API exports (<code>get_config</code>, <code>Config</code>)</li> <li><code>DEFAULT_CFG</code>: Stores default YAML configurations for rendering intervals, tree/table styling, and layout parameters.  </li> </ul> Functions <ul> <li><code>list_to_callbacklist</code>: Wraps lists with mutation callbacks for state tracking.  </li> <li><code>dict_to_namespace</code>: Converts dictionaries to observable <code>FlagNameSpace</code> objects recursively.  </li> <li><code>namespace_to_dict</code>: Serializes <code>FlagNameSpace</code> back to dictionaries for persistence.  </li> <li><code>get_config</code>: Ensures thread-safe singleton access to configuration instances with environment/file override support.  </li> </ul> Classes <ul> <li><code>ConfigMeta</code>: Enforces singleton pattern via metaclass for global configuration consistency.  </li> <li><code>Config</code>: Central configuration manager handling YAML loading, validation, and dynamic updates.  </li> <li><code>FlagNameSpace</code>: Extends <code>SimpleNamespace</code> with nested change tracking.  </li> <li><code>CallbackList/CallbackSet</code>: Collection proxies that propagate modification events through callback chains</li> </ul>"},{"location":"others/architecture/#9-enginepy","title":"9. <code>engine.py</code>","text":"Purpose <p>Constructs hierarchical operation trees for <code>PyTorch</code> models to track parameters, computational costs, memory usage, and inference time metrics.  </p> Global Variables <ul> <li><code>__all__</code>: Public API exports (<code>OperationNode</code>, <code>OperationTree</code>).  </li> </ul> Functions <p>None </p> Classes <ul> <li><code>OperationNode</code>: Represents individual model components with hierarchical relationships, stores module meta info, statistical     metrics (parameters, computation, memory, throughput), and tracks module repetitions.  </li> <li><code>OperationTree</code>: Constructs the structural and display trees simultaneously through depth-first traversal, and identifying repeated modules to implement smart folding of repeated blocks.</li> </ul>"},{"location":"others/architecture/#10-displaypy","title":"10. <code>display.py</code>","text":"Purpose <p>Implements visualization components for rendering <code>PyTorch</code> model architecture as rich text tree and performance metrics as programmable tabular reports, supporting configuration-driven styling and data export capabilities.  </p> Global Variables <ul> <li><code>__all__</code>: Public API exports (<code>render_perline</code>, <code>TreeRenderer</code>, <code>TabularRenderer</code>).  </li> <li><code>__cfg__</code>: Global configuration.</li> </ul> Functions <ul> <li><code>apply_setting</code>: Dynamically applies configuration in tree or tabular report rendering process.</li> <li><code>render_perline</code>: Implements progressive rendering with configurable delay for terminal animation effects.  </li> </ul> Classes <ul> <li><code>TreeRenderer</code>: Generates collapsible tree visualizations with loop algebra notation for repeated modules through depth-first traversal and configuration inheritance.  </li> <li><code>TabularRenderer</code>: Produces customizable metric tables with column filtering/renaming, dynamic column management(rename, insert, delete and interact), and CSV/XLSX export functionality.  </li> </ul>"},{"location":"others/architecture/#11-statisticpy","title":"11. <code>statistic.py</code>","text":"Purpose <p>Implements metering tools for comprehensive PyTorch model analysis across parameters, computation, memory, and inference performance through modular measurement components.  </p> Global Variables <ul> <li><code>__all__</code>: Public API exports (<code>ParamsMeter</code>, <code>CalMeter</code>, <code>MemMeter</code>, <code>IttpMeter</code>).  </li> </ul> Functions <p>None </p> Classes <ul> <li><code>Statistics</code>: Abstract base class defining common interfaces and properties for all specialized metric calculators.  </li> <li><code>ParamsMeter</code>: Quantifies total/learnable parameters across model layers with hierarchical aggregation capabilities.  </li> <li><code>CalMeter</code>: Calculates floating-point operations (<code>FLOPs</code>/<code>MACS</code>) using layer-specific forward hooks and kernel analysis.  </li> <li><code>MemMeter</code>: Measures parameter/buffer/memory overhead in binary units via deep object size inspection.  </li> <li><code>IttpMeter</code>: Benchmarks inference latency/throughput using device-optimized timing (<code>CPU</code> wall-clock/<code>CUDA</code> events)</li> </ul>"},{"location":"others/management/","title":"Management","text":"<p>This page outlines the <code>torchmeter</code> project's governance framework to transparently communicate our workflow for managing branches, handling issues, and processing contributions. It ensures contributors clearly understand how their efforts are reviewed and integrated into the project's development lifecycle.</p>"},{"location":"others/management/#Branching-Strategy","title":"Branching Strategy","text":"Bugfix\ud83d\udd30 Version(v0.1.x)PR branch(feat/bugfix)\ud83d\udd30 MasterC5C0C6C4C2C1C3C7C13rebaseC9C8C14V0.1.0TagC10C11C12cherry-pickV0.1.1Tag\ud83d\udd30 \uff1aProtected branch:\u00a0 Create a new commitCreate a new branch (PR):C0:\u00a0 CommitMerge branch (Squash):Tag:\u00a0 Tag:\u00a0 Git operationGit operation flow:Text is not SVG - cannot display <p>To streamline collaboration and enable rapid iteration, <code>torchmeter</code> employs a simplified branching strategy inspired by <code>Git Flow</code> and practices from mature OSS projects. Our workflow(visualized above) balances stability with agility through two core branch types, i.e. the <code>master</code> branch and the version branches(<code>vA.B.x</code>).</p>"},{"location":"others/management/#Branch-Architecture","title":"Branch Architecture","text":"Overview Branch Name Name Purpose Maintainer Contributor Permissions <code>master</code> Primary Development Branch Receives latest stable code, accepts new features, optimizations, and general bug fixes All (with review) Allowed to submit PRs <code>vA.B.x</code> Version Maintenance Branch Only accepts bug fixes for this version, no new features Core Team Forbidden to submit PRs directly"},{"location":"others/management/#Master-Branch","title":"Master Branch","text":"<ul> <li>Name: <code>master</code></li> <li>Purpose: Always represents the latest stable state, incorporating validated features and fixes.</li> <li>Lifecycle: Permanent</li> <li>Branch Protection Rules:<ol> <li> Branch deletion forbidden</li> <li> Direct commits prohibited. All changes must be proposed via Pull Requests (PRs) and approved through code review.</li> <li> PR Requirements before Merging:<ul> <li>All comments must be resolved.</li> <li>Pass PR title checks and code compatibility tests.</li> <li>At least one approval from reviewers required.</li> </ul> </li> </ol> </li> </ul>"},{"location":"others/management/#Version-Branches","title":"Version Branches","text":"<ul> <li>Name: <code>v</code> + semantic version  (e.g., <code>v1.2.x</code><sup>1</sup>). </li> <li>Purpose: Exclusive bugfix channel for specific releases</li> <li>Lifecycle:<ol> <li>Created when incrementing major/minor versions</li> <li>Archived when superseded by newer version branch (e.g., <code>v1.3.x</code>).</li> </ol> </li> <li>Branch Protection Rules: Inherits <code>master</code> branch's rules</li> </ul>"},{"location":"others/management/#Development-Pipeline","title":"Development Pipeline","text":""},{"location":"others/management/#For-Contributors","title":"For Contributors","text":"<p>When proposing new features or fixes, please follow our Contribution Guide .</p>"},{"location":"others/management/#For-Maintainers","title":"For Maintainers","text":"Merging PRs to Master <ol> <li> <p>Promptly review contributions</p> <p>Promise the PR has a valid title and pass the compatiability tests.</p> </li> <li> <p>Update coverage badge in <code>README.md</code> before merging:</p> <ul> <li>Right-click coverage badge in PR's comment \u2192 Copy link  </li> <li>Manually trigger <code>badge_updater.yml</code> workflow</li> </ul> </li> <li> <p>Sync local after merging: <code>git checkout master &amp;&amp; git pull</code></p> </li> </ol> Fixing Issues in Current Version <ol> <li> <p>Fetch latest changes</p> Bash<pre><code>git checkout master\ngit pull\n\ngit checkout &lt;latest-version-branch&gt;\ngit pull\n</code></pre> </li> <li> <p>Copy the change</p> Bash<pre><code># working branch: &lt;latest-version-branch&gt;\ngit checkout -b bugfix/&lt;PR-number&gt;-&lt;short-description&gt;\ngit cherry-pick &lt;hash-of-commit-on-master&gt; # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f Usually should resolve merge conflicts according to steps .</li> </ol> </li> <li> <p>Test locally</p> Bash<pre><code>bash misc/lint_format.sh\npytest -q\n</code></pre> </li> <li> <p>Push to remote</p> Bash<pre><code>git push origin bugfix/&lt;PR-number&gt;-&lt;short-description&gt; # (1)\n</code></pre> <ol> <li>\ud83d\ude4b\u200d\u2642\ufe0f If it the work can't be finished at the moment, consider to enable the <code>-u</code> flag to track the upstream branch.</li> </ol> </li> <li> <p>Merge to codebase</p> <p>Create a PR to the latest version branch, merge and then delete the <code>bugfix/&lt;PR-number&gt;-&lt;short-description&gt;</code> branch.</p> </li> <li> <p>Release a Patch Version</p> <p>See below.</p> </li> </ol> Releasing a Major/Minor Version <ol> <li> <p>Fetch latest changes</p> Bash<pre><code>git checkout master\ngit pull\n</code></pre> </li> <li> <p>Create new version branch</p> Bash<pre><code>git checkout -b &lt;version-branch&gt;\ngit push origin &lt;version-branch&gt;\n</code></pre> </li> <li> <p>Push version tag to version branch</p> Bash<pre><code>git tag &lt;version&gt;\ngit push origin &lt;version&gt;\n</code></pre> </li> <li> <p>Publish github release</p> <p>Last step will trigger the publication workflow, if it succeeds, go to Github Repo \u2192 Releases \u2192 review and publish the draft release created by <code>release-drafter</code>.</p> </li> </ol> Releasing a Patch Version <ol> <li> <p>Fetch latest changes</p> Bash<pre><code>git checkout master\ngit pull\n\ngit checkout &lt;latest-version-branch&gt;\ngit pull\n</code></pre> </li> <li> <p>Push version tag to version branch</p> Bash<pre><code>git tag &lt;version&gt;\ngit push origin &lt;version&gt;\n</code></pre> </li> <li> <p>Publish github release</p> <p>Last step will trigger the publication workflow, if it succeeds, go to Github Repo \u2192 Releases \u2192 review and publish the draft release created by <code>release-drafter</code>.</p> </li> </ol>"},{"location":"others/management/#Issue-Management","title":"Issue Management","text":""},{"location":"others/management/#Issue-Labels","title":"Issue Labels","text":"<p>Labels help categorize and prioritize issues.</p> <ol> <li> <p>Default Labels</p> <ul> <li> <p>Issues created from templates are automatically labeled:  </p> <ol> <li><code>Bug Report</code> \u2192 <code>bug</code> </li> <li><code>Feature Request</code> \u2192 <code>feat</code> </li> </ol> </li> <li> <p>Blank issues (created without templates) have no default labels.</p> </li> </ul> </li> <li> <p>Add Labels </p> <ul> <li>Click the <code>Label</code> section in the right sidebar of the issue page.</li> <li>View all labels <code>torchmeter</code> provided at our Label page .</li> </ul> </li> </ol>"},{"location":"others/management/#Issue-Ownership--Assignment","title":"Issue Ownership &amp; Assignment","text":"<p>Assigning an issue indicates ownership responsibility for tracking and resolving it.</p> Voluntary Claim <p>Assignees should self-claim issues voluntarily. Avoid assigning to others without their consent.  </p> PR-Based Assignment <p>When someone creating a PR to address an issue, the maintainer might assign the issue to himself/herself and the contributor driving the resolution.</p> Accountability <ul> <li>Assignees are responsible for issue lifecycle management.  </li> <li>The steps to resolve an issue through a PR are detailed in the Pull Request Guide .</li> </ul> <ol> <li> <p>It should be noted that the <code>PATCH</code> number is represented by the letter <code>x</code>, which refers to a series of revisions to be updated in the future.\u00a0\u21a9</p> </li> </ol>"}]}